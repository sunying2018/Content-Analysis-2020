{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MysUqNT2xFnV"
   },
   "source": [
    "# Week - 8 - Deep Neural Nets and Text - Training Models\n",
    "**Ying Sun**\n",
    "\n",
    "**Note: I conducted this homework in Google colab and only includes my answers to exercises.**\n",
    "\n",
    "\n",
    "In this week we will be introduced to using Deep Neural Networks to work with text. We have already seen some uses of neural networks for text in our classification HW, where we used a simple neural network to classify text - it performs quite well, but they can come up short in more sophisticated classification tasks, such as in predicting intent. We have also seen neural nets in the form of word embeddings such as Word2Vec - and while they certainly work well, they have some drawbacks, such as dealing with words with multiple meanings.\n",
    "\n",
    "BERT, which is a language model built using bidirectional encoders, allows us to have a powerful pre-trained model which we can then use to perform our own tasks based on the data we are analysing.\n",
    "\n",
    "In this notebook we will use huggingface/transformers, which is a python package which allows for an easy interface to use pre-trained BERT models. It is built using Tensorflow and PyTorch, two computational graph packages which are built specifically for creating powerful neural networks. We will also be introducing Keras, which allows us to easily build Neural Networks in an abstracted way. Keras is a popular way to understand how we can stack layers to create such Neural Networks, though to reach state-of-the-art results we will stick with using BERT and similar models.\n",
    "\n",
    "To demonstrate this, we will use the Corpus of Linguistic Acceptability. We will also be using BERT by learning how to extract embeddings from such a model and use it to semantically probe sentences. There are a bunch of new packages and methods we will be using so be sure to update lucem_illud_2020.\n",
    "\n",
    "Note that this notebook is different to take advantage of the GPU here. We only run the GPU heavy tasks here, where we need models to be fine-tuned.\n",
    "\n",
    "The first section contains the CoLA classification task, the second contains training a model on Trump tweets, and the last bit has us training a model on US and UK blog posts.\n",
    "\n",
    "To switch on your GPU, go to edit -> notebook settings -> hardware accelerator -> enable GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ApUQKH501LnZ"
   },
   "source": [
    "# <span style=\"color:red\">*Exercise 1*</span>\n",
    "\n",
    "<span style=\"color:red\">Construct cells immediately below this that estimate a deep classification model with Keras (and LSTM) and also BERT in order to predict pre-established data labels relevant to your final project (as for week 3's homework). Which works better? Are the errors the same or different?\n",
    "\n",
    "<span style=\"color:red\">***Stretch***</span>: <span style=\"color:red\">Now alter the neural network by stacking network layers, adjusting the embedding dimension, compare its performance with your model above, and interpret why it might be different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "geYLXGf71drx"
   },
   "source": [
    "In this exercise, I continue to use the dataset I used in hw3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "SdjewziuxLhR",
    "outputId": "efd622b7-8dab-4402-e4ed-be99676c23b6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Get the GPU device name.\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# The device name should look like the following:\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "DxTBg5j0xW2L",
    "outputId": "d0a1b2d9-3fe3-4ecd-c9e9-4c27e8d101ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "colab_type": "code",
    "id": "UUU4wr2dxaq2",
    "outputId": "0e2df345-8ef6-4c3b-f4fb-d2a6723e4a63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
      "\u001b[K     |████████████████████████████████| 501kB 4.8MB/s \n",
      "\u001b[?25hCollecting tokenizers==0.5.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7MB 57.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
      "\u001b[K     |████████████████████████████████| 870kB 53.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 51.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=25f9482d6bda2c7de88cb6e0bc30023682e8d45008c263ec3fa8eb02f74fb640\n",
      "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
      "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vuoh3AUDxem6"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "from transformers import AdamW, BertForSequenceClassification\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PVepQKa2-6f0"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632
    },
    "colab_type": "code",
    "id": "rBAzCroaxoB5",
    "outputId": "e5ce76bb-7563-4891-e07c-9f79179cbd03"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Clothing ID  Age                    Title  \\\n",
       "0           0          767   33                      NaN   \n",
       "1           1         1080   34                      NaN   \n",
       "2           2         1077   60  Some major design flaws   \n",
       "3           3         1049   50         My favorite buy!   \n",
       "4           4          847   47         Flattering shirt   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "4  This shirt is very flattering to all due to th...       5                1   \n",
       "\n",
       "   Positive Feedback Count   Division Name Department Name Class Name  \n",
       "0                        0       Initmates        Intimate  Intimates  \n",
       "1                        4         General         Dresses    Dresses  \n",
       "2                        0         General         Dresses    Dresses  \n",
       "3                        0  General Petite         Bottoms      Pants  \n",
       "4                        6         General            Tops    Blouses  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data I used in hw3\n",
    "review_raw = pd.read_csv(\"review.csv\")\n",
    "review_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Zme58bW0x22o",
    "outputId": "2ef9a59b-327f-4925-fbae-526a71cefa52"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>Intimates</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>Pants</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review Text  Rating Class Name  Age\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4  Intimates   33\n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5    Dresses   34\n",
       "2  I had such high hopes for this dress and reall...       3    Dresses   60\n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5      Pants   50\n",
       "4  This shirt is very flattering to all due to th...       5    Blouses   47"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# form the analysis dataset\n",
    "review = review_raw[['Review Text','Rating','Class Name','Age']]\n",
    "review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "gPDUfkM2x43g",
    "outputId": "11854c95-d9af-490c-c2f0-d96a7c7700ad"
   },
   "outputs": [],
   "source": [
    "# fill NA values by space\n",
    "review['Review Text'] = review['Review Text'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ly-C7UiA1tlK"
   },
   "source": [
    "Then we need to add a column \"category\" to represent the positive or negative reviews based on the rating. If the rating is 4 or higher, we can regard it as a positive review. If the rating is 2 or lower, we can regard it as a negative review. I plan to implement binary classification here so I only retain the record with negative or positive sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "PoVXATEQx79V",
    "outputId": "93e4a7e8-dc0f-495a-f804-ea11f82a94e4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>Intimates</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>Pants</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I love tracy reese dresses, but this one is no...</td>\n",
       "      <td>2</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review Text  Rating Class Name  Age  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4  Intimates   33   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5    Dresses   34   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5      Pants   50   \n",
       "4  This shirt is very flattering to all due to th...       5    Blouses   47   \n",
       "5  I love tracy reese dresses, but this one is no...       2    Dresses   49   \n",
       "\n",
       "   label  \n",
       "0      1  \n",
       "1      1  \n",
       "3      1  \n",
       "4      1  \n",
       "5      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_df = review[review['Rating'] != 3]\n",
    "b_df['label'] = np.where(b_df['Rating']>=4, 1, 0)\n",
    "b_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iau7sY5yx-LU",
    "outputId": "5c519b27-fc74-4cfe-a92d-b4f9351a5acb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20615, 5)"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iMtsBxUhyBQX"
   },
   "source": [
    "Here we use roughly 80% of all the data in training model and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HH7j7CoOyAck",
    "outputId": "485be8a5-3db8-4db9-b0d4-f8da5be2e87d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16500, 5)"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = b_df[:16500]\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LdU57O_KyE47"
   },
   "outputs": [],
   "source": [
    "# Create sentence and label lists\n",
    "sentences = train_df['Review Text'].values\n",
    "\n",
    "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
    "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
    "labels = train_df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "994Qgn4DyKNJ",
    "outputId": "f0da35c0-8437-4d9d-a911-aa4d3b92016d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenize the first sentence:\n",
      "['[CLS]', 'absolutely', 'wonderful', '-', 'silky', 'and', 'sexy', 'and', 'comfortable', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "print (\"Tokenize the first sentence:\")\n",
    "print (tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dGHjA_y_yNw5"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "\n",
    "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gz0mr-xRyZ0J"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-_bS3CWwyP8B"
   },
   "outputs": [],
   "source": [
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "18lPyuZaycIW"
   },
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SdkRfyyOyfB1"
   },
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NzCPlAEqysZd"
   },
   "outputs": [],
   "source": [
    "# Use train_test_split to split our data into train and validation sets for training\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=2020, test_size=0.1)\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                             random_state=2020, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f-9emQhtzNP-"
   },
   "source": [
    "After preprocessing, we can move to the deep neural nets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zgoqj76oyh9T"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ozo6ZDhqykNP"
   },
   "outputs": [],
   "source": [
    "vocab_in_size = tokenizer.vocab_size\n",
    "embedding_dim = 32\n",
    "unit = 100\n",
    "no_labels = len(np.unique(train_labels))\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "voxDD8veyxM6",
    "outputId": "5f8002fd-b891-4f72-cac3-430964d6bdef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 128, 32)           976704    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 1,030,106\n",
      "Trainable params: 1,030,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(vocab_in_size, embedding_dim, input_length=MAX_LEN))\n",
    "model_lstm.add(LSTM(unit))\n",
    "model_lstm.add(Dense(no_labels, activation='softmax'))\n",
    "model_lstm.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "id": "780S_YSRzBFv",
    "outputId": "346b1ca4-000b-48a9-c382-f8664cd6b46f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14850/14850 [==============================] - 103s 7ms/step - loss: 0.3686 - acc: 0.8821\n",
      "Epoch 2/10\n",
      "14850/14850 [==============================] - 101s 7ms/step - loss: 0.3588 - acc: 0.8838\n",
      "Epoch 3/10\n",
      "14850/14850 [==============================] - 102s 7ms/step - loss: 0.3387 - acc: 0.8831\n",
      "Epoch 4/10\n",
      "14850/14850 [==============================] - 101s 7ms/step - loss: 0.3467 - acc: 0.8834\n",
      "Epoch 5/10\n",
      "14850/14850 [==============================] - 102s 7ms/step - loss: 0.3429 - acc: 0.8837\n",
      "Epoch 6/10\n",
      "14850/14850 [==============================] - 104s 7ms/step - loss: 0.3363 - acc: 0.8838\n",
      "Epoch 7/10\n",
      "14850/14850 [==============================] - 101s 7ms/step - loss: 0.3240 - acc: 0.8843\n",
      "Epoch 8/10\n",
      "14850/14850 [==============================] - 100s 7ms/step - loss: 0.3258 - acc: 0.8840\n",
      "Epoch 9/10\n",
      "14850/14850 [==============================] - 99s 7ms/step - loss: 0.2116 - acc: 0.9086\n",
      "Epoch 10/10\n",
      "14850/14850 [==============================] - 98s 7ms/step - loss: 0.1500 - acc: 0.9416\n"
     ]
    }
   ],
   "source": [
    "history_lstm = model_lstm.fit(train_inputs, train_labels, \n",
    "                              epochs=10,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mHC2vQ9TzVEX"
   },
   "source": [
    "From the above results, we can see that the accuracy of this model is not bad, it hovers around 94%. Then we can implement BERT to see the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y-Jr0hapzcBn"
   },
   "outputs": [],
   "source": [
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oHCraOlPzm7x"
   },
   "outputs": [],
   "source": [
    "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
    "batch_size = 32\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dfaVkT0LztAg"
   },
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "JL8TP_cezvoW",
    "outputId": "85d31099-3523-47a6-e24a-af276e0494cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nGpfIvxez36F"
   },
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zuwBcgwdz_Py"
   },
   "outputs": [],
   "source": [
    "# This variable contains all of the hyperparemeter information our training loop needs\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V1AOSJXG0Bid"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ph-cU3cc0EUa"
   },
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sbOQjeES0Gkc"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ILzoyEW00JRe",
    "outputId": "64c3007e-baa5-40f9-b99e-76d3cd4d1511"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    465.    Elapsed: 0:00:30.\n",
      "  Batch    80  of    465.    Elapsed: 0:01:00.\n",
      "  Batch   120  of    465.    Elapsed: 0:01:31.\n",
      "  Batch   160  of    465.    Elapsed: 0:02:01.\n",
      "  Batch   200  of    465.    Elapsed: 0:02:32.\n",
      "  Batch   240  of    465.    Elapsed: 0:03:04.\n",
      "  Batch   280  of    465.    Elapsed: 0:03:36.\n",
      "  Batch   320  of    465.    Elapsed: 0:04:08.\n",
      "  Batch   360  of    465.    Elapsed: 0:04:39.\n",
      "  Batch   400  of    465.    Elapsed: 0:05:11.\n",
      "  Batch   440  of    465.    Elapsed: 0:05:43.\n",
      "\n",
      "  Average training loss: 0.17\n",
      "  Training epcoh took: 0:06:02\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.93\n",
      "  Validation took: 0:00:13\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    465.    Elapsed: 0:00:32.\n",
      "  Batch    80  of    465.    Elapsed: 0:01:03.\n",
      "  Batch   120  of    465.    Elapsed: 0:01:35.\n",
      "  Batch   160  of    465.    Elapsed: 0:02:07.\n",
      "  Batch   200  of    465.    Elapsed: 0:02:39.\n",
      "  Batch   240  of    465.    Elapsed: 0:03:10.\n",
      "  Batch   280  of    465.    Elapsed: 0:03:42.\n",
      "  Batch   320  of    465.    Elapsed: 0:04:14.\n",
      "  Batch   360  of    465.    Elapsed: 0:04:46.\n",
      "  Batch   400  of    465.    Elapsed: 0:05:17.\n",
      "  Batch   440  of    465.    Elapsed: 0:05:49.\n",
      "\n",
      "  Average training loss: 0.09\n",
      "  Training epcoh took: 0:06:08\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation took: 0:00:13\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    465.    Elapsed: 0:00:32.\n",
      "  Batch    80  of    465.    Elapsed: 0:01:03.\n",
      "  Batch   120  of    465.    Elapsed: 0:01:35.\n",
      "  Batch   160  of    465.    Elapsed: 0:02:07.\n",
      "  Batch   200  of    465.    Elapsed: 0:02:39.\n",
      "  Batch   240  of    465.    Elapsed: 0:03:10.\n",
      "  Batch   280  of    465.    Elapsed: 0:03:42.\n",
      "  Batch   320  of    465.    Elapsed: 0:04:14.\n",
      "  Batch   360  of    465.    Elapsed: 0:04:45.\n",
      "  Batch   400  of    465.    Elapsed: 0:05:17.\n",
      "  Batch   440  of    465.    Elapsed: 0:05:49.\n",
      "\n",
      "  Average training loss: 0.05\n",
      "  Training epcoh took: 0:06:08\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation took: 0:00:13\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    465.    Elapsed: 0:00:32.\n",
      "  Batch    80  of    465.    Elapsed: 0:01:03.\n",
      "  Batch   120  of    465.    Elapsed: 0:01:35.\n",
      "  Batch   160  of    465.    Elapsed: 0:02:07.\n",
      "  Batch   200  of    465.    Elapsed: 0:02:38.\n",
      "  Batch   240  of    465.    Elapsed: 0:03:10.\n",
      "  Batch   280  of    465.    Elapsed: 0:03:42.\n",
      "  Batch   320  of    465.    Elapsed: 0:04:13.\n",
      "  Batch   360  of    465.    Elapsed: 0:04:45.\n",
      "  Batch   400  of    465.    Elapsed: 0:05:17.\n",
      "  Batch   440  of    465.    Elapsed: 0:05:48.\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epcoh took: 0:06:08\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation took: 0:00:13\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # This will return the loss (rather than the model output) because we\n",
    "        # have provided the `labels`.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        # The call to `model` always returns a tuple, so we need to pull the \n",
    "        # loss value out of the tuple.\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # Telling the model not to compute or store gradients, saving memory and\n",
    "        # speeding up validation\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # This will return the logits rather than the loss because we have\n",
    "            # not provided labels.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "        # values prior to applying an activation function like the softmax.\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "00yEiOtV1BL7"
   },
   "source": [
    "## Training Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "colab_type": "code",
    "id": "S7cLmZzT0_FC",
    "outputId": "75230293-3463-40cf-8ddd-8d69625c814b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvAAAAGaCAYAAABpIXfbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERERD6IEXkRERETEg/z/VPQI8S6nmwsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(loss_values, 'b-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DiJ1XcE92ByZ"
   },
   "source": [
    "## Holdout Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QPFnB81l4B5C",
    "outputId": "58d36970-38a6-4870-9ff7-39b64c938aa4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4115, 5)"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = b_df[16500:]\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "FQzaNFvRDASK",
    "outputId": "7e62e87c-c725-4513-a012-556baa4b92e6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18821</th>\n",
       "      <td>I love the muted coloring! this top is generou...</td>\n",
       "      <td>4</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18822</th>\n",
       "      <td>I thought this top was so cute but when i trie...</td>\n",
       "      <td>1</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18823</th>\n",
       "      <td>I loved the color of the top and the faded loo...</td>\n",
       "      <td>4</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18824</th>\n",
       "      <td>These truly are tights and not leggings. they ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Legwear</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18825</th>\n",
       "      <td>I love this top! it fits perfect and is of gre...</td>\n",
       "      <td>5</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Review Text  Rating  ... Age  label\n",
       "18821  I love the muted coloring! this top is generou...       4  ...  43      1\n",
       "18822  I thought this top was so cute but when i trie...       1  ...  37      0\n",
       "18823  I loved the color of the top and the faded loo...       4  ...  23      1\n",
       "18824  These truly are tights and not leggings. they ...       5  ...  44      1\n",
       "18825  I love this top! it fits perfect and is of gre...       5  ...  45      1\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "vU2AsAFlDFnI",
    "outputId": "96f59a5b-8530-457b-8945-872df8f5c1b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test sentences: 4,115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Number of test sentences: {:,}\\n'.format(test_df.shape[0]))\n",
    "\n",
    "# Create sentence and label lists\n",
    "sentences = test_df['Review Text'].values\n",
    "labels = test_df.label.values\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
    "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask) \n",
    "\n",
    "# Convert to tensors.\n",
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "prediction_labels = torch.tensor(labels)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 32  \n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "zOx3ZwTSDbYb",
    "outputId": "a890e71f-93bc-4bf7-b86c-43d3ba2a0da2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 4,115 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    # Telling the model not to compute or store gradients, saving memory and \n",
    "    # speeding up prediction\n",
    "    with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YAuROhTdDj5U",
    "outputId": "4254a044-1ec4-42f6-8fb0-8a28d6bc686f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 3637 of 4115 (88.38%)\n"
     ]
    }
   ],
   "source": [
    "print('Positive samples: %d of %d (%.2f%%)' % (test_df.label.sum(), len(test_df.label), (test_df.label.sum() / len(test_df.label) * 100.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "JaDPeKPDDmsF",
    "outputId": "509c556d-097b-4c96-8776-b0c65fbfa392"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Matthews Corr. Coef. for each batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "matthews_set = []\n",
    "\n",
    "# Evaluate each test batch using Matthew's correlation coefficient\n",
    "print('Calculating Matthews Corr. Coef. for each batch...')\n",
    "\n",
    "# For each input batch...\n",
    "for i in range(len(true_labels)):\n",
    "\n",
    "    # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
    "    # and one column for \"1\"). Pick the label with the highest value and turn this\n",
    "    # in to a list of 0s and 1s.\n",
    "    pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "\n",
    "    # Calculate and store the coef for this batch.  \n",
    "    matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
    "    matthews_set.append(matthews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "IO7TFNb_EKiS",
    "outputId": "2f46955a-dccd-415a-afd7-2e575e269022"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6753002216523571,\n",
       " 0.6831300510639733,\n",
       " 0.8783100656536799,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.8027729719194864,\n",
       " 0.5673665146135802,\n",
       " 0.8783100656536799,\n",
       " 0.6050580452280905,\n",
       " 0.7867957924694432,\n",
       " 0.0,\n",
       " 0.7141684885491869,\n",
       " 1.0,\n",
       " 0.52678658400752,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.8509629433967631,\n",
       " 0.8027729719194864,\n",
       " 0.7141684885491869,\n",
       " 0.8509629433967631,\n",
       " 0.762962962962963,\n",
       " 0.8509629433967631,\n",
       " 0.7948717948717948,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.762962962962963,\n",
       " 0.8509629433967631,\n",
       " 0.8958064164776167,\n",
       " 1.0,\n",
       " 0.762962962962963,\n",
       " 0.4666666666666667,\n",
       " 0.6,\n",
       " 0.7142857142857143,\n",
       " 0.632183908045977,\n",
       " 0.8171428571428572,\n",
       " 1.0,\n",
       " 0.9078412990032037,\n",
       " 0.8027729719194864,\n",
       " 1.0,\n",
       " 0.8027729719194864,\n",
       " 1.0,\n",
       " 0.4666666666666667,\n",
       " 0.6753002216523571,\n",
       " 0.7453559924999299,\n",
       " 0.9078412990032037,\n",
       " 0.8320502943378436,\n",
       " 0.8333333333333334,\n",
       " 0.7142857142857143,\n",
       " 0.7142857142857143,\n",
       " 0.647150228929434,\n",
       " 0.6831300510639733,\n",
       " 0.8027729719194864,\n",
       " 0.0,\n",
       " 0.8027729719194864,\n",
       " 0.8509629433967631,\n",
       " 0.8509629433967631,\n",
       " 0.9078412990032037,\n",
       " 0.4666666666666667,\n",
       " 0.7474093186836597,\n",
       " 0.6831300510639733,\n",
       " 0.8027729719194864,\n",
       " 0.0,\n",
       " 0.8027729719194864,\n",
       " 0.6180700462007377,\n",
       " 0.8027729719194864,\n",
       " 1.0,\n",
       " 0.6956083436402525,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.8027729719194864,\n",
       " 0.6831300510639733,\n",
       " 0.5584155773160767,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.42857142857142855,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.6956083436402525,\n",
       " 0.0,\n",
       " 0.47519096331149147,\n",
       " 0.8132500607904443,\n",
       " 0.47519096331149147,\n",
       " 1.0,\n",
       " 0.5584155773160767,\n",
       " 0.7474093186836597,\n",
       " 1.0,\n",
       " 0.8783100656536799,\n",
       " 1.0,\n",
       " 0.8509629433967631,\n",
       " 0.7142857142857143,\n",
       " 0.9078412990032037,\n",
       " 0.8958064164776167,\n",
       " 0.8027729719194864,\n",
       " 0.8509629433967631,\n",
       " 1.0,\n",
       " 0.8783100656536799,\n",
       " 0.35986374603287324,\n",
       " 0.4414147946478204,\n",
       " 0.9229582069908973,\n",
       " 0.7142857142857143,\n",
       " 0.8783100656536799,\n",
       " 0.8171428571428572,\n",
       " 0.632183908045977,\n",
       " 0.9078412990032037,\n",
       " 1.0,\n",
       " 0.7948717948717948,\n",
       " 0.9078412990032037,\n",
       " -0.03225806451612903,\n",
       " 0.8027729719194864,\n",
       " 0.8509629433967631,\n",
       " 0.8027729719194864,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.8783100656536799,\n",
       " 0.8958064164776167,\n",
       " 1.0,\n",
       " 0.6753002216523571,\n",
       " 0.632183908045977,\n",
       " 0.8509629433967631,\n",
       " 0.8509629433967631,\n",
       " 1.0,\n",
       " 0.5584155773160767,\n",
       " 0.4666666666666667,\n",
       " 0.4521365014259176,\n",
       " 0.8027729719194864,\n",
       " 1.0,\n",
       " 1.0]"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matthews_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YZrZTWi2EQGF",
    "outputId": "aa3c1949-6ab2-4bbc-bfec-b87402282232"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.787\n"
     ]
    }
   ],
   "source": [
    "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
    "flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
    "\n",
    "# Calculate the MCC\n",
    "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
    "\n",
    "print('MCC: %.3f' % mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "Mmq5henqFZv8",
    "outputId": "a53f6efc-344d-4cd6-96f6-9480d28b39eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to ./model_save/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./model_save/vocab.txt',\n",
       " './model_save/special_tokens_map.json',\n",
       " './model_save/added_tokens.json')"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "\n",
    "output_dir = './model_save/'\n",
    "\n",
    "# Create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "# They can then be reloaded using `from_pretrained()`\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "# Good practice: save your training arguments together with the trained model\n",
    "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AMpveItgEfXC"
   },
   "source": [
    "From the result above, we can see that's pretty good performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hWj8j_mVHWxP"
   },
   "source": [
    "# <span style=\"color:red\">*Exercise 2*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, use the pipeline functions and the word or sentence vector functions (e.g., similarity) to explore the social game underlying the production and meaning of texts associated with your final project. You have used similar, but often weaker versions in previous weeks. How does BERT help you gain insight regarding your research question that is similar and different from prior methods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0LAtM_vCHflC",
    "outputId": "37bb7710-cc77-414a-edef-66ebeffd1fcf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20615, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6epeA8vNHw9H"
   },
   "outputs": [],
   "source": [
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ICmPkh5AH6yR"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "EXARgPveIDNe",
    "outputId": "f16a4dd5-dad2-4638-e042-d549b7e0bb85"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>Intimates</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>Pants</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I love tracy reese dresses, but this one is no...</td>\n",
       "      <td>2</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review Text  Rating Class Name  Age  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4  Intimates   33   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5    Dresses   34   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5      Pants   50   \n",
       "4  This shirt is very flattering to all due to th...       5    Blouses   47   \n",
       "5  I love tracy reese dresses, but this one is no...       2    Dresses   49   \n",
       "\n",
       "   label  \n",
       "0      1  \n",
       "1      1  \n",
       "3      1  \n",
       "4      1  \n",
       "5      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9bm3XhupIQep",
    "outputId": "6277c78a-5fa8-4094-a948-0f0e68fd2dec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Absolutely wonderful - silky and sexy and comfortable'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = b_df['Review Text'][0]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "MqQVA8ctIHC3",
    "outputId": "504f3c2f-7a5b-4665-d2d3-49a42c6f0e8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'absolutely', 'wonderful', '-', 'silky', 'and', 'sexy', 'and', 'comfortable', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Tokenize our sentence with the BERT tokenizer.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "# Print out the tokens.\n",
    "print (tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "cYAyWAygIZnI",
    "outputId": "1f5ac140-106d-4d55-b2aa-afe9f2eb4ab2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['peninsula',\n",
       " 'adults',\n",
       " 'novels',\n",
       " 'emerged',\n",
       " 'vienna',\n",
       " 'metro',\n",
       " 'debuted',\n",
       " 'shoes',\n",
       " 'tamil',\n",
       " 'songwriter',\n",
       " 'meets',\n",
       " 'prove',\n",
       " 'beating',\n",
       " 'instance',\n",
       " 'heaven',\n",
       " 'scared',\n",
       " 'sending',\n",
       " 'marks',\n",
       " 'artistic',\n",
       " 'passage',\n",
       " 'superior',\n",
       " '03',\n",
       " 'significantly',\n",
       " 'shopping',\n",
       " '##tive',\n",
       " 'retained',\n",
       " '##izing',\n",
       " 'malaysia',\n",
       " 'technique',\n",
       " 'cheeks']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the vocabulary looks like\n",
    "list(tokenizer.vocab.keys())[6000:6030]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iEPivNS0JNAp"
   },
   "outputs": [],
   "source": [
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2OiieBOCJlp-",
    "outputId": "b0dc830a-4e16-460a-ec23-444ef18abaf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# segment id\n",
    "segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "print (segments_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GGe9iVlwKDLS"
   },
   "outputs": [],
   "source": [
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "cg408j2nKEOB",
    "outputId": "1e7804f0-70b9-403a-ff75-ddeb96f85706"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model_embedding = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model_embedding.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "colab_type": "code",
    "id": "Xu1jndC-KHGt",
    "outputId": "c23bb882-2e9e-4eb6-cf2f-41283fc50af8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 768)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model_embedding(tokens_tensor)\n",
    "len(output[0][0][0]), len(output[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings, sentence_embedding = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4399, -0.0191, -0.0617,  ..., -0.3785,  0.1435,  0.4821],\n",
       "        [ 0.6304,  0.1536,  0.2274,  ..., -0.3958,  0.9708,  0.6290],\n",
       "        [ 0.6038,  0.5120,  0.3658,  ..., -0.7298,  0.4188, -0.3061],\n",
       "        ...,\n",
       "        [-0.9268, -0.4823,  0.4026,  ..., -0.2851,  0.4595,  0.5096],\n",
       "        [-0.7741, -0.5284,  0.2177,  ..., -0.5207,  0.3757, -0.3708],\n",
       "        [ 0.7537,  0.0132, -0.3186,  ..., -0.1667, -0.6352, -0.1745]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vec = word_embeddings[0][0]\n",
    "vec = vec.detach().numpy()\n",
    "# Plot the values as a histogram to show their distribution.\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(vec, bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values are groupd by layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_vecs = []\n",
    "# For each token in the sentence...\n",
    "for embedding in word_embeddings[0]:\n",
    "    cat_vec = embedding.detach().numpy()\n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs.append(cat_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-4.39877272e-01, -1.90802664e-02, -6.16667457e-02,  6.03222772e-02,\n",
       "        -4.18127298e-01, -2.64296681e-01, -1.87311396e-01,  2.07460880e-01,\n",
       "         2.89250445e-02, -3.17205563e-02, -1.32442310e-01,  2.09557757e-01,\n",
       "         5.20663440e-01,  5.59812963e-01, -9.67808068e-02,  1.42375648e-01,\n",
       "        -1.80406988e-01,  3.62244427e-01,  9.67378020e-02, -2.95396090e-01,\n",
       "         5.54107502e-02, -1.74445540e-01, -1.98907390e-01, -1.36980474e-01,\n",
       "         3.77720445e-02,  9.75560099e-02, -1.29530638e-01,  7.10966140e-02,\n",
       "         3.49142075e-01,  3.04462194e-01,  1.29554555e-01, -1.23081461e-01,\n",
       "        -1.34923130e-01, -3.55803162e-01,  3.13375741e-01, -2.52043128e-01,\n",
       "         2.97488153e-01, -3.14916313e-01, -3.62309128e-01, -4.68669713e-01,\n",
       "        -1.26954794e-01,  4.75697070e-02,  3.11124325e-01, -4.70018610e-02,\n",
       "        -1.30449235e-03, -4.45340872e-02, -2.85827136e+00,  4.55799662e-02,\n",
       "        -2.00929165e-01, -5.02035320e-02,  1.85074016e-01, -3.43539923e-01,\n",
       "         2.18231212e-02,  2.63503134e-01,  1.88975304e-01,  1.68835565e-01,\n",
       "        -1.26975611e-01,  5.06058931e-01,  1.30575374e-01,  3.33965838e-01,\n",
       "        -2.05319412e-02,  5.77261746e-02,  2.13407993e-01, -2.38261312e-01,\n",
       "         4.15424287e-01,  3.17663431e-01,  1.13851607e-01, -1.89813115e-02,\n",
       "         1.57160968e-01,  8.89301002e-01, -2.11304337e-01, -3.64232183e-01,\n",
       "         2.08134234e-01, -2.06205860e-01, -2.49415442e-01, -3.57962072e-01,\n",
       "         2.28340089e-01,  7.81026706e-02,  3.26458737e-02,  4.35542941e-01,\n",
       "        -3.96513611e-01,  5.90287745e-01,  2.43140340e-01,  8.08566809e-02,\n",
       "        -6.01086393e-03,  6.59447014e-01, -3.03579926e-01, -2.63659537e-01,\n",
       "         2.87497759e-01,  3.09670791e-02, -2.64628142e-01, -1.60652883e-02,\n",
       "         9.35174748e-02,  3.70153069e-01,  2.14002743e-01, -1.95515007e-01,\n",
       "        -4.99734879e-01, -9.78180692e-02,  5.52559271e-02,  1.28718063e-01,\n",
       "         3.05950269e-02, -8.74056742e-02,  8.90107602e-02, -6.19700253e-01,\n",
       "         1.18941940e-01,  1.93682969e-01, -1.16504073e-01, -4.33854550e-01,\n",
       "        -8.21978152e-02, -2.21539831e+00,  2.34435737e-01,  5.11847548e-02,\n",
       "        -3.64645869e-01,  1.85214933e-02, -5.04835024e-02,  6.14617348e-01,\n",
       "         1.32771388e-01,  2.10168958e-01,  5.56563973e-01,  1.04725793e-01,\n",
       "         1.93513453e-01,  1.53395429e-01,  2.06427738e-01,  1.00720108e-01,\n",
       "         4.20309573e-01, -4.49714288e-02, -1.96654931e-01, -3.05079907e-01,\n",
       "         3.99848185e-02,  2.51286268e-01,  3.44729424e-03,  3.50959241e-01,\n",
       "         2.71182731e-02,  4.39693891e-02, -3.34370792e-01,  1.54466808e-01,\n",
       "         6.88182935e-02, -1.62536666e-01,  2.80825138e-01, -3.78175706e-01,\n",
       "        -4.14806306e-01, -2.58415461e-01, -3.29305363e+00,  1.76814258e-01,\n",
       "         3.60050350e-01, -1.34164631e-01, -3.16617340e-01,  1.93486348e-01,\n",
       "        -1.19354509e-01, -1.27946392e-01,  2.88357764e-01,  2.05841094e-01,\n",
       "        -2.89319277e-01, -4.47582722e-01, -1.97977901e-01,  8.83066654e-03,\n",
       "        -5.67473546e-02,  1.36954039e-01,  2.31358796e-01, -6.61813468e-02,\n",
       "        -1.25162601e-01, -1.12697951e-01,  5.65905198e-02,  8.13551098e-02,\n",
       "        -4.73496318e-01, -7.17534944e-02,  5.03651798e-01,  5.27185440e-01,\n",
       "         1.43551812e-01,  1.71586588e-01,  2.56333262e-01, -1.07503384e-01,\n",
       "         4.89881843e-01,  4.22807515e-01,  1.42276362e-02,  2.59019509e-02,\n",
       "         1.84558704e-02, -6.12384640e-03, -1.42941140e-02,  2.77923942e-02,\n",
       "        -3.86269391e-03,  2.75699764e-01,  2.67185837e-01,  3.03617656e-01,\n",
       "         4.28788543e-01,  3.52241583e-02,  3.42671901e-01, -7.74732381e-02,\n",
       "        -3.74526411e-01,  1.63740322e-01, -3.48500200e-02,  2.54733384e-01,\n",
       "         3.63801606e-04, -1.82857811e-01, -5.85428216e-02,  9.47251767e-02,\n",
       "         3.47196758e-01, -2.03195155e-01, -8.56966898e-02,  3.86565238e-01,\n",
       "         3.22906137e-01, -2.48174444e-01, -2.09822834e-01,  1.59647912e-01,\n",
       "        -3.18457007e-01,  3.55254126e+00,  3.19198728e-01, -1.35955200e-01,\n",
       "         4.04599346e-02, -8.12916383e-02, -2.23122895e-01,  1.66198060e-01,\n",
       "         1.69205025e-01, -2.55526900e-02, -9.53121781e-02, -1.50946081e-01,\n",
       "         2.45979756e-01,  9.33064520e-02,  3.82377282e-02, -4.38149497e-02,\n",
       "         4.93482471e-01,  4.18316722e-01, -5.09032086e-02,  1.27384245e-01,\n",
       "        -2.96522707e-01, -1.57495245e-01, -2.31734276e-01, -1.49487138e-01,\n",
       "        -2.09480703e-01, -1.20851564e+00, -2.04151601e-01, -1.36808023e-01,\n",
       "        -6.80463910e-01,  2.39076465e-01,  4.69127111e-02, -9.47561339e-02,\n",
       "        -8.90102237e-02, -1.57231405e-01,  2.60350734e-01, -2.67006345e-02,\n",
       "        -1.10172287e-01,  4.74998772e-01,  4.79498267e-01,  1.77167296e-01,\n",
       "        -5.33031762e-01,  6.69356108e-01,  2.48017296e-01,  2.22696960e-02,\n",
       "         2.68604666e-01,  2.86019295e-01,  3.87608379e-01, -1.71351343e-01,\n",
       "         7.89506510e-02,  4.85153124e-02, -4.39959794e-01,  2.58838907e-02,\n",
       "        -2.18538523e-01, -5.16629890e-02, -1.18197784e-01, -6.95615709e-02,\n",
       "        -2.98436344e-01, -3.37381095e-01,  3.66415232e-01, -3.33203733e-01,\n",
       "        -3.01071286e-01, -1.69754148e-01,  1.37632057e-01, -4.30763870e-01,\n",
       "         6.40651807e-02,  1.77160770e-01, -3.44188809e-01,  1.94822568e-02,\n",
       "        -3.10343325e-01, -3.43864965e+00, -1.75352588e-01,  8.60308409e-02,\n",
       "        -9.74995717e-02,  1.80484444e-01,  1.95979878e-01, -3.49940270e-01,\n",
       "         4.97463167e-01,  3.36426765e-01, -1.67631313e-01,  2.79892564e-01,\n",
       "         2.23105088e-01, -4.57920074e-01,  3.26047570e-01, -3.54618073e-01,\n",
       "         1.26403064e-01,  4.25915308e-02,  3.49878490e-01, -5.30009151e-01,\n",
       "        -2.56823629e-01,  2.89823532e-01,  5.11372149e-01,  9.63720605e-02,\n",
       "         3.11011761e-01,  2.68485248e-01, -3.65728319e-01, -4.60594684e-01,\n",
       "        -8.44346583e-01,  1.63120985e-01, -1.24164134e-01, -5.43825962e-02,\n",
       "         1.66860282e-01,  4.59810883e-01,  4.15622920e-01, -3.34534258e-01,\n",
       "        -3.64532900e+00, -3.70377786e-02, -3.06158662e-01, -2.25576654e-01,\n",
       "        -2.07182374e-02,  8.37005153e-02,  1.49209291e-01, -2.18048751e-01,\n",
       "        -3.61292034e-01,  3.29725683e-01,  2.07013726e-01, -2.97113247e-02,\n",
       "        -2.50610232e-01,  2.77024001e-01,  4.40186679e-01,  3.04641068e-01,\n",
       "         1.02571152e-01, -1.32142473e-02,  7.67747611e-02,  3.14401314e-02,\n",
       "        -3.95826072e-01,  7.33424351e-02,  4.62321430e-01, -3.10593750e-02,\n",
       "         3.68943125e-01,  3.36572230e-01, -3.37776989e-01, -4.93677139e-01,\n",
       "        -4.04693753e-01, -1.78353172e-02, -4.45449889e-01, -2.38146633e-01,\n",
       "         2.71818966e-01,  7.85025209e-02,  1.72472328e-01, -4.58726957e-02,\n",
       "         4.18741941e-01, -2.67938972e-01,  6.92193329e-01,  1.04570806e-01,\n",
       "         1.21450491e-01,  5.98424792e-01,  2.23106623e-01,  2.70099044e-01,\n",
       "         2.05601126e-01, -2.75015712e-01,  5.27938306e-01,  3.44486296e-01,\n",
       "         5.22581756e-01,  2.40336359e-02,  2.08633825e-01,  1.84801668e-01,\n",
       "         7.46103168e-01, -3.13747436e-01, -2.11108282e-01,  1.70282811e-01,\n",
       "         1.50462136e-01,  1.31380081e-01,  1.24909565e-01,  1.81097955e-01,\n",
       "         5.83000362e-01, -4.55646187e-01,  4.53932762e-01,  1.62906364e-01,\n",
       "         2.96550095e-01,  3.67515460e-02,  3.08519781e-01, -4.30511832e-01,\n",
       "        -8.57156515e-02,  2.19398856e-01,  1.55803144e-01,  5.58141768e-02,\n",
       "         1.29068904e-02, -9.95545566e-01, -3.03377658e-01, -2.17449982e-02,\n",
       "        -5.72673798e-01,  6.56199679e-02,  2.71699071e-01, -4.54284437e-02,\n",
       "        -4.49779570e-01, -1.67536765e-01,  4.30282503e-02,  6.86727166e-01,\n",
       "        -4.61232364e-01, -1.22299477e-01,  6.03335015e-02, -3.07441592e-01,\n",
       "        -4.03933406e-01, -2.58615673e-01, -3.38640869e-01,  2.46001855e-02,\n",
       "         1.64146721e-01, -5.11180051e-02, -1.61131658e-03,  1.67022601e-01,\n",
       "        -6.82140701e-03, -5.06210268e-01,  1.00583635e-01, -3.37633967e-01,\n",
       "        -6.82568789e-01, -2.51802385e-01, -5.08007891e-02,  4.75903094e-01,\n",
       "         2.13547602e-01, -3.99953067e-01, -2.71380335e-01, -1.36174440e-01,\n",
       "         1.59829244e-01,  2.94065565e-01, -6.88934028e-02,  2.02070266e-01,\n",
       "         3.13872248e-01,  3.08576524e-01,  8.26480985e-01, -4.60080862e-01,\n",
       "        -3.77903372e-01,  7.36247361e-01,  3.75964969e-01, -6.86182529e-02,\n",
       "         1.79855525e-01,  1.64724022e-01, -1.57013014e-01,  3.20578814e-01,\n",
       "        -1.67528987e-02,  2.10528988e-02,  7.14054555e-02, -1.87485129e-01,\n",
       "        -6.74017429e-01, -3.44227046e-01,  1.53339937e-01, -3.87800962e-01,\n",
       "        -1.89060107e-01, -6.66216135e-01,  2.20021337e-01, -3.85247618e-02,\n",
       "        -2.32197374e-01, -9.34099779e-02, -7.69720301e-02, -9.65722650e-03,\n",
       "         2.28051871e-01, -4.64345887e-03, -3.26410949e-01,  4.36488360e-01,\n",
       "         1.02575548e-01,  7.65467942e-01,  9.58555192e-02,  2.01450467e-01,\n",
       "         1.09461404e-01,  7.52420843e-01,  9.00437608e-02, -1.60404772e-01,\n",
       "        -4.46610630e-01, -2.86503345e-01,  1.32131562e-01, -6.03691414e-02,\n",
       "         1.49614096e-01, -4.28690277e-02,  2.51594298e-02, -4.44525555e-02,\n",
       "         2.36826628e-01,  2.10612148e-01, -1.26413548e+00,  3.66716653e-01,\n",
       "         4.46906835e-01, -1.76681690e-02,  2.98483759e-01, -2.98535079e-03,\n",
       "        -3.03707540e-01,  6.66403294e-01,  4.98581469e-01,  2.84721732e-01,\n",
       "        -6.58016875e-02, -1.53152898e-01, -1.20514221e-01,  3.80342752e-01,\n",
       "        -7.83716589e-02,  1.24767840e-01, -1.50622815e-01,  5.41016608e-02,\n",
       "         1.75071150e-01,  8.08503665e-03,  5.73129773e-01,  4.49116170e-01,\n",
       "         2.06960872e-01,  2.23125219e-01, -5.89964569e-01, -8.43336955e-02,\n",
       "        -6.70736432e-02,  4.00660396e-01, -1.21640131e-01,  2.93325365e-01,\n",
       "         2.54710056e-02, -6.31427705e-01, -5.09134769e-01, -1.50660962e-01,\n",
       "         1.52463078e-01, -7.16541708e-03,  4.29372847e-01, -1.52589396e-01,\n",
       "         1.75433010e-01,  1.56552285e-01, -2.27405369e-01,  8.11860144e-01,\n",
       "         4.47632596e-02, -1.29681796e-01,  8.96082342e-01, -6.09936304e-02,\n",
       "        -3.82970393e-01,  3.02963793e-01,  1.72254294e-02, -1.74176574e-01,\n",
       "        -2.53953099e-01, -4.59228069e-01, -3.97048861e-01,  1.59845367e-01,\n",
       "         1.52738243e-01, -1.93197444e-01, -1.58638507e-03, -1.77064687e-01,\n",
       "        -1.89066067e-01, -3.39293331e-01,  2.44197831e-01, -7.09091544e-01,\n",
       "        -5.20823181e-01, -1.27566531e-02, -1.95386007e-01, -2.27167442e-01,\n",
       "         2.11988986e-02, -2.55162299e-01, -5.23479320e-02,  2.46608704e-01,\n",
       "         4.27615285e-01, -8.55924636e-02, -2.11735114e-01,  3.30868930e-01,\n",
       "        -2.19468921e-01,  5.17893061e-02,  5.02516747e-01, -3.98959294e-02,\n",
       "         3.63826007e-02, -5.31865716e-01, -1.26143068e-01, -1.78887159e-01,\n",
       "        -2.22254336e-01,  6.41527712e-01, -2.88837373e-01,  3.14566493e-01,\n",
       "         1.83342155e-02,  1.18100941e-01, -1.53103709e-01, -3.45491260e-01,\n",
       "        -3.12567264e-01, -7.73628592e-01,  3.91178042e-01, -6.79055825e-02,\n",
       "         1.57304347e-01, -2.09170908e-01, -1.99557483e-01, -5.42132296e-02,\n",
       "        -1.37455553e-01,  2.76549190e-01, -3.55628207e-02,  4.11429368e-02,\n",
       "         8.69576633e-03,  2.12884992e-01,  1.19077846e-01,  2.75704503e-01,\n",
       "         2.01922521e-01,  1.12924322e-01, -1.54092908e-01,  3.01316470e-01,\n",
       "        -5.40340953e-02,  1.53918862e-01, -1.25898659e-01, -9.23625007e-03,\n",
       "         2.07380265e-01, -2.55902022e-01,  5.89319348e-01, -5.60770690e-01,\n",
       "         1.79065490e+00,  2.31479928e-01,  2.55455345e-01, -3.54075022e-02,\n",
       "         2.16894835e-01, -1.63200513e-01, -3.25228095e-01, -1.05133101e-01,\n",
       "        -3.03230911e-01,  2.50543833e-01,  6.68090165e-01,  4.16918814e-01,\n",
       "         3.19684684e-01,  4.81013730e-02,  3.53353977e-01,  3.82126153e-01,\n",
       "        -4.99136329e-01, -1.60490245e-01, -5.59184372e-01, -1.96634792e-02,\n",
       "        -4.23234910e-01,  3.58205587e-01,  2.15150908e-01, -1.51352361e-02,\n",
       "        -2.31667057e-01,  5.63991606e-01,  3.64645064e-01, -4.05241132e-01,\n",
       "        -1.37173086e-01, -2.10986659e-01,  1.02365896e-01, -2.51179993e-01,\n",
       "        -2.27792531e-01,  4.17927653e-01, -7.30988562e-01,  1.67561769e-02,\n",
       "         1.52922615e-01, -2.72748947e-01,  1.26960084e-01,  3.69534075e-01,\n",
       "         2.75047362e-01, -3.99697006e-01,  6.19479060e-01, -4.74532992e-01,\n",
       "        -8.61586034e-02,  6.22477531e-01, -4.03107733e-01, -2.76007235e-01,\n",
       "         3.73733193e-01,  6.65450037e-01, -1.27352342e-01,  1.14753343e-01,\n",
       "        -6.25814199e-01,  3.31605338e-02, -2.20727369e-01, -2.35701561e-01,\n",
       "         3.77960168e-02, -2.84950912e-01, -6.35304093e-01,  3.77503037e-01,\n",
       "         1.48190260e-01,  8.94038901e-02,  2.25626945e-01, -8.96797329e-02,\n",
       "        -1.17282011e-01,  3.64154458e-01,  2.25792617e-01,  7.27619603e-03,\n",
       "        -1.18153244e-01, -3.72277349e-01,  4.41248640e-02,  6.03375554e-01,\n",
       "         4.07734334e-01,  5.84391803e-02,  1.63652487e-02,  2.79850245e-01,\n",
       "         6.11119032e-01, -1.95272967e-01, -6.87546253e-01, -2.63819170e+00,\n",
       "        -6.67043775e-02,  1.99175686e-01,  2.87708193e-01, -1.00094281e-01,\n",
       "         4.89359722e-02,  4.14647728e-01, -1.36051625e-01,  3.19836915e-01,\n",
       "        -3.05796593e-01,  1.90346822e-01,  1.59523383e-01,  1.99890748e-01,\n",
       "         1.60435587e-02, -2.76208937e-01,  1.75415114e-01,  5.80735058e-02,\n",
       "        -2.28707656e-01, -3.79298627e-03, -3.56395729e-03,  1.98873021e-02,\n",
       "         1.59271464e-01,  7.45666102e-02, -1.65917143e-01, -3.02834481e-01,\n",
       "         5.79702735e-01, -1.79380268e-01, -1.42579198e-01,  1.45860553e-01,\n",
       "         1.20968133e-01,  5.62167428e-02,  9.04148936e-01, -2.84681559e-01,\n",
       "         6.78075776e-02,  3.62363905e-01, -2.23336101e-01, -1.00757770e-01,\n",
       "        -9.84358639e-02, -7.64312670e-02,  1.15754202e-01, -3.70369703e-01,\n",
       "         4.24074590e-01,  5.21273077e-01,  1.54167414e-04,  7.37106130e-02,\n",
       "        -1.33696139e-01,  6.30799294e-01, -1.85566798e-01,  7.04215646e-01,\n",
       "        -4.95942608e-02, -2.08481014e-01, -4.74552542e-01,  3.77494812e-01,\n",
       "        -1.90017313e-01,  5.73771417e-01,  1.54008925e-01, -1.74313858e-02,\n",
       "        -2.57767409e-01,  2.03420997e-01, -2.69471794e-01,  1.61923677e-01,\n",
       "        -2.46906728e-01, -9.13854837e-02,  1.76498681e-01,  4.86288995e-01,\n",
       "        -2.43383676e-01, -2.11271271e-02,  1.24829181e-01, -2.26783037e-01,\n",
       "        -5.39064184e-02,  1.63140297e-01, -2.29166418e-01,  4.46570098e-01,\n",
       "        -4.38806862e-02, -1.02465637e-01,  2.26278186e-01,  6.31386995e-01,\n",
       "         8.88147354e-02,  3.84918123e-01, -1.71598732e-01,  3.73836011e-02,\n",
       "        -1.85930520e-01, -4.72096413e-01, -1.83129683e-01,  8.33527893e-02,\n",
       "        -7.24503565e+00,  3.41484323e-02, -4.50770169e-01, -2.07253128e-01,\n",
       "        -1.49651960e-01, -1.90845847e-01,  2.37832949e-01, -6.35387182e-01,\n",
       "         2.59075701e-01, -3.49284649e-01,  6.51793405e-02, -1.61671445e-01,\n",
       "        -2.51007617e-01, -3.78503472e-01,  1.43521383e-01,  4.82148945e-01],\n",
       "       dtype=float32),\n",
       " array([ 6.30430698e-01,  1.53639823e-01,  2.27373481e-01,  1.63852628e-02,\n",
       "         9.87269938e-01,  2.71094739e-02, -2.13083386e-01,  4.53424394e-01,\n",
       "         3.32856864e-01, -5.90704679e-01,  6.77545369e-03, -8.06991994e-01,\n",
       "         4.49577346e-02,  8.58916938e-01,  4.46285725e-01,  5.22616982e-01,\n",
       "         6.61814928e-01,  4.23944920e-01, -1.25962007e+00,  3.43148619e-01,\n",
       "         1.24459662e-01, -4.91133362e-01, -5.10345280e-01,  4.36077297e-01,\n",
       "         5.87790906e-01,  1.09224036e-01, -1.04776412e-01, -4.88017201e-02,\n",
       "         2.82431811e-01, -6.85379282e-02,  5.98745584e-01, -2.49790177e-01,\n",
       "        -2.03750670e-01, -5.20859361e-01, -1.30336344e+00, -5.15566051e-01,\n",
       "        -1.25618815e-01, -4.26791728e-01, -4.75045204e-01, -9.10720229e-03,\n",
       "         3.70507807e-01, -3.58254313e-01,  2.56260574e-01, -1.82956979e-02,\n",
       "        -9.61706862e-02, -2.03539163e-01, -2.18647659e-01, -3.31914961e-01,\n",
       "        -2.17780679e-01, -4.85543251e-01, -1.96942449e-01,  4.70128506e-01,\n",
       "        -7.07839131e-01, -1.63818493e-01, -1.56849831e-01,  6.26293600e-01,\n",
       "        -1.01745331e+00, -3.86619598e-01,  3.69571033e-03,  8.47015977e-02,\n",
       "        -8.54943931e-01,  6.30299002e-03,  2.88947552e-01, -9.81493592e-01,\n",
       "         1.91779792e-01,  7.82938242e-01,  6.23169653e-02,  2.63056718e-02,\n",
       "         5.74802756e-01,  2.50097334e-01,  3.11303854e-01, -7.27926970e-01,\n",
       "        -2.18233541e-01, -2.74895549e-01, -7.33394027e-01, -2.66357839e-01,\n",
       "        -3.96018803e-01, -6.64461851e-01, -6.91456497e-02,  3.19630206e-01,\n",
       "        -1.47614136e-01,  5.54359734e-01,  3.16936880e-01,  9.41420913e-01,\n",
       "         1.61570013e-02,  4.25676584e-01, -5.08750319e-01,  5.40249825e-01,\n",
       "         5.26835501e-01,  1.06732465e-01,  2.16177523e-01, -4.88792174e-02,\n",
       "         2.40783021e-01,  4.44629461e-01,  6.29427075e-01, -8.26350272e-01,\n",
       "        -3.34805727e-01, -8.29850286e-02,  7.31527358e-02, -1.03371561e-01,\n",
       "         1.30902261e-01,  4.42045450e-01, -1.38334081e-01,  7.08332211e-02,\n",
       "        -6.38343632e-01, -4.33356851e-01, -4.69197482e-02,  7.68552572e-02,\n",
       "         6.73488498e-01, -8.63427997e-01, -3.61593932e-01,  2.81414762e-03,\n",
       "         2.37300679e-01, -1.48700386e-01,  1.07415035e-01, -3.70611623e-03,\n",
       "         5.83706379e-01,  9.21896160e-01,  3.00090969e-01, -4.29969251e-01,\n",
       "        -4.02551562e-01,  2.57177234e-01,  6.83199286e-01,  7.08998740e-01,\n",
       "         2.75569975e-01, -4.63891447e-01, -2.64192730e-01,  6.53075516e-01,\n",
       "        -5.45401216e-01, -5.53291500e-01,  4.59534340e-02, -2.41717786e-01,\n",
       "        -2.24011719e-01, -5.03894687e-01, -6.35342360e-01,  3.61482322e-01,\n",
       "        -2.44313180e-01, -3.85476798e-01,  2.71419287e-01,  4.27491874e-01,\n",
       "         1.99145764e-01,  5.29687405e-01, -2.02872229e+00,  5.27046263e-01,\n",
       "        -3.69209573e-02, -4.02675956e-01,  4.55504596e-01,  4.59209263e-01,\n",
       "        -2.41563037e-01, -2.45993614e-01,  2.60779619e-01, -2.35046923e-01,\n",
       "        -6.12326443e-01, -9.46684599e-01, -1.21460684e-01,  4.63923216e-01,\n",
       "         2.56201386e-01, -2.53323704e-01,  2.14344531e-01, -4.54104215e-01,\n",
       "        -3.53258163e-01,  1.34066403e-01,  4.38368112e-01,  5.04220188e-01,\n",
       "        -6.94315553e-01,  2.26358712e-01, -6.07629716e-02,  8.42022955e-01,\n",
       "        -5.56842797e-02,  4.37717080e-01,  3.87377322e-01, -3.58832866e-01,\n",
       "         2.13709995e-01,  6.33609951e-01,  5.41901469e-01, -2.10656643e-01,\n",
       "         1.49945736e-01,  5.12589931e-01,  5.65446556e-01,  3.91882390e-01,\n",
       "        -5.10524988e-01,  1.05476654e+00, -6.26611188e-02, -8.22955847e-01,\n",
       "         4.74727247e-03, -2.49424487e-01,  4.46836382e-01, -6.19732551e-02,\n",
       "        -2.33394265e-01,  1.05567253e+00,  7.41993934e-02,  5.44100463e-01,\n",
       "         7.84171879e-01,  1.62662104e-01,  3.78466770e-02,  1.85595095e-01,\n",
       "         1.26102105e-01, -5.27221859e-01, -2.52808571e-01,  2.56885141e-01,\n",
       "         5.08079112e-01,  1.19767919e-01,  5.17763257e-01,  5.44866435e-02,\n",
       "        -4.18261677e-01,  9.25911129e-01,  4.02479082e-01, -1.91655651e-01,\n",
       "        -6.70533121e-01, -2.36698911e-02,  1.57242686e-01, -3.08973938e-01,\n",
       "         5.26985466e-01, -5.95960915e-01,  6.11430764e-01,  1.69113725e-01,\n",
       "        -3.47860932e-01,  6.62112236e-03,  2.43976489e-01, -2.53583699e-01,\n",
       "         4.71792042e-01,  5.39466977e-01, -3.23351592e-01,  7.97504842e-01,\n",
       "         2.41162270e-01,  8.94808471e-01, -1.15947224e-01, -3.79305035e-01,\n",
       "         5.52050531e-01, -4.72108006e-01, -3.72570574e-01, -2.90378630e-01,\n",
       "         7.50896573e-01,  9.41810906e-01,  8.49092603e-01,  1.26278829e-02,\n",
       "        -5.96414268e-01,  4.38115060e-01,  2.38706693e-01,  5.57916403e-01,\n",
       "        -1.78224444e-01,  1.20524859e+00,  1.91791117e-01,  3.85604322e-01,\n",
       "        -4.85748559e-01,  9.31689262e-01, -2.38142744e-01, -6.71793461e-01,\n",
       "        -5.45917034e-01,  5.91324687e-01, -7.20244944e-01, -1.12042241e-01,\n",
       "        -1.93557456e-01, -3.92281502e-01,  2.68353939e-01, -4.02868718e-01,\n",
       "        -2.66299725e-01,  4.57457870e-01, -3.12891722e-01,  1.50410652e-01,\n",
       "        -1.61586702e-01, -7.76534379e-01,  7.62388289e-01, -6.57747090e-01,\n",
       "        -4.39462572e-01, -3.18396837e-01, -4.62278366e-01,  3.63072693e-01,\n",
       "         2.88624913e-01,  1.06503785e+00,  2.64470309e-01,  3.44622195e-01,\n",
       "         2.50147045e-01, -8.69228244e-01,  5.86635888e-01, -4.59057719e-01,\n",
       "         6.87978745e-01, -5.53636700e-02, -1.09345671e-02, -1.10852587e+00,\n",
       "        -4.71376956e-01,  5.09502292e-01,  9.32213664e-03,  4.71476018e-02,\n",
       "         5.36784649e-01, -4.82305586e-01, -3.84086728e-01, -1.36954498e+00,\n",
       "        -5.18550217e-01, -2.89783806e-01, -9.20367986e-02,  3.04065943e-01,\n",
       "        -9.05012727e-01, -5.13753355e-01,  8.35149527e-01, -7.96236098e-02,\n",
       "         5.19217968e-01,  1.97821483e-01, -6.70642257e-01, -8.56358767e-01,\n",
       "        -1.00347602e+00,  5.20205319e-01, -6.29588068e-01, -3.08969021e-02,\n",
       "        -1.00828841e-01, -9.99526531e-02,  1.25642449e-01, -1.46111712e-01,\n",
       "        -3.95213079e+00, -5.25397897e-01,  1.43437669e-01,  4.93571721e-02,\n",
       "        -4.80449378e-01, -5.54849267e-01, -9.79488641e-02, -1.09667718e-01,\n",
       "        -5.73770404e-01, -7.51899481e-01,  6.27445221e-01, -5.75092621e-02,\n",
       "         1.41073346e-01, -1.38440073e-01,  4.30990189e-01, -4.96673524e-01,\n",
       "        -1.02348991e-01,  1.82227716e-02,  3.07264417e-01,  4.80621219e-01,\n",
       "        -2.62104034e-01, -3.21006060e-01, -3.73663008e-01, -3.96020450e-02,\n",
       "         4.05554205e-01, -1.95615441e-02, -6.19911551e-01, -1.72562078e-02,\n",
       "        -2.86709040e-01,  5.60721397e-01, -1.33862913e+00,  1.20564781e-01,\n",
       "        -2.36533239e-01,  1.32488206e-01,  6.03926897e-01, -3.81820768e-01,\n",
       "         4.13875520e-01, -2.32440725e-01,  2.11600348e-01, -5.30876756e-01,\n",
       "        -5.53086475e-02, -8.77985358e-01, -6.65862113e-02,  5.07217944e-01,\n",
       "         4.49894935e-01, -2.24170223e-01,  1.51661560e-01, -1.23300338e+00,\n",
       "         3.50540072e-01, -6.21982664e-03,  3.50671053e-01,  2.25086451e-01,\n",
       "         1.12879443e+00, -2.13562757e-01, -5.25123626e-03,  5.16018748e-01,\n",
       "        -3.17945421e-01, -4.59630042e-02, -1.70255244e-01, -2.57827133e-01,\n",
       "        -4.31901902e-01, -2.45797485e-01,  9.58642811e-02,  1.23806208e-01,\n",
       "         4.94874954e-01,  9.06290650e-01, -4.75585461e-01, -3.28981221e-01,\n",
       "        -3.37755054e-01,  1.59959078e-01, -2.62733102e-01, -8.48408937e-01,\n",
       "        -1.90710962e-01, -1.26491201e+00, -1.33928752e+00, -4.60093170e-01,\n",
       "        -2.14988023e-01,  4.78662327e-02,  5.11492610e-01, -1.51674700e+00,\n",
       "        -1.54745018e+00, -6.72135130e-03,  6.25270307e-02,  3.37161124e-01,\n",
       "         1.93463713e-01, -5.29379189e-01,  4.43183839e-01,  1.59371316e-01,\n",
       "         5.60198784e-01,  3.86108607e-01,  2.28567153e-01,  7.06595242e-01,\n",
       "         6.66201472e-01,  4.43293434e-03, -1.21234953e-01,  3.96951824e-01,\n",
       "        -2.92381227e-01, -4.75704610e-01,  9.78828669e-01,  1.20711535e-01,\n",
       "        -8.56677175e-01,  8.55489373e-02,  3.66253257e-01,  3.90618145e-01,\n",
       "        -3.38230878e-01, -2.46941984e-01, -2.59596258e-01,  1.85350478e-02,\n",
       "        -5.34188710e-02, -3.10299426e-01, -6.91193417e-02,  5.24091125e-02,\n",
       "         4.47001100e-01, -4.15190220e-01,  3.68108034e-01, -2.76544541e-01,\n",
       "        -3.06383103e-01,  3.40927005e-01, -1.56238094e-01, -4.73533660e-01,\n",
       "         1.43101513e-01, -7.49413995e-03, -4.93066907e-01,  3.02103069e-02,\n",
       "        -6.16620898e-01,  2.82230198e-01, -9.60098431e-02,  4.36817944e-01,\n",
       "        -6.81336164e-01, -1.27462909e-01, -4.87617910e-01, -3.95072252e-01,\n",
       "         8.22223961e-01, -7.53041804e-01,  9.85673487e-01,  7.68509090e-01,\n",
       "        -3.29789251e-01, -1.02364886e+00, -5.79365373e-01,  1.83259442e-01,\n",
       "         1.45596281e-01,  4.94829416e-01, -9.24717709e-02,  3.19448918e-01,\n",
       "        -4.51474972e-02,  2.87747979e-01, -3.62212956e-03,  4.96212035e-01,\n",
       "        -2.79398352e-01,  6.61374867e-01,  2.98013985e-01,  1.59397528e-01,\n",
       "         9.48109329e-01, -5.03635645e-01, -3.62408221e-01,  8.14594254e-02,\n",
       "         7.30694711e-01, -1.98638842e-01, -1.27079427e-01, -4.14709032e-01,\n",
       "        -4.48310114e-02,  7.77590275e-03,  4.53569889e-01,  5.20438999e-02,\n",
       "         6.06447697e-01,  3.54734540e-01,  3.43151093e-01,  1.60717353e-01,\n",
       "        -7.72864372e-02,  3.61653090e-01,  9.56764519e-01,  4.14857864e-02,\n",
       "        -4.53950390e-02, -6.75003290e-01,  1.31973736e-02,  1.72566995e-01,\n",
       "        -1.49453655e-01,  3.17687571e-01,  1.89447120e-01,  3.03417444e-01,\n",
       "         7.77051523e-02, -3.33750248e-01,  3.49269032e-01,  3.09707075e-01,\n",
       "         1.46027222e-01,  4.13782626e-01, -9.96117175e-01, -3.17451566e-01,\n",
       "         1.49817929e-01, -4.02370811e-01, -8.70385528e-01,  5.99253833e-01,\n",
       "         1.78482249e-01, -4.75719750e-01, -5.00490189e-01, -8.02078009e-01,\n",
       "         2.81264752e-01, -6.64690197e-01,  6.47020042e-01,  4.04078186e-01,\n",
       "        -1.92334563e-01, -4.98541266e-01, -2.07113683e-01,  6.49021208e-01,\n",
       "        -6.18775725e-01,  5.47685176e-02,  1.29825020e+00,  4.30360138e-01,\n",
       "        -1.20772719e+00,  6.44251585e-01, -4.14507389e-01, -5.71669519e-01,\n",
       "        -2.56542135e-02,  2.64372230e-01, -4.87091154e-01, -1.22420937e-02,\n",
       "         4.78014529e-01, -8.11872125e-01, -6.34499550e-01,  2.16086611e-01,\n",
       "        -1.03450727e+00,  9.71760377e-02,  7.25627422e-01, -3.65860581e-01,\n",
       "         1.43341292e-02, -2.98761502e-02,  8.20855439e-01, -6.25774637e-03,\n",
       "        -3.60159427e-01, -1.31342530e-01,  1.23686463e-01, -1.40885741e-01,\n",
       "         2.46425986e-01, -2.74631321e-01,  3.44924390e-01,  4.50844139e-01,\n",
       "        -6.90096244e-02, -7.18893781e-02,  4.94801641e-01,  1.26283169e-01,\n",
       "         1.22368135e-01, -7.43272841e-01, -1.07483134e-01,  6.51435375e-01,\n",
       "         1.61434710e-02,  8.69831204e-01, -8.48359108e-01, -7.81507045e-03,\n",
       "        -3.41260374e-01,  4.60203797e-01,  1.61543816e-01, -8.44565034e-02,\n",
       "        -3.73557121e-01, -1.42157793e+00,  8.26487184e-01,  2.48556852e-01,\n",
       "         5.50683856e-01,  1.29658595e-01,  1.85560226e-01,  4.79616851e-01,\n",
       "        -5.74342310e-01,  3.78482528e-02,  2.29111671e-01, -5.85877299e-01,\n",
       "        -7.50357985e-01,  4.49688047e-01,  3.35620373e-01,  1.06476462e+00,\n",
       "        -5.26028812e-01,  3.56985442e-02,  8.08200359e-01, -4.08785716e-02,\n",
       "        -7.29654729e-02, -7.79773891e-01,  1.02502182e-01, -3.02050829e-01,\n",
       "         6.84947848e-01, -2.35195503e-01, -3.37488532e-01,  1.10442221e+00,\n",
       "         2.30300397e-01,  8.12478960e-01,  4.98995394e-01, -8.03835243e-02,\n",
       "        -2.39828214e-01,  7.65312687e-02, -5.40528297e-01,  7.11157918e-05,\n",
       "         2.51067102e-01,  8.68289232e-01,  1.80132359e-01, -3.01228791e-01,\n",
       "         5.82635328e-02, -1.60582334e-01, -9.81493711e-01, -1.00273326e-01,\n",
       "        -4.85950336e-02, -1.60831228e-01,  8.37923512e-02, -1.03403283e-02,\n",
       "        -2.80038178e-01,  2.32043713e-01, -1.37926206e-01,  2.03567162e-01,\n",
       "        -4.93666410e-01,  3.08822274e-01,  6.84312344e-01, -8.05197418e-01,\n",
       "        -3.37412983e-01, -4.70527261e-01, -2.64968127e-01,  1.40531808e-01,\n",
       "        -4.31490093e-01,  4.42270726e-01, -6.97714239e-02, -1.85375631e-01,\n",
       "         6.22703195e-01, -4.84035835e-02, -8.49577785e-03,  6.07563257e-01,\n",
       "         7.46733606e-01, -2.20725805e-01, -4.50829387e-01, -4.28743988e-01,\n",
       "         2.05687627e-01,  5.69385290e-01, -2.48368949e-01, -1.97297260e-02,\n",
       "         7.03114569e-01,  7.22700357e-01,  2.30472028e-01,  1.34461254e-01,\n",
       "        -3.74066770e-01,  6.12524152e-01, -3.58252436e-01, -6.69300616e-01,\n",
       "        -6.89802766e-01, -2.88129508e-01, -2.07769752e-01,  5.32999158e-01,\n",
       "         3.75001758e-01, -4.52816039e-02,  1.07070434e+00,  3.65983069e-01,\n",
       "        -5.38255334e-01,  6.75377250e-01, -2.21179388e-02, -1.10068507e-02,\n",
       "        -1.59585193e-01, -6.65531039e-01,  4.27614480e-01,  1.02653742e+00,\n",
       "         4.09425646e-01, -5.99786401e-01,  3.60405475e-01,  3.79708767e-01,\n",
       "         2.37928212e-01,  4.03416306e-01,  1.66057423e-02, -2.02170038e+00,\n",
       "        -1.34522244e-01,  2.21584916e-01,  2.10774347e-01, -3.22869480e-01,\n",
       "         5.29484689e-01,  7.70649791e-01, -2.47878104e-01,  3.51262957e-01,\n",
       "        -3.96579802e-02,  4.01101381e-01, -2.80502230e-01, -6.84285462e-01,\n",
       "        -2.09087238e-01, -8.99544656e-01,  1.70546755e-01,  2.93494821e-01,\n",
       "         1.07199065e-01, -3.85636300e-01,  6.56895220e-01,  6.13290183e-02,\n",
       "         3.44922364e-01,  6.04695901e-02, -4.22223181e-01, -4.80754882e-01,\n",
       "        -1.24892192e-02, -6.20496094e-01,  5.02531379e-02, -3.46718878e-01,\n",
       "        -1.31709442e-01,  2.17449665e-01,  5.77013373e-01, -6.40615821e-01,\n",
       "        -5.89236617e-03, -3.28262806e-01,  3.05111200e-01, -4.43256468e-01,\n",
       "         4.80441570e-01, -4.14032936e-02, -4.90098447e-01, -6.16909444e-01,\n",
       "         1.15519845e+00,  7.08413005e-01, -3.74300122e-01,  2.84617841e-01,\n",
       "         1.07591622e-01,  4.60906267e-01, -5.60863376e-01,  8.78949583e-01,\n",
       "        -4.10235643e-01, -1.25618231e+00, -1.39050871e-01,  9.64395285e-01,\n",
       "        -2.25889802e-01,  5.39581068e-02,  7.17261851e-01, -2.65794754e-01,\n",
       "         5.16971827e-01, -1.44290417e-01, -5.12939692e-01,  7.21190333e-01,\n",
       "        -3.98012936e-01, -4.09400642e-01, -8.81574303e-03,  7.35169947e-01,\n",
       "        -2.43955180e-01, -8.90958011e-01, -7.75430351e-02,  4.08763856e-01,\n",
       "         3.83813322e-01, -1.72800720e-01, -3.20142210e-01,  2.86174893e-01,\n",
       "         3.97953808e-01,  1.79139346e-01, -4.99484688e-03,  1.30448595e-01,\n",
       "         4.33104634e-01, -1.00332163e-01,  3.95814121e-01, -2.55903155e-01,\n",
       "        -2.08761506e-02, -2.76826732e-02, -9.06615198e-01, -3.87795478e-01,\n",
       "        -3.83033848e+00, -2.57436149e-02, -4.15508330e-01, -3.71796459e-01,\n",
       "         1.02663159e+00, -6.99206963e-02,  5.28894901e-01, -5.40772915e-01,\n",
       "         9.33461785e-01, -8.14782977e-01, -2.96717197e-01,  3.91422838e-01,\n",
       "         8.35669339e-02, -3.95796537e-01,  9.70783830e-01,  6.29009604e-01],\n",
       "       dtype=float32),\n",
       " array([ 6.03828311e-01,  5.11986792e-01,  3.65849137e-01,  3.99374604e-01,\n",
       "         5.20902455e-01, -1.88618302e-02,  1.98837250e-01,  7.64901564e-03,\n",
       "        -4.71703112e-01,  5.36919117e-01,  1.06440589e-01, -5.07377326e-01,\n",
       "         6.33124232e-01,  5.86148381e-01,  1.58375651e-01,  1.01167297e+00,\n",
       "         3.73917311e-01, -3.13901931e-01, -5.95026016e-01, -1.42140195e-01,\n",
       "         1.49484277e-01, -5.77520072e-01, -9.48879793e-02,  6.19325101e-01,\n",
       "         9.31778014e-01, -4.01282728e-01,  4.82091278e-01, -1.14052914e-01,\n",
       "        -7.87338540e-02, -1.13037556e-01,  4.88698006e-01,  1.25378996e-01,\n",
       "        -4.29160804e-01, -3.50690149e-02, -9.67849135e-01, -6.53475821e-01,\n",
       "        -2.03692555e-01, -3.35840940e-01, -4.41927277e-02, -2.73964524e-01,\n",
       "         1.59428522e-01, -5.67251921e-01,  4.41577025e-02,  2.23052263e-01,\n",
       "        -2.24681437e-01, -4.30339515e-01, -2.28162184e-01,  6.49375141e-01,\n",
       "         6.33161426e-01, -3.47120792e-01,  2.95879319e-03,  6.77417040e-01,\n",
       "        -2.09506303e-02, -2.91894644e-01, -6.83867186e-02,  4.13120270e-01,\n",
       "        -1.07153404e+00, -4.45738435e-01, -8.63873139e-02, -1.80861935e-01,\n",
       "        -5.10891199e-01, -4.69470263e-01,  3.69652808e-02, -6.58730567e-02,\n",
       "         2.04485387e-01,  1.16245496e+00,  2.37314060e-01,  1.41577139e-01,\n",
       "         2.20725864e-01, -2.52624936e-02, -1.42535701e-01, -8.95738065e-01,\n",
       "         5.58097959e-01, -1.60849750e-01, -7.34417617e-01, -2.53426015e-01,\n",
       "        -1.55405551e-01,  8.50169733e-02, -2.39454091e-01,  5.42686224e-01,\n",
       "        -8.29989254e-01,  3.43507528e-01,  5.27304292e-01,  4.64015841e-01,\n",
       "         2.31354311e-03,  2.69067645e-01, -4.33975071e-01,  5.32768250e-01,\n",
       "         2.82417327e-01,  2.45543391e-01,  1.71408042e-01, -7.13998079e-02,\n",
       "         2.01722071e-01, -2.72820573e-02,  5.05072653e-01, -4.18891788e-01,\n",
       "        -5.79592705e-01, -1.12884760e-01, -7.83409774e-01, -4.65178825e-02,\n",
       "         5.78448832e-01, -4.42393631e-01,  2.18930230e-01, -1.63922921e-01,\n",
       "        -2.22440600e-01,  9.74278748e-02,  3.48157346e-01,  8.32927376e-02,\n",
       "         8.66214395e-01,  1.04516661e+00, -1.00416411e-02,  3.66280489e-02,\n",
       "        -1.84548676e-01, -5.17885029e-01, -1.13527966e+00, -1.43451571e-01,\n",
       "         4.88955081e-01,  4.32985574e-01, -2.49584883e-01, -3.56484652e-01,\n",
       "         1.64670289e-01, -4.82735336e-01,  4.29238945e-01,  9.00089502e-01,\n",
       "         4.69969571e-01, -6.90403879e-01, -5.03931284e-01, -7.31634274e-02,\n",
       "        -2.21805826e-01, -1.28134936e-02,  6.26566261e-02, -1.07151955e-01,\n",
       "        -2.03000098e-01, -4.14955616e-01, -4.30367172e-01,  4.91441905e-01,\n",
       "        -2.07113296e-01, -6.56693578e-01, -3.25968504e-01,  1.19089141e-01,\n",
       "        -1.68839898e-02,  8.32317472e-01, -3.05599183e-01,  2.95855075e-01,\n",
       "        -2.64587373e-01,  1.03310347e-02, -1.39404520e-01,  5.54278970e-01,\n",
       "        -3.80689353e-01, -3.06047499e-01,  4.31233704e-01,  1.14350103e-01,\n",
       "        -5.40423870e-01, -1.13547301e+00,  3.51984620e-01,  6.72774792e-01,\n",
       "         5.68578318e-02, -5.24225086e-03,  5.54776609e-01, -6.44263148e-01,\n",
       "        -1.03319633e+00,  6.95150375e-01, -1.24997590e-02,  5.69663823e-01,\n",
       "        -3.88886213e-01,  1.22497998e-01,  1.09076798e-01,  1.29259312e+00,\n",
       "        -3.92917454e-01,  3.92223060e-01, -2.49762125e-02, -6.55910790e-01,\n",
       "         3.31792355e-01,  7.05188096e-01, -7.98608124e-01, -1.60295218e-01,\n",
       "         6.53672993e-01,  1.29914016e-01,  3.49143893e-01,  1.77014440e-01,\n",
       "        -6.68164492e-02,  3.32466047e-03,  7.96960741e-02, -5.84483862e-01,\n",
       "         4.32675123e-01,  9.17640626e-02,  1.31734145e+00,  9.41757187e-02,\n",
       "        -4.43309218e-01,  4.60947663e-01,  1.32899642e-01,  4.59239185e-01,\n",
       "         3.55970830e-01, -3.56222451e-01, -4.53681089e-02,  8.43130648e-02,\n",
       "         9.76903439e-02,  2.10749447e-01, -3.84692326e-02,  1.64188057e-01,\n",
       "         5.82015693e-01,  1.80184647e-01, -7.10674971e-02, -3.39056790e-01,\n",
       "        -4.87036884e-01, -6.14774823e-02,  2.00545058e-01,  1.41939968e-02,\n",
       "        -3.35277021e-01,  2.47838080e-01, -7.48304948e-02,  3.38197947e-01,\n",
       "         1.18807185e+00, -3.51285458e-01,  5.73950410e-01, -2.81396925e-01,\n",
       "         1.20445356e-01, -1.32174656e-01,  3.56002629e-01, -5.11035442e-01,\n",
       "         1.61519602e-01, -1.58484012e-01,  3.72039407e-01,  8.16808790e-02,\n",
       "        -2.63363600e-01,  7.52457500e-01,  4.35851216e-01, -5.59673846e-01,\n",
       "        -1.47014186e-01,  7.58419037e-01, -6.79767787e-01, -1.21827573e-01,\n",
       "         1.64860159e-01, -5.31416059e-01,  1.18892379e-01,  2.84043968e-01,\n",
       "        -7.95872211e-02,  4.06303436e-01,  1.08573273e-01,  1.61636576e-01,\n",
       "        -4.54406202e-01, -7.79598951e-02,  8.94477904e-01,  6.37275219e-01,\n",
       "        -6.09353364e-01,  5.55049837e-01, -2.21292481e-01, -2.47955129e-01,\n",
       "        -2.38441288e-01,  9.25268978e-03, -1.15198448e-01, -2.37654418e-01,\n",
       "        -3.23108375e-01, -6.06041908e-01,  2.95912206e-01, -1.54030114e-01,\n",
       "        -3.41998637e-01,  2.59508848e-01, -1.41723454e-01,  3.05632025e-01,\n",
       "         2.16355503e-01, -4.56683308e-01,  1.81149006e-01, -7.16814160e-01,\n",
       "        -3.63908261e-01, -5.19156098e-01, -6.19008005e-01,  1.86151266e-01,\n",
       "        -3.41528058e-01,  7.74196804e-01, -4.55509603e-01,  2.46443544e-02,\n",
       "        -3.34711298e-02,  6.83866858e-01, -9.84168053e-02, -5.63871145e-01,\n",
       "         3.57276142e-01, -7.52208661e-03,  1.38116032e-01, -1.29085767e+00,\n",
       "        -1.20033637e-01,  7.10017323e-01, -4.19450432e-01, -3.78781885e-01,\n",
       "         7.37056255e-01, -5.63561097e-02, -5.00968575e-01, -2.07826599e-01,\n",
       "        -3.97716016e-01, -1.20363247e+00, -6.69956058e-02, -2.00167596e-01,\n",
       "        -8.37503612e-01, -1.94751889e-01,  5.67636430e-01,  3.60445887e-01,\n",
       "         5.64422980e-02,  4.80874211e-01, -3.05432320e-01, -4.58003014e-01,\n",
       "         4.11287248e-01,  1.01493262e-01,  2.13341042e-01, -1.77763909e-01,\n",
       "         2.91058064e-01, -3.99398580e-02, -3.34064513e-01, -5.89299321e-01,\n",
       "        -4.97150993e+00, -4.75190192e-01,  2.81483382e-01,  2.55428314e-01,\n",
       "        -2.82303244e-01,  1.86412692e-01, -4.03892875e-01, -3.74490529e-01,\n",
       "        -2.66708910e-01,  1.57504141e-01,  4.63688672e-01,  1.13791198e-01,\n",
       "        -3.33726257e-01, -1.25243023e-01, -2.45799109e-01, -4.32247639e-01,\n",
       "        -1.54886574e-01, -3.25411350e-01,  3.53015900e-01,  9.20692742e-01,\n",
       "        -6.23164058e-01, -4.91239995e-01,  3.41721416e-01, -3.52367014e-01,\n",
       "         7.21121073e-01,  2.02117234e-01,  1.05483055e-01,  4.18263942e-01,\n",
       "        -3.51600707e-01,  5.08349776e-01, -1.22424698e+00, -5.57489812e-01,\n",
       "         2.96604276e-01,  8.73899519e-01,  5.33213973e-01, -3.90027195e-01,\n",
       "         6.25789046e-01, -2.24436864e-01, -1.42283946e-01, -3.71245950e-01,\n",
       "        -1.94796339e-01, -4.23578054e-01,  1.53955147e-02,  5.88707030e-01,\n",
       "         6.26889825e-01, -8.60678554e-01,  1.85328066e-01, -3.50759029e-01,\n",
       "         6.23333275e-01,  2.40221754e-01, -2.71442495e-02,  4.66072261e-01,\n",
       "         1.93148106e-03, -3.75303447e-01, -3.48194063e-01,  2.71467865e-01,\n",
       "        -1.28111765e-01,  5.08907557e-01, -4.88632649e-01,  4.52570140e-01,\n",
       "        -2.99546361e-01, -1.77368268e-01, -2.34693080e-01,  7.63087496e-02,\n",
       "         9.42658961e-01,  6.12338006e-01, -9.84563679e-02, -7.43612945e-01,\n",
       "        -3.69250298e-01,  1.68807209e-01, -2.71624744e-01, -4.16430607e-02,\n",
       "         1.46946326e-01, -9.69522595e-01, -5.55022418e-01, -5.18323660e-01,\n",
       "        -7.98940212e-02, -2.45505929e-01,  5.47427297e-01, -6.14795387e-01,\n",
       "        -5.62716663e-01, -6.16491258e-01,  4.67575908e-01,  8.49448144e-01,\n",
       "         3.47041190e-01, -1.01783061e+00,  6.48858070e-01, -2.71865577e-01,\n",
       "         6.94284141e-02,  1.74234226e-01,  3.34124535e-01,  2.95129240e-01,\n",
       "         4.69844520e-01, -1.65770516e-01, -3.00529033e-01,  3.45029011e-02,\n",
       "         1.94782913e-01, -6.74768537e-03,  9.36283469e-01, -3.07428718e-01,\n",
       "        -9.50032115e-01, -4.04249102e-01, -3.97690013e-02,  3.84222269e-01,\n",
       "        -3.22016299e-01,  1.24002434e-03, -2.35034198e-01, -7.70327389e-01,\n",
       "         7.37268180e-02, -1.96736217e-01, -1.57536015e-01, -2.77115226e-01,\n",
       "        -5.06523661e-02,  1.17269710e-01,  1.48445815e-01, -5.94249308e-01,\n",
       "        -1.34774446e-01,  5.38864255e-01,  3.16425622e-01, -2.34474286e-01,\n",
       "         4.04997110e-01,  6.86602950e-01, -2.57490516e-01, -2.43263487e-02,\n",
       "        -3.14798892e-01, -1.01497889e-01, -3.44984531e-02,  3.44988823e-01,\n",
       "        -4.83116627e-01, -3.33630025e-01, -4.46335912e-01, -9.72094178e-01,\n",
       "         1.44478112e-01, -1.89198375e-01,  7.73517728e-01,  1.04404652e+00,\n",
       "        -4.55709249e-01, -1.14192200e+00,  2.16250062e-01,  3.36382031e-01,\n",
       "         6.77991882e-02,  6.26509666e-01, -6.63523376e-01,  4.21480507e-01,\n",
       "        -4.27302927e-01,  1.60290599e-01, -6.10426307e-01,  1.95774972e-01,\n",
       "        -6.04313731e-01,  1.30284846e-01,  2.92935818e-01, -3.47509146e-01,\n",
       "         6.89969301e-01, -3.77885252e-01, -4.78640616e-01, -2.83433080e-01,\n",
       "         9.95609283e-01,  1.38992965e-01, -4.33696866e-01, -4.34289664e-01,\n",
       "        -8.08059871e-02,  8.04596767e-02,  1.13825709e-01,  3.18021685e-01,\n",
       "         2.43954778e-01,  7.41604924e-01, -5.23582220e-01, -1.91423059e-01,\n",
       "        -2.86404788e-01,  7.91498899e-01,  4.68022525e-01,  1.94281399e-01,\n",
       "        -7.84550786e-01,  1.95760623e-01,  1.88650832e-01,  1.08067858e+00,\n",
       "        -3.32540512e-01,  1.26376867e-01,  3.15501034e-01,  1.30167663e+00,\n",
       "         1.60142317e-01, -6.90050781e-01,  4.15204108e-01,  8.71490359e-01,\n",
       "         5.73540866e-01,  5.73462486e-01, -5.83590627e-01, -3.23997080e-01,\n",
       "        -8.88345465e-02, -1.62353516e-01, -7.72664487e-01,  7.98569858e-01,\n",
       "        -9.59145725e-02, -6.41432106e-01, -7.99281836e-01, -3.42691064e-01,\n",
       "         2.84688294e-01, -5.81823945e-01,  2.17350125e-01, -1.18881047e-01,\n",
       "         3.27431262e-01,  5.51600397e-01,  3.00485045e-02, -2.35497281e-02,\n",
       "        -1.40498728e-01, -6.30829453e-01,  1.01672006e+00,  9.76320654e-02,\n",
       "        -5.91004431e-01,  3.80962372e-01, -2.10092187e-01, -5.50349653e-01,\n",
       "         7.95410395e-01, -7.91488364e-02, -4.38756734e-01, -1.87753856e-01,\n",
       "         2.37483144e-01, -7.68801808e-01, -6.80690408e-01,  6.68507278e-01,\n",
       "        -6.96027935e-01,  1.62539005e-01,  7.31430888e-01, -4.63986188e-01,\n",
       "        -4.44278061e-01, -5.30059874e-01,  8.10562253e-01,  1.56739593e-01,\n",
       "         2.22915486e-01,  2.19418675e-01, -3.03474903e-01,  8.20921957e-02,\n",
       "        -1.48994233e-02, -9.95179772e-01,  7.39512742e-02,  3.37814301e-01,\n",
       "         1.22494623e-01,  1.86457895e-02,  3.49732816e-01, -2.61093616e-01,\n",
       "        -1.68829560e-01, -4.55690563e-01,  3.15337270e-01,  2.47364193e-01,\n",
       "         1.50781006e-01,  8.40688050e-01, -5.58895528e-01, -1.08291514e-01,\n",
       "        -6.00158155e-01, -1.50501102e-01, -4.67326045e-01,  2.56564736e-01,\n",
       "         1.44046277e-01, -8.24477792e-01,  6.63399339e-01, -1.15471199e-01,\n",
       "         6.12278581e-01, -2.71340579e-01, -2.55140930e-01,  8.18894267e-01,\n",
       "         1.27063483e-01,  1.62179217e-01,  3.96392316e-01,  3.03015001e-02,\n",
       "        -3.60304236e-01,  2.50283331e-01,  6.10692084e-01,  4.76774037e-01,\n",
       "        -4.04215455e-01, -6.08099878e-01,  2.09964871e-01,  1.09782827e+00,\n",
       "        -1.41752958e-01,  1.68192938e-01,  2.41600350e-03, -7.05829412e-02,\n",
       "        -1.14083104e-03, -6.75195575e-01,  6.09528244e-01, -2.98303843e-01,\n",
       "        -9.38891590e-01,  5.63122153e-01, -4.89336014e-01, -1.82221398e-01,\n",
       "        -2.35568471e-02,  3.07413131e-01, -4.55026507e-01, -2.76759237e-01,\n",
       "         3.26330476e-02,  1.99730545e-01,  6.36519730e-01, -4.95393723e-02,\n",
       "         1.30860567e-01, -6.79068804e-01, -6.89482629e-01, -1.10425480e-01,\n",
       "        -1.86240733e-01, -1.41254619e-01,  1.25921392e+00,  2.42233798e-01,\n",
       "        -3.41746688e-01, -1.84189491e-02, -4.51154590e-01,  3.13591003e-01,\n",
       "        -3.84246439e-01,  6.93156600e-01,  4.54111636e-01, -7.08113670e-01,\n",
       "        -6.43196881e-01,  5.70177622e-02,  2.87524939e-01,  1.70084760e-02,\n",
       "        -1.55369654e-01,  4.56388265e-01, -7.62214720e-01,  3.85550499e-01,\n",
       "         9.84905005e-01, -3.75874043e-01, -5.14288135e-02,  1.04287088e+00,\n",
       "         1.03414166e+00, -4.00829971e-01, -5.42438567e-01, -6.29949197e-02,\n",
       "        -7.76952207e-02,  5.60660124e-01, -2.91671455e-01, -1.06537253e-01,\n",
       "         7.50339985e-01,  8.37748706e-01,  1.53257787e-01, -7.28724003e-01,\n",
       "        -5.88129163e-01,  6.00247800e-01, -2.26329677e-02, -1.14776425e-01,\n",
       "         2.03325525e-01,  6.05519116e-01, -1.73593760e-01,  8.74155164e-01,\n",
       "         2.34414846e-01,  1.32839084e-01,  1.74224734e-01, -9.20059234e-02,\n",
       "        -6.45089209e-01,  3.94735575e-01,  6.07297838e-01, -4.13345516e-01,\n",
       "        -5.61013043e-01, -3.82027656e-01,  3.30743134e-01,  6.69924140e-01,\n",
       "         5.97444057e-01, -4.74901088e-02,  3.06195378e-01,  3.74994069e-01,\n",
       "        -4.62338120e-01,  3.30212206e-01,  2.84721643e-01,  2.73897111e-01,\n",
       "        -4.05872345e-01,  3.01218510e-01, -1.20926434e-02,  1.83501333e-01,\n",
       "        -4.35841531e-02,  6.76155090e-01, -3.25105250e-01,  3.15107167e-01,\n",
       "        -7.60059059e-01,  4.11832899e-01, -3.97884473e-03, -3.47636938e-01,\n",
       "        -4.49675649e-01, -5.81080973e-01, -3.25364619e-02, -1.99873045e-01,\n",
       "         1.66533083e-01, -6.05117440e-01,  2.03334257e-01,  5.84066175e-02,\n",
       "        -5.29274791e-02,  1.08176991e-02, -1.87314972e-01,  3.97055477e-01,\n",
       "        -8.51403028e-02, -1.72290951e-01,  3.96737874e-01, -3.55318546e-01,\n",
       "         5.73386997e-03,  2.97752172e-02,  5.20145416e-01, -5.56983352e-01,\n",
       "        -8.67611393e-02,  5.38074255e-01,  9.98728797e-02, -2.61168927e-01,\n",
       "         3.83118570e-01, -4.06156838e-01, -1.91672333e-03, -8.59597698e-02,\n",
       "         3.48801047e-01,  4.85030651e-01, -8.03007126e-01,  3.17811847e-01,\n",
       "        -6.68763041e-01,  3.49450350e-01, -4.69850659e-01,  1.51960403e-01,\n",
       "        -3.23813379e-01, -6.49946094e-01, -8.79374146e-01,  6.30073547e-01,\n",
       "        -5.52664042e-01, -1.56651556e-01, -2.10265785e-01, -3.84639204e-03,\n",
       "        -4.39744592e-02, -3.16662759e-01, -5.63544407e-02,  5.94114840e-01,\n",
       "        -7.67796755e-01,  4.27198768e-01, -2.84192234e-01,  5.81906259e-01,\n",
       "        -1.02669746e-02, -2.35628411e-01, -9.36665609e-02,  7.31710494e-02,\n",
       "        -8.46973777e-01,  2.53252625e-01, -3.26049775e-01,  3.61078620e-01,\n",
       "        -5.18969335e-02,  2.35277683e-01,  6.23645708e-02,  2.02723920e-01,\n",
       "         9.05127525e-02,  2.48625979e-01,  3.54102433e-01, -1.40023120e-02,\n",
       "        -1.54335648e-01,  5.19822121e-01, -8.45109880e-01,  7.72758365e-01,\n",
       "        -1.51767313e-01, -1.58603132e-01, -9.66189981e-01, -6.00172341e-01,\n",
       "        -7.94713423e-02, -5.02042115e-01,  4.73133653e-01, -1.22262575e-01,\n",
       "         1.23820089e-01, -6.65107965e-01, -2.87225395e-01,  3.72120254e-02,\n",
       "         8.73086751e-02, -7.29753792e-01,  4.18849409e-01, -3.06134284e-01],\n",
       "       dtype=float32),\n",
       " array([-1.44296642e-02,  1.48857981e-01,  2.55931765e-02,  3.42420936e-01,\n",
       "         1.04909427e-01,  1.04652822e-01,  2.59134203e-01,  3.05366255e-02,\n",
       "        -1.12826258e-01, -7.46195674e-01, -2.17150211e-01, -2.77455240e-01,\n",
       "         1.50572747e-01,  7.98620641e-01, -9.12543312e-02,  3.80044758e-01,\n",
       "         6.37153208e-01,  4.80081052e-01,  3.45003664e-01,  2.34817132e-01,\n",
       "        -1.62926078e-01, -1.56921849e-01,  1.71191290e-01,  4.02845442e-04,\n",
       "         1.10807812e+00, -1.92769751e-01, -5.25296688e-01,  3.64393264e-01,\n",
       "         1.66398808e-02, -3.60296607e-01,  8.85221601e-01,  5.78882135e-02,\n",
       "        -6.15033433e-02, -1.56848609e-01, -5.99353433e-01, -5.19107342e-01,\n",
       "        -2.63940543e-03, -5.18075466e-01, -6.52690947e-01, -6.28292263e-01,\n",
       "        -3.03368270e-01, -1.24009019e-02, -2.92881846e-01, -1.41179055e-01,\n",
       "        -3.04238528e-01,  2.06500798e-01, -5.61756551e-01, -3.42069902e-02,\n",
       "         1.89667493e-02, -6.91739917e-01, -9.42834973e-01,  6.20977283e-02,\n",
       "         4.90330428e-01, -4.89819199e-02, -4.17080104e-01, -1.03376381e-01,\n",
       "        -4.15023595e-01, -3.80659997e-02, -4.32624668e-01,  5.28615892e-01,\n",
       "        -9.61293340e-01,  3.48368943e-01,  2.82096118e-01, -9.54758227e-02,\n",
       "         5.71963727e-01,  2.78361559e-01, -1.50486439e-01,  6.95112824e-01,\n",
       "         2.42306381e-01, -2.59897679e-01, -7.22297251e-01, -7.10147083e-01,\n",
       "        -8.64731312e-01, -2.15744883e-01, -2.34824181e-01, -3.32858890e-01,\n",
       "         7.31818855e-01,  1.51607171e-02,  1.67840824e-01,  3.12947154e-01,\n",
       "        -2.47720584e-01,  7.02830851e-01, -3.18294652e-02,  4.59568888e-01,\n",
       "         5.29952645e-02,  4.87306774e-01, -2.13702783e-01,  7.70305544e-02,\n",
       "         3.35074514e-01,  2.29101285e-01, -1.22391023e-01, -8.50485936e-02,\n",
       "         4.03478801e-01,  2.04045810e-02, -7.84132838e-01, -1.17849731e+00,\n",
       "        -2.97617465e-01,  1.89072751e-02,  1.23625487e-01, -9.05262351e-01,\n",
       "        -5.92707694e-01, -6.22531533e-01,  2.01647773e-01, -6.19957924e-01,\n",
       "        -1.92476124e-01, -1.10224504e-02, -8.75549912e-02, -3.17032218e-01,\n",
       "        -1.89500973e-01,  2.83007592e-01,  2.46067733e-01,  1.61767930e-01,\n",
       "        -1.29339978e-01,  8.22122216e-01, -3.39192778e-01,  1.15386575e-01,\n",
       "        -7.18171597e-02,  7.43254364e-01,  4.30587441e-01, -9.60124061e-02,\n",
       "        -6.81461319e-02, -3.90568554e-01,  7.05952168e-01,  5.34375489e-01,\n",
       "         6.55151784e-01,  3.07280928e-01,  2.66715705e-01,  7.86012113e-02,\n",
       "        -6.60601020e-01, -1.15569778e-01,  2.08623409e-01, -6.99168369e-02,\n",
       "        -3.67427200e-01, -4.77292508e-01, -7.24861801e-01, -4.61331129e-01,\n",
       "        -1.14677936e-01, -1.70416057e-01, -5.41053832e-01, -2.09901705e-01,\n",
       "        -5.02041519e-01,  5.61711550e-01,  3.22062641e-01,  4.68948126e-01,\n",
       "         3.65007490e-01,  3.44778895e-01, -7.38314241e-02,  1.82062879e-01,\n",
       "        -1.85827315e-01, -7.99842060e-01, -2.42848292e-01,  1.00559521e+00,\n",
       "        -3.32647502e-01, -4.98154879e-01,  2.99586821e-03, -5.08128762e-01,\n",
       "         3.87260504e-02,  2.30338126e-01,  3.98093790e-01, -3.28534126e-01,\n",
       "         2.28016421e-01, -1.29990637e-01, -2.14897349e-01, -3.35214615e-01,\n",
       "        -2.68045932e-01, -2.29929656e-01, -8.25565755e-02,  9.71267343e-01,\n",
       "         2.39075243e-01,  2.36865759e-01, -2.89510846e-01, -4.05712962e-01,\n",
       "         4.71000791e-01,  6.18025422e-01, -5.44465929e-02, -1.10683382e-01,\n",
       "         4.52351332e-01,  1.16224393e-01,  1.10141814e-01, -5.36250770e-01,\n",
       "        -1.19003519e-01,  5.54733157e-01,  7.45367289e-01,  1.64709464e-01,\n",
       "        -6.70799315e-01, -4.98770177e-01, -6.83047712e-01,  4.62391693e-03,\n",
       "        -3.17533106e-01, -1.74784027e-02, -7.39391804e-01,  9.52419996e-01,\n",
       "         5.80313742e-01,  7.86884055e-02, -7.31919557e-02,  1.41511559e-02,\n",
       "         2.61096805e-02,  7.68384188e-02, -7.09135175e-01,  5.24486482e-01,\n",
       "         1.10348666e+00, -2.82321393e-01, -4.24885809e-01,  4.39172208e-01,\n",
       "        -6.52612627e-01,  3.63402665e-01, -1.22346997e-01, -4.31268334e-01,\n",
       "         2.27567375e-01, -6.90190315e-01,  1.28870055e-01,  3.69732916e-01,\n",
       "         5.55388331e-01, -1.43994346e-01,  9.09156352e-02, -2.09760547e-01,\n",
       "         2.95014441e-01, -2.03406319e-01,  4.09029961e-01,  1.19383775e-01,\n",
       "         2.08806545e-01,  4.88525927e-02, -6.35833144e-02,  1.34208158e-01,\n",
       "        -3.63226943e-02,  3.63475457e-02,  2.43036523e-02,  3.61802131e-01,\n",
       "        -2.28160039e-01,  5.04000545e-01, -1.94038808e-01, -6.08654499e-01,\n",
       "        -3.42250794e-01,  9.76518467e-02, -5.89696281e-02,  3.34821343e-01,\n",
       "         1.07966080e-01,  9.66034532e-02,  7.45722294e-01, -8.07549596e-01,\n",
       "        -8.43751431e-03,  8.08725059e-01,  6.14979625e-01,  5.09345174e-01,\n",
       "        -6.38145804e-01,  1.16882063e-02,  1.14149705e-01, -2.10932598e-01,\n",
       "        -3.17347914e-01,  1.74532875e-01, -4.64981556e-01, -9.74450648e-01,\n",
       "        -4.00338113e-01,  8.57222453e-03, -7.10292101e-01, -2.54667044e-01,\n",
       "        -2.89195061e-01,  3.39522570e-01, -1.77251860e-01,  2.03698710e-01,\n",
       "         1.16543166e-01,  3.39963377e-01,  6.96787953e-01, -1.05118835e+00,\n",
       "        -7.04139292e-01, -2.48559386e-01, -3.86099577e-01, -2.79069304e-01,\n",
       "         5.08848310e-01,  7.08354652e-01,  3.80317509e-01, -1.81418285e-01,\n",
       "         3.86424005e-01,  8.77988338e-01,  1.28404796e-01, -2.27845728e-01,\n",
       "         2.09469795e-01,  1.59960970e-01, -8.82987231e-02, -1.95209473e-01,\n",
       "         4.29875076e-01,  4.28167939e-01, -1.03730068e-01, -7.15987802e-01,\n",
       "        -1.64060369e-02, -5.63168287e-01,  5.74248910e-01, -9.33920264e-01,\n",
       "        -2.56385535e-01,  3.27375203e-01,  9.71477572e-03, -1.65172815e-02,\n",
       "        -1.44695982e-01,  1.78632692e-01,  8.23264718e-01,  1.84180617e-01,\n",
       "         4.58776891e-01, -2.12355405e-01, -4.65676785e-01,  3.63069296e-01,\n",
       "         7.78565183e-02,  2.96972916e-02, -2.87967712e-01, -1.76228374e-01,\n",
       "        -2.41618559e-01, -1.44106150e-01,  2.29450181e-01, -8.70918810e-01,\n",
       "        -5.35628557e+00,  1.90331414e-01, -8.74167755e-02, -4.53386009e-02,\n",
       "         3.83989602e-01, -3.69720310e-01, -1.12770990e-01, -1.29998803e-01,\n",
       "        -1.85103089e-01,  4.26958650e-01, -3.36983681e-01,  7.01861084e-02,\n",
       "         3.52058172e-01, -1.84137031e-01,  4.89824444e-01,  5.44270456e-01,\n",
       "         8.19037482e-02, -5.94460309e-01, -4.36446443e-03,  2.65149355e-01,\n",
       "         1.48124710e-01, -1.85496911e-01,  3.27492148e-01, -4.08736914e-01,\n",
       "         1.73164636e-01,  2.15869725e-01,  3.43742907e-01,  1.52888999e-03,\n",
       "        -5.83585143e-01, -2.29769289e-01, -5.28131843e-01, -6.78517699e-01,\n",
       "        -3.98523420e-01,  7.22972572e-01,  1.71966955e-01, -1.66887820e-01,\n",
       "         5.61495662e-01, -2.37428486e-01,  2.06047386e-01,  4.68340993e-01,\n",
       "        -1.09449394e-01, -1.02594979e-01,  6.00329161e-01, -5.57717793e-02,\n",
       "         3.43536809e-02, -3.66434574e-01,  1.12547360e-01,  2.49278799e-01,\n",
       "         1.47531569e-01, -1.12131000e+00,  5.73367998e-02, -5.36699919e-03,\n",
       "         3.42640549e-01, -5.11921585e-01, -7.00445414e-01,  3.21241349e-01,\n",
       "         5.09519428e-02,  5.48730604e-02, -3.93156588e-01,  7.47804269e-02,\n",
       "        -3.70989442e-01,  7.55020278e-03,  4.88349423e-02,  2.08648250e-01,\n",
       "         3.63290012e-01,  4.31043148e-01,  4.92029339e-02, -1.08967233e+00,\n",
       "        -1.34320091e-03,  4.87733424e-01,  2.13768780e-01, -3.90306443e-01,\n",
       "         9.23082232e-04, -7.60254800e-01, -2.47020856e-01, -5.85828364e-01,\n",
       "        -3.83791000e-01,  3.43857288e-01,  6.86858058e-01,  2.33043715e-01,\n",
       "        -6.26440287e-01, -6.86799765e-01, -5.38836867e-02,  2.99912512e-01,\n",
       "         1.29975930e-01, -7.94354796e-01,  1.69018447e-01,  2.96926528e-01,\n",
       "         2.27317184e-01, -3.73727754e-02,  6.64721668e-01,  5.77245235e-01,\n",
       "         4.22697276e-01, -3.44702393e-01, -1.22046500e-01,  4.91463542e-01,\n",
       "        -7.54822716e-02,  4.24146920e-01,  3.57991159e-01, -3.96417975e-01,\n",
       "        -1.17418997e-01, -2.20325679e-01,  1.32182598e-01,  7.31843710e-01,\n",
       "         1.75093874e-01, -1.11090243e-01, -7.22958386e-01,  2.13537142e-02,\n",
       "         7.01521993e-01, -1.91594541e-01,  4.66689050e-01,  2.30293572e-02,\n",
       "         2.32141569e-01,  3.06009173e-01,  6.63796782e-01, -6.71154141e-01,\n",
       "        -5.42171061e-01,  6.77638590e-01,  8.86990368e-01,  7.59227723e-02,\n",
       "         2.95007318e-01,  3.25703919e-01, -7.48467863e-01, -3.78703296e-01,\n",
       "         6.06289983e-01,  4.02663857e-01, -6.20844185e-01, -7.97690332e-01,\n",
       "        -1.55510679e-01, -1.98448047e-01,  3.48484784e-01,  7.40841031e-02,\n",
       "        -3.75826210e-01, -4.06477928e-01,  1.05510807e+00,  6.06058538e-01,\n",
       "        -4.10539031e-01, -4.85635921e-02, -5.70044577e-01,  6.19027436e-01,\n",
       "         3.37680250e-01,  4.19783682e-01,  2.99234420e-01,  5.84449291e-01,\n",
       "         3.43175918e-01,  6.59544691e-02, -1.02328226e-01,  6.42547965e-01,\n",
       "         2.72999018e-01,  1.18693873e-01,  1.82535231e-01, -3.32736075e-02,\n",
       "         7.58543491e-01, -5.19093513e-01, -1.96700737e-01,  4.47833061e-01,\n",
       "         7.66357705e-02, -5.67947745e-01, -1.10041723e-01, -3.87637675e-01,\n",
       "         3.25238824e-01, -2.24763006e-01,  9.62383687e-01,  4.26453352e-01,\n",
       "         2.10920006e-01,  5.72339222e-02,  2.58248478e-01, -6.19166434e-01,\n",
       "        -9.36051011e-02,  7.12964773e-01,  5.44606328e-01, -6.65080249e-02,\n",
       "        -2.81616509e-01, -5.63118398e-01, -2.52529204e-01,  7.19182074e-01,\n",
       "        -2.39113376e-01,  2.97089934e-01, -1.72302842e-01,  1.33336318e+00,\n",
       "        -2.61445433e-01, -6.11447453e-01,  1.33529887e-01, -1.72995120e-01,\n",
       "         8.73168886e-01,  5.41822910e-01, -2.47733295e-01, -6.93669021e-01,\n",
       "        -2.00377688e-01, -1.97305530e-01, -3.44529688e-01,  4.85463172e-01,\n",
       "        -5.26949354e-02, -4.03870270e-02, -1.47934377e-01, -4.69267756e-01,\n",
       "         2.43060756e-02, -2.21209362e-01,  5.34388013e-02,  3.00740480e-01,\n",
       "         2.86793530e-01, -7.83385634e-02, -1.82589404e-02,  6.56481147e-01,\n",
       "        -6.60591900e-01, -4.43259805e-01,  1.10289943e+00,  3.43361497e-01,\n",
       "        -6.34905696e-01,  4.19181734e-02, -7.19489157e-02, -4.00656052e-02,\n",
       "         2.54132926e-01, -1.69499055e-01, -7.63936192e-02, -2.12257579e-02,\n",
       "         3.80153686e-01, -4.08334807e-02, -5.67200541e-01,  2.40436286e-01,\n",
       "        -5.43290079e-01, -3.02593172e-01, -2.95852751e-01, -2.67256498e-02,\n",
       "        -9.84861970e-01,  1.69607490e-01,  2.10409254e-01,  2.64222234e-01,\n",
       "        -4.93055433e-01, -1.75261855e-01,  4.43595380e-01,  1.33628994e-01,\n",
       "        -8.68385434e-02,  4.00648981e-01, -6.15198731e-01,  1.57895833e-01,\n",
       "         3.33122373e-01, -4.08103913e-01, -8.62237215e-02, -2.58345783e-01,\n",
       "         1.14491574e-01, -8.64119112e-01,  4.51919138e-01,  2.95619369e-01,\n",
       "        -1.69039994e-01,  5.49043939e-02, -6.35722399e-01,  1.62852362e-01,\n",
       "        -2.16358319e-01,  7.21375942e-01, -1.16001032e-01, -4.91700232e-01,\n",
       "         2.48314627e-02, -6.79056644e-01,  5.74595213e-01, -3.66124898e-01,\n",
       "         1.17151581e-01,  4.32476141e-02, -6.49329498e-02, -1.30918205e-01,\n",
       "        -7.73078084e-01,  9.21959043e-01, -6.30445302e-01,  5.68785444e-02,\n",
       "        -3.11895400e-01,  4.17714745e-01,  1.39107645e-01,  3.17096829e-01,\n",
       "        -2.71115713e-02, -3.84770900e-01, -2.53630877e-01,  1.10736001e+00,\n",
       "        -1.53371274e-01,  4.50117439e-01,  3.18217099e-01, -6.57370389e-01,\n",
       "         2.46477604e-01, -3.52942169e-01, -1.49299085e-01, -6.08609855e-01,\n",
       "        -5.89798152e-01, -7.83418268e-02,  5.73160827e-01,  2.45557129e-01,\n",
       "        -1.24139056e-01, -5.01732826e-01,  5.07437587e-02,  4.89909202e-02,\n",
       "        -1.32979929e-01,  2.08390057e-01,  7.31386960e-01,  1.77556112e-01,\n",
       "         4.45047945e-01,  6.14586234e-01, -2.74169087e-01, -7.87930340e-02,\n",
       "        -5.80212995e-02, -2.96409518e-01,  3.51314582e-02,  2.11882696e-01,\n",
       "        -3.84128183e-01,  6.20526373e-01,  3.34728539e-01,  6.72924876e-01,\n",
       "         5.11194617e-02,  2.05215335e-01, -7.07537904e-02, -7.45522618e-01,\n",
       "        -1.29170835e-01, -1.22500762e-01,  2.89614439e-01,  3.65521908e-02,\n",
       "         1.10742092e-01,  2.32594877e-01,  4.83535528e-02, -2.00108737e-01,\n",
       "         2.68205628e-03, -5.87127864e-01, -9.33206320e-01,  3.12792242e-01,\n",
       "         5.86066604e-01, -3.52394462e-01,  5.77934563e-01,  3.22157964e-02,\n",
       "         1.04670063e-01,  6.86014533e-01, -9.00603652e-01,  3.03688824e-01,\n",
       "         4.69381362e-01, -1.86669767e-01, -1.83802750e-02,  4.95854944e-01,\n",
       "        -5.29387712e-01,  1.94507867e-01,  2.18865260e-01, -5.95260620e-01,\n",
       "         2.63458751e-02,  2.27007568e-01, -6.78096712e-01,  2.15298802e-01,\n",
       "        -5.78256667e-01, -2.20549911e-01, -6.05237246e-01,  3.22251439e-01,\n",
       "        -1.05634909e-02,  3.00751060e-01, -1.51000738e-01, -3.89637321e-01,\n",
       "        -3.01515639e-01, -6.67718470e-01,  2.19822496e-01,  8.90142396e-02,\n",
       "         2.15636522e-01, -5.36941648e-01, -7.37565383e-03,  1.60669029e-01,\n",
       "         8.65785360e-01,  4.95802671e-01,  3.39639410e-02,  3.82883668e-01,\n",
       "         3.85185629e-01, -3.09567004e-01,  8.38160396e-01,  1.36341318e-01,\n",
       "         1.17410511e-01,  3.28853130e-01, -3.28241102e-02,  4.88417208e-01,\n",
       "        -5.34203351e-01,  3.04159261e-02, -3.74980330e-01, -8.47190499e-01,\n",
       "         1.47821948e-01, -1.75004676e-01, -3.70442569e-01, -6.71388879e-02,\n",
       "         5.92280030e-01,  1.43422067e-01, -2.98709482e-01,  4.61934388e-01,\n",
       "         1.07091749e+00, -5.92058301e-01, -2.78808057e-01, -1.93617538e-01,\n",
       "        -4.46473300e-01, -7.35292196e-01,  7.41396308e-01, -1.43867284e-01,\n",
       "         1.39099747e-01, -3.68205667e-01,  3.28067660e-01,  4.66048717e-01,\n",
       "         1.93350077e-01,  1.21849447e-01, -5.57974577e-01, -3.88980865e-01,\n",
       "         1.50573999e-03,  3.85077447e-01, -2.62539238e-02, -6.69458732e-02,\n",
       "         3.27328384e-01,  2.28765368e-01, -4.40849304e-01,  7.17884183e-01,\n",
       "        -1.52994603e-01,  4.36864674e-01, -3.17517608e-01,  9.49253142e-01,\n",
       "         3.70942771e-01, -7.73010433e-01, -1.14800796e-01,  3.59068543e-01,\n",
       "        -3.17390531e-01,  6.78571880e-01, -4.42181736e-01, -2.52285331e-01,\n",
       "        -1.42510206e-01,  2.70896971e-01, -1.53425142e-01, -3.30700397e-01,\n",
       "        -3.57206523e-01, -5.02989113e-01, -4.04090524e-01,  3.46865922e-01,\n",
       "        -5.92724979e-01,  2.95026042e-02,  1.84331909e-02,  2.31234074e-01,\n",
       "         6.39158845e-01, -7.86263287e-01, -3.33564728e-01,  5.14475286e-01,\n",
       "         5.33131540e-01,  3.47170621e-01,  4.17137176e-01, -2.17266321e-01,\n",
       "        -1.04513049e+00,  7.60985732e-01,  6.14056766e-01, -3.72218549e-01,\n",
       "        -4.14683908e-01, -9.81070623e-02, -7.98722029e-01, -2.18889311e-01,\n",
       "        -7.39873201e-02, -1.84243232e-01, -2.60148883e-01,  2.60912776e-01,\n",
       "        -6.73864901e-01, -4.61737812e-01,  1.24067104e+00, -6.84629977e-01,\n",
       "         2.31796294e-01,  1.80889681e-01,  8.90048370e-02, -3.84165138e-01,\n",
       "        -3.66874933e-01,  1.00866288e-01, -2.49001980e-01,  4.36002702e-01],\n",
       "       dtype=float32),\n",
       " array([ 6.00604534e-01, -1.34959072e-01,  5.18294692e-01,  1.89286351e-01,\n",
       "         2.19713122e-01,  3.78166914e-01,  2.41008848e-01, -6.71060443e-01,\n",
       "        -2.21895009e-01,  7.49505520e-01,  1.54862240e-01, -1.11175843e-01,\n",
       "        -1.58591032e-01,  6.19848371e-01, -4.35874820e-01,  7.69215167e-01,\n",
       "        -4.55036730e-01, -6.45966053e-01, -2.76120566e-03, -2.94469237e-01,\n",
       "         1.05912244e+00, -2.04192355e-01, -9.18362677e-01,  4.87608999e-01,\n",
       "         6.75285518e-01, -8.54684785e-03, -2.59428769e-01,  5.17210066e-01,\n",
       "        -1.90925255e-01, -4.76582706e-01,  1.47138226e+00,  4.64141041e-01,\n",
       "        -8.17565620e-02, -1.16087802e-01, -6.52213454e-01, -3.03557158e-01,\n",
       "        -7.92008191e-02, -2.52050534e-02, -9.59789991e-01,  2.21889392e-01,\n",
       "        -2.64582932e-01, -6.86766088e-01,  2.18503118e-01, -2.64385819e-01,\n",
       "        -3.13858956e-01, -4.56037223e-01, -1.14400402e-01, -3.97952385e-02,\n",
       "        -4.86734748e-01, -1.42447904e-01, -7.33882368e-01,  4.55729842e-01,\n",
       "        -2.04371676e-01, -4.86424446e-01,  1.13255329e-01,  1.09317327e+00,\n",
       "        -3.18158835e-01, -1.97520018e-01,  3.38002682e-01, -8.31269324e-02,\n",
       "        -7.98772454e-01, -1.01796150e-01,  2.31561214e-01, -8.42903972e-01,\n",
       "        -6.95869386e-01,  1.05238810e-01,  2.75118928e-02, -7.57913709e-01,\n",
       "        -4.96925622e-01,  1.94800884e-01, -3.36727887e-01, -6.60704747e-02,\n",
       "         8.06367099e-02,  2.55402744e-01, -4.82880414e-01,  6.43134475e-01,\n",
       "        -4.91437316e-01,  4.60905790e-01,  2.36292318e-01,  3.28525230e-02,\n",
       "        -6.46994948e-01,  1.23586275e-01,  6.57734573e-01,  1.66216403e-01,\n",
       "         8.43183324e-02,  8.45901132e-01,  1.91244110e-02,  9.39859569e-01,\n",
       "         3.33604962e-01, -4.87711459e-01,  1.00180186e-01,  3.39256197e-01,\n",
       "         2.99108773e-02,  2.75467813e-01,  5.45241833e-01, -6.08200319e-02,\n",
       "        -3.74214686e-02, -2.04345718e-01, -9.04188082e-02,  3.23770344e-01,\n",
       "         3.55670631e-01, -8.61103952e-01, -2.20258892e-01,  1.29710913e-01,\n",
       "        -1.90599889e-01,  3.38565707e-01, -6.52581900e-02,  3.84419173e-01,\n",
       "         9.06612352e-03,  8.32600713e-01,  4.45724167e-02,  2.83292644e-02,\n",
       "        -5.22940196e-02, -2.42383704e-01, -5.98609269e-01,  6.23575211e-01,\n",
       "        -2.87906807e-02,  6.64854109e-01, -6.38633013e-01, -1.55921072e-01,\n",
       "        -9.53635946e-02, -4.27037001e-01,  5.19190013e-01,  9.95329678e-01,\n",
       "         7.79892087e-01, -3.58000338e-01,  2.53840923e-01,  3.52591157e-01,\n",
       "         1.82287067e-01,  2.40713984e-01,  2.75080949e-01,  3.61676306e-01,\n",
       "        -6.23165630e-02, -2.35294938e-01, -3.87675226e-01,  1.74487054e-01,\n",
       "         3.71360809e-01, -2.18299598e-01, -2.81358846e-02,  4.92461175e-02,\n",
       "        -7.13520229e-01,  1.45508036e-01, -2.49902636e-01,  6.46426916e-01,\n",
       "         5.05220965e-02,  1.91111535e-01,  2.23426551e-01,  6.03656650e-01,\n",
       "        -5.23266077e-01, -9.35257912e-01,  3.15272063e-01,  3.79672706e-01,\n",
       "         4.82876599e-03, -4.72979784e-01, -2.77994275e-01,  6.71134531e-01,\n",
       "        -9.91841257e-02,  2.22403333e-02,  5.57657063e-01, -5.03710866e-01,\n",
       "        -4.81090397e-02,  4.45895076e-01,  9.69478562e-02, -5.09745367e-02,\n",
       "        -5.14542997e-01, -1.43717945e-01,  4.09264676e-02,  7.88519561e-01,\n",
       "        -6.40542686e-01,  8.68725121e-01,  4.39737365e-02,  3.52426618e-01,\n",
       "         1.36376664e-01,  5.91838181e-01, -7.23250434e-02,  1.47271603e-02,\n",
       "        -9.20040682e-02, -5.60792923e-01,  3.03988218e-01, -2.55823433e-01,\n",
       "         5.21091819e-01,  9.53339972e-04,  7.01979876e-01,  9.23650116e-02,\n",
       "         8.33301067e-01,  1.53812528e-01,  1.43283272e+00,  4.20963436e-01,\n",
       "        -8.06764960e-01,  1.59408078e-01,  2.07939491e-01,  3.98246527e-01,\n",
       "        -1.87585369e-01, -2.92304754e-01, -2.70649403e-01, -4.83727217e-01,\n",
       "         7.14718029e-02,  2.24409878e-01, -6.01112425e-01,  1.76259190e-01,\n",
       "         4.42065358e-01, -2.54846402e-02, -4.57147360e-01, -2.38436624e-01,\n",
       "        -3.10688496e-01,  1.96154207e-01, -6.38724342e-02, -1.36033654e-01,\n",
       "        -2.96521872e-01, -6.62360311e-01,  2.32409239e-01,  4.30942416e-01,\n",
       "         2.97076643e-01, -1.77986175e-01,  8.69896114e-02, -3.45762402e-01,\n",
       "        -4.64395195e-01,  6.16026282e-01,  3.02826285e-01, -5.10964990e-01,\n",
       "         6.21577978e-01,  6.59799814e-01,  6.30161285e-01,  6.70545280e-01,\n",
       "        -1.96979910e-01,  1.21818483e+00,  8.46304476e-01,  6.71376139e-02,\n",
       "         6.08185790e-02,  1.18394144e-01, -3.73992443e-01, -1.94629863e-01,\n",
       "        -4.33734983e-01, -9.54317927e-01, -5.90075850e-01,  2.09326088e-01,\n",
       "        -1.57834709e-01, -4.92694497e-01, -1.61674619e-02, -3.59656960e-02,\n",
       "        -1.80532068e-01, -1.43447563e-01,  3.25807482e-01,  4.75255728e-01,\n",
       "        -6.33040249e-01,  4.50367570e-01, -5.83447337e-01,  1.91706836e-01,\n",
       "        -6.55059814e-02, -3.00616920e-01, -1.54130131e-01,  9.23719585e-01,\n",
       "         7.62720779e-02, -1.18512861e-01, -6.56207681e-01,  7.77211010e-01,\n",
       "         5.01968712e-02,  6.37445986e-01, -4.99944597e-01,  7.15956271e-01,\n",
       "         4.02032793e-01, -3.68998647e-01,  1.95438668e-01, -3.67220640e-01,\n",
       "        -1.03682525e-01, -1.13997273e-02, -2.04719901e-01,  1.82800293e-01,\n",
       "        -7.71073028e-02,  4.68124658e-01, -3.96188200e-01,  2.85092115e-01,\n",
       "        -5.78685626e-02,  9.55211043e-01,  1.41311511e-01, -5.39685905e-01,\n",
       "         4.87720490e-01, -7.00498402e-01,  9.20967534e-02, -1.12356639e+00,\n",
       "         3.16597968e-01,  4.02328104e-01, -1.75904125e-01,  1.19354919e-01,\n",
       "        -1.53992251e-01, -4.34351951e-01,  1.73177451e-01, -2.09441558e-01,\n",
       "        -1.21581428e-01, -3.80236685e-01, -5.85126698e-01, -2.72786111e-01,\n",
       "        -1.38109899e+00, -6.63348138e-01,  8.37911516e-02,  9.39928368e-03,\n",
       "         2.91482151e-01,  2.20700115e-01, -1.15963250e-01, -3.69278073e-01,\n",
       "        -5.03331870e-02, -4.52068090e-01,  2.80273795e-01, -3.31762910e-01,\n",
       "        -3.31226438e-01,  1.22665465e+00, -9.12176967e-02, -4.89282727e-01,\n",
       "        -4.42331219e+00, -6.79634288e-02, -2.15715289e-01,  9.10340250e-02,\n",
       "        -7.89185092e-02, -4.61723842e-02,  1.40795231e-01,  3.68079171e-03,\n",
       "        -1.78953201e-01, -1.36173356e+00, -4.43804324e-01, -1.40655369e-01,\n",
       "        -1.35903388e-01, -1.15346089e-01, -3.48228924e-02,  1.11048907e-01,\n",
       "         3.23129416e-01, -6.08663559e-01,  1.22656263e-02,  5.77709854e-01,\n",
       "        -3.84311885e-01,  1.00281648e-01,  1.22797966e-01,  2.45239899e-01,\n",
       "         1.61202848e-01,  2.86053598e-01,  2.22156778e-01,  4.92143780e-01,\n",
       "         6.13610625e-01, -3.42494436e-03, -1.84441888e+00, -1.50059640e-01,\n",
       "         2.66683608e-01,  8.57699037e-01,  1.30397409e-01,  4.10434306e-02,\n",
       "         2.90750228e-02,  5.19927368e-02,  1.11332977e+00,  1.52737916e-01,\n",
       "         1.01575464e-01, -7.24206567e-01, -3.75283509e-01, -9.21599194e-03,\n",
       "         4.03221399e-01, -3.93668748e-02, -2.06139550e-01, -1.47365153e-01,\n",
       "         9.32917595e-01,  1.32824093e-01,  1.38307780e-01,  2.50476927e-01,\n",
       "        -2.81930208e-01, -5.46096742e-01, -2.70586237e-02,  2.67087430e-01,\n",
       "        -9.72733423e-02, -3.35172951e-01, -9.63556707e-01,  3.66856843e-01,\n",
       "        -8.40511024e-02, -2.30529681e-01, -1.08215652e-01,  2.07413763e-01,\n",
       "         1.27975953e+00, -2.86871463e-01, -9.65552747e-01, -1.54863477e-01,\n",
       "        -5.69288254e-01,  2.00065807e-01,  6.02009296e-02, -1.02308440e+00,\n",
       "         5.34830987e-01, -1.30408156e+00, -2.44952179e-03, -3.11360002e-01,\n",
       "        -2.26942629e-01, -2.27109730e-01,  1.12241757e+00, -1.10374355e+00,\n",
       "         8.91044587e-02, -1.39919245e+00,  3.52602065e-01,  6.50687099e-01,\n",
       "        -7.21315503e-01, -3.67806286e-01,  2.30253041e-01,  1.01344377e-01,\n",
       "         3.06272000e-01,  1.78737611e-01, -1.51625007e-01,  3.15539271e-01,\n",
       "        -4.91703600e-01, -7.29126751e-01, -3.92766297e-02, -2.62457043e-01,\n",
       "        -4.67290342e-01, -4.02952611e-01,  4.48387027e-01, -8.77697349e-01,\n",
       "         1.20956346e-01, -7.56643951e-01,  1.15531888e-02,  4.64804053e-01,\n",
       "        -3.91325027e-01,  1.64041579e-01, -3.10351372e-01, -5.39966106e-01,\n",
       "         1.85883433e-01,  4.17173952e-01,  6.60522461e-01, -8.56164694e-01,\n",
       "        -1.13637010e-02, -2.25637555e-01,  2.58992940e-01, -8.02999675e-01,\n",
       "        -2.91024417e-01,  1.02506328e+00, -3.05439651e-01,  1.11537866e-01,\n",
       "        -1.70252740e-01,  9.29913163e-01, -1.70819759e-02,  2.85578787e-01,\n",
       "        -4.21402514e-01, -3.77460420e-02, -4.46594298e-01, -5.78905463e-01,\n",
       "        -1.12110806e+00, -2.48489395e-01, -1.71912774e-01, -1.25463223e+00,\n",
       "         6.90569818e-01, -1.53335214e-01,  2.59737939e-01,  2.93505847e-01,\n",
       "        -1.84234157e-01, -1.89792228e+00, -4.88791704e-01,  3.61007273e-01,\n",
       "         1.57012865e-01,  8.15016508e-01,  1.91547647e-01,  4.99779135e-01,\n",
       "         7.07796454e-01,  5.06354094e-01,  1.64394781e-01,  1.24972150e-01,\n",
       "        -8.58134449e-01,  1.50941655e-01,  3.16794753e-01,  1.12920120e-01,\n",
       "        -4.02202010e-02, -5.91902554e-01, -1.31813675e-01, -8.19452345e-01,\n",
       "         1.18299150e+00,  2.19384372e-01, -6.69667542e-01, -9.78496969e-01,\n",
       "         8.60647410e-02,  3.14886719e-01,  4.87119257e-01,  1.15558028e+00,\n",
       "        -1.55889913e-01,  6.55221462e-01, -4.23359960e-01, -1.36347860e-01,\n",
       "         3.30652118e-01,  1.17382765e-01,  6.23203032e-02,  5.74263707e-02,\n",
       "        -1.42552912e-01,  1.18527047e-01,  2.10682362e-01,  9.30239320e-01,\n",
       "        -1.29248604e-01,  2.48645857e-01,  3.59361231e-01,  1.22878897e+00,\n",
       "         1.21927544e-01,  2.53344357e-01, -6.83714226e-02,  4.25933361e-01,\n",
       "         3.73003304e-01,  5.32828987e-01,  2.11536996e-02, -2.74878174e-01,\n",
       "        -8.57124105e-02,  1.24367513e-02, -4.71944988e-01,  9.56589758e-01,\n",
       "         3.67320895e-01, -6.63207769e-01, -5.88693619e-01, -2.50990272e-01,\n",
       "         4.35863048e-01, -6.90657735e-01,  6.61455512e-01,  2.76873767e-01,\n",
       "        -5.64456105e-01, -1.09301411e-01, -3.21194351e-01,  2.71238029e-01,\n",
       "         4.04079080e-01, -5.71499109e-01,  2.57025778e-01,  2.93879390e-01,\n",
       "        -3.61999929e-01,  3.23464096e-01,  3.38290691e-01, -3.69367212e-01,\n",
       "         3.43015641e-01, -3.31546366e-01, -5.56552410e-01,  2.13251486e-02,\n",
       "         2.02995479e-01, -3.72458845e-01, -5.35193622e-01,  1.03549969e+00,\n",
       "        -1.65367961e-01,  1.09090330e-02,  4.60500538e-01, -2.44905084e-01,\n",
       "        -1.13571048e+00, -6.57290161e-01,  4.35109995e-02,  6.57664016e-02,\n",
       "        -2.80351669e-01,  7.35970363e-02, -5.80742061e-01, -7.10553646e-01,\n",
       "        -3.95112127e-01, -1.06218684e+00, -6.39837623e-01,  4.70153838e-01,\n",
       "        -5.66091001e-01, -2.62597144e-01,  8.46594125e-02,  2.36432821e-01,\n",
       "        -5.25797784e-01, -4.77756053e-01, -1.96637496e-01,  2.57024080e-01,\n",
       "        -1.08281933e-02,  7.60967433e-01, -3.99369627e-01,  1.57835439e-01,\n",
       "        -1.20291281e+00,  7.03307986e-02, -4.01298225e-01,  6.48425996e-01,\n",
       "        -2.18047172e-01, -7.71949470e-01,  3.92176688e-01,  1.98128223e-01,\n",
       "         8.94534290e-01,  6.17256641e-01,  1.29393131e-01,  3.04522246e-01,\n",
       "        -3.72412980e-01, -4.30834293e-01,  8.57930303e-01,  6.60696387e-01,\n",
       "        -6.74047828e-01,  1.68021798e-01,  9.43428636e-01,  7.89203525e-01,\n",
       "        -3.82870257e-01, -9.11964953e-01, -3.30488890e-01, -3.01449060e-01,\n",
       "         5.67250013e-01, -3.49020004e-01, -5.38758516e-01,  5.92711270e-02,\n",
       "         4.34025019e-01, -8.89967024e-01,  1.14029431e+00, -1.31225079e-01,\n",
       "        -3.59742254e-01, -2.29898274e-01, -8.81550670e-01, -2.98547834e-01,\n",
       "        -3.49941909e-01,  3.60563964e-01,  6.32247210e-01, -7.51502216e-01,\n",
       "        -8.17392826e-01,  2.57472992e-01,  7.42709935e-01,  4.22730416e-01,\n",
       "         4.31385487e-02, -1.62429780e-01,  1.63571075e-01,  4.31501716e-01,\n",
       "        -1.07530683e-01,  1.10960245e-01,  8.46176028e-01,  3.00145447e-01,\n",
       "        -8.91126573e-01, -4.53329943e-02, -2.18369678e-01,  5.19406915e-01,\n",
       "        -4.33993459e-01,  1.15467571e-01,  2.21544653e-01, -8.33371401e-01,\n",
       "        -5.29056549e-01, -6.99185073e-01, -1.43181160e-02,  1.56752989e-01,\n",
       "         6.80078268e-02,  5.64206004e-01,  5.21525264e-01, -3.92447352e-01,\n",
       "         5.90551019e-01,  4.67017829e-01, -2.85268947e-02,  5.53051792e-02,\n",
       "         3.71642523e-02, -1.89118832e-03, -5.30632854e-01,  3.12593699e-01,\n",
       "         7.42098153e-01,  7.99341679e-01, -2.87587315e-01,  2.53725052e-01,\n",
       "         3.29007357e-02, -1.69132084e-01, -3.44239213e-02, -1.11888066e-01,\n",
       "        -4.63818997e-01, -5.04671395e-01,  3.28249514e-01, -1.31883085e-01,\n",
       "         7.62218833e-01, -5.37293516e-02, -2.03594849e-01,  1.26394057e+00,\n",
       "         1.06719923e+00, -3.10911983e-02, -4.95794028e-01, -1.99513882e-03,\n",
       "        -2.75221556e-01,  1.58122346e-01,  2.75866389e-02, -7.46701509e-02,\n",
       "         3.65614332e-02, -3.57194036e-01,  1.14799023e+00,  4.44476187e-01,\n",
       "         7.05742300e-01, -1.48564100e-01, -7.28950351e-02,  1.42320603e-01,\n",
       "         2.76869625e-01, -5.59625663e-02, -5.86245596e-01, -8.18939805e-02,\n",
       "        -2.76980460e-01, -2.17006832e-01,  1.39512062e-01,  2.08909661e-01,\n",
       "         3.23472649e-01,  8.27359259e-01, -8.06154013e-01,  2.34054700e-01,\n",
       "        -1.30237758e-01,  1.88087985e-01,  4.88619268e-01,  4.89208475e-02,\n",
       "        -2.86628067e-01, -1.55153751e-01, -3.23461354e-01,  5.03653228e-01,\n",
       "        -6.74547374e-01,  3.47280622e-01,  1.07005931e-01,  9.77352381e-01,\n",
       "         4.72124517e-01,  8.39413166e-01, -3.32786262e-01,  3.10491472e-01,\n",
       "        -2.41474628e-01,  1.28265351e-01,  3.83227319e-02, -4.15790111e-01,\n",
       "         1.99533746e-01, -4.91172493e-01,  7.18582511e-01,  4.59200680e-01,\n",
       "         4.88502800e-01,  4.88098741e-01, -2.98055112e-01,  2.09569633e-02,\n",
       "         1.77114114e-01, -1.70566574e-01,  6.79116607e-01, -4.63670582e-01,\n",
       "        -7.34676063e-01, -3.33771184e-02, -3.94285917e-01, -2.88045168e-01,\n",
       "        -1.32092267e-01,  3.83990765e-01, -2.85661072e-01,  1.73035171e-02,\n",
       "        -9.16087255e-03, -9.69216645e-01, -5.16176760e-01,  3.73166353e-01,\n",
       "        -4.83624578e-01,  7.80811191e-01, -2.32169162e-02, -4.32629526e-01,\n",
       "        -7.82177001e-02, -3.39133888e-01,  2.68586762e-02, -3.82381886e-01,\n",
       "        -8.56580794e-01,  3.71140629e-01,  3.73622477e-02,  5.88460147e-01,\n",
       "         4.17331606e-01, -9.89403427e-01,  1.37679189e-01,  4.60742474e-01,\n",
       "         6.22610450e-02,  8.48459303e-02, -3.88477832e-01, -3.58572602e-01,\n",
       "         8.38460028e-02, -5.48053309e-02,  5.12359500e-01,  8.28450561e-01,\n",
       "         4.43525016e-02,  1.67252533e-02, -2.76495308e-01, -5.42263508e-01,\n",
       "         4.96886283e-01,  8.64282429e-01,  6.28320500e-03,  1.85799345e-01,\n",
       "        -1.80926943e+00,  5.90442061e-01, -8.15887272e-01, -7.89222240e-01,\n",
       "        -2.97111899e-01, -8.56005698e-02,  1.53419256e-01,  2.04978824e-01,\n",
       "        -1.69416755e-01, -5.13487339e-01, -1.15876317e-01, -4.09399003e-01,\n",
       "         1.61101371e-01, -8.43874991e-01,  3.56312171e-02,  1.94666937e-01],\n",
       "       dtype=float32),\n",
       " array([-1.17446351e+00, -3.83024037e-01,  3.08563471e-01,  1.75179809e-01,\n",
       "         1.02247298e-03,  3.19458485e-01, -6.24821544e-01,  4.79912788e-01,\n",
       "         1.72227532e-01, -1.24802756e+00,  1.24070093e-01, -4.17536825e-01,\n",
       "         4.42324668e-01,  9.10337687e-01, -2.65229374e-01,  9.04964149e-01,\n",
       "         6.92493021e-01,  3.42434421e-02, -6.26355410e-01,  5.60032666e-01,\n",
       "         4.13254410e-01, -6.51395142e-01, -1.44866452e-01, -1.42093375e-02,\n",
       "         6.14067852e-01,  5.01102209e-02, -8.05687681e-02,  2.13170081e-01,\n",
       "         2.91391611e-01, -3.45051795e-01, -1.38204331e-02, -1.54410288e-01,\n",
       "        -2.20299251e-02, -5.70157886e-01, -7.50864863e-01, -6.33003235e-01,\n",
       "         8.44407007e-02, -5.74135125e-01, -6.60850465e-01,  1.35062471e-01,\n",
       "        -1.20503628e+00, -8.24360132e-01, -8.92900586e-01, -2.05460995e-01,\n",
       "        -1.84689820e-01, -3.47746432e-01,  1.43918648e-01, -3.37861240e-01,\n",
       "        -2.89749205e-01, -5.48530817e-01, -6.07669428e-02, -5.86285055e-01,\n",
       "         7.87788257e-03, -2.81717688e-01, -1.05407938e-01,  3.41983914e-01,\n",
       "         1.57525033e-01, -5.67845702e-01, -1.73559025e-01,  5.13833821e-01,\n",
       "         4.05825496e-01,  2.89022699e-02,  9.61438000e-01, -9.37822521e-01,\n",
       "         5.36207631e-02,  3.71831775e-01,  4.85143065e-02,  1.37888923e-01,\n",
       "        -8.82789269e-02, -5.22891045e-01, -2.44073704e-01, -2.16691852e-01,\n",
       "        -2.82987356e-01, -2.45679364e-01, -4.72339541e-01, -9.73748744e-01,\n",
       "         2.47864038e-01, -5.01830280e-02,  5.22708058e-01,  1.42451763e+00,\n",
       "        -4.31408376e-01,  1.30929816e+00,  3.10048819e-01,  9.11615491e-01,\n",
       "         4.86634299e-02,  1.55198485e-01, -3.94955397e-01,  3.39668483e-01,\n",
       "         1.38628066e-01, -6.01467073e-01, -9.61712003e-02, -2.11768627e-01,\n",
       "         3.16837490e-01,  2.56117582e-01,  4.82269615e-01, -5.69228888e-01,\n",
       "         2.84984946e-01,  6.11237474e-02, -5.41837513e-02,  8.53786886e-01,\n",
       "         3.58618349e-02, -3.90909344e-01,  5.92830181e-01,  1.23409018e-01,\n",
       "         6.60285279e-02,  1.68496892e-01,  7.53333747e-01,  1.48626685e-01,\n",
       "         6.41137064e-02, -6.79469258e-02, -1.25409812e-01, -7.67417908e-01,\n",
       "        -3.26153189e-01,  1.69955269e-01,  2.42692411e-01,  5.44800699e-01,\n",
       "        -1.48417637e-01, -9.82245058e-02,  2.23382682e-01,  2.87370950e-01,\n",
       "         1.08636692e-01, -1.09825444e+00,  7.70786464e-01,  5.41003883e-01,\n",
       "         6.03646040e-01, -4.36221570e-01, -3.48780274e-01,  4.48910505e-01,\n",
       "         1.10860378e-01, -4.16096509e-01, -1.49422558e-02, -7.05152377e-02,\n",
       "        -2.24223122e-01, -1.17724133e+00,  5.07394910e-01,  1.26551464e-02,\n",
       "        -5.69137335e-01, -8.85575533e-01, -5.83161116e-01, -3.14827442e-01,\n",
       "         4.62666482e-01, -2.46115118e-01, -1.17571473e-01, -1.08222812e-01,\n",
       "        -6.49915874e-01, -5.08904219e-01, -6.49414778e-01,  1.88390121e-01,\n",
       "         1.70661107e-01,  1.22831658e-01,  3.06298643e-01, -1.65531084e-01,\n",
       "        -4.37566280e-01, -9.38018918e-01,  4.58957762e-01, -3.46696198e-01,\n",
       "        -5.85455894e-01,  1.53709918e-01,  5.10094538e-02, -2.12386876e-01,\n",
       "        -1.39572129e-01, -1.52457833e-01,  3.08168381e-01, -2.76672155e-01,\n",
       "        -2.84355044e-01, -1.38773888e-01, -2.05468446e-01,  4.04484808e-01,\n",
       "         5.55198193e-01,  5.73690355e-01,  3.24906707e-02, -2.35110357e-01,\n",
       "         6.87800407e-01,  4.21143442e-01,  3.45890880e-01, -8.27998668e-02,\n",
       "         5.95912337e-01,  1.79808289e-01,  4.88372952e-01,  1.05106540e-01,\n",
       "        -3.78105879e-01,  1.08542717e+00,  6.76977158e-01,  2.22498327e-01,\n",
       "         2.75104254e-01,  4.71522868e-01,  4.71883230e-02,  5.57199061e-01,\n",
       "        -4.89568442e-01, -1.52551636e-01,  3.26096535e-01,  5.85146308e-01,\n",
       "        -7.02571034e-01,  2.31870145e-01, -7.35847712e-01, -6.08850181e-01,\n",
       "        -1.89843863e-01,  7.77896821e-01, -1.02967250e+00,  4.88282949e-01,\n",
       "         8.64763021e-01, -1.72206849e-01,  1.77793652e-01,  2.77010709e-01,\n",
       "        -1.35065392e-02, -6.22148991e-01,  6.23981833e-01, -4.24497485e-01,\n",
       "        -6.04349971e-01,  4.70087938e-02, -1.92447841e-01,  1.09840620e+00,\n",
       "         5.24307370e-01, -2.37534404e-01,  2.29973912e-01,  4.06980604e-01,\n",
       "         2.44970500e-01,  6.61527038e-01,  3.80405486e-01,  3.90668899e-01,\n",
       "         2.76376188e-01,  3.82146329e-01, -7.21044481e-01,  2.16899723e-01,\n",
       "         3.17951769e-01,  4.84966040e-01, -1.50918126e-01, -1.50637209e-01,\n",
       "         7.23705113e-01,  9.57566977e-01, -4.00689662e-01,  2.13865831e-01,\n",
       "        -2.86466837e-01,  6.82795197e-02,  2.38733321e-01,  3.42588097e-01,\n",
       "         3.57965320e-01,  3.64303648e-01,  6.40101254e-01, -2.65134364e-01,\n",
       "        -5.90059534e-02,  1.20332086e+00,  1.06456661e+00,  9.83374268e-02,\n",
       "        -8.19243968e-01,  3.43148232e-01, -2.49199525e-01, -1.08019739e-01,\n",
       "        -8.44337344e-01,  3.23069170e-02, -5.69852352e-01, -6.38349175e-01,\n",
       "         4.72690836e-02, -3.62319112e-01, -5.51969290e-01, -3.41214649e-02,\n",
       "        -1.94854274e-01, -2.07310706e-01,  1.92866817e-01,  1.95284933e-03,\n",
       "         5.08787408e-02, -4.01519805e-01,  4.47282970e-01,  4.77706492e-01,\n",
       "        -1.06447488e-01, -7.43500113e-01, -4.43748116e-01,  1.44341141e-01,\n",
       "         2.14302793e-01,  1.20833039e+00, -2.89593041e-01,  6.05497718e-01,\n",
       "         1.38094082e-01,  5.74463248e-01, -1.16030067e-01,  3.79371136e-01,\n",
       "        -3.62357050e-01,  3.88531417e-01, -8.97259355e-01, -3.63189310e-01,\n",
       "         8.01243842e-01,  6.11927092e-01, -5.52211642e-01, -5.99234223e-01,\n",
       "         4.57986504e-01, -7.32778192e-01, -3.78898978e-01,  1.21404260e-01,\n",
       "        -7.45679736e-01, -3.48993570e-01,  6.73717618e-01,  5.00282168e-01,\n",
       "        -7.63119519e-01, -2.08876267e-01,  7.48382628e-01,  7.47240067e-01,\n",
       "         4.80451360e-02,  6.02626383e-01, -1.07179195e-01, -6.34526908e-01,\n",
       "        -8.25895607e-01, -8.86576712e-01, -2.71834731e-01,  1.99534923e-01,\n",
       "         2.60768801e-01,  2.19761968e-01,  1.30547023e+00, -1.27193916e+00,\n",
       "        -4.12150192e+00,  4.77910489e-02,  2.44333237e-01, -2.99716920e-01,\n",
       "         3.71516168e-01, -2.36024618e-01, -1.31747812e-01, -3.59925896e-01,\n",
       "        -5.89818001e-01, -3.31700444e-01, -1.74385682e-01, -3.16090822e-01,\n",
       "         6.23660386e-01,  2.84567952e-01,  4.07449096e-01,  2.26050839e-01,\n",
       "        -8.03446889e-01, -6.60733879e-01, -1.09829336e-01,  8.11713636e-01,\n",
       "        -6.41623378e-01, -1.37277639e+00,  5.60456634e-01,  2.88689941e-01,\n",
       "         4.21302468e-01,  3.00680816e-01, -4.05510999e-02, -4.50792462e-01,\n",
       "        -9.02534723e-01, -7.28803128e-02, -7.40119576e-01, -3.61980677e-01,\n",
       "         2.72961229e-01, -3.87779027e-02,  1.94803506e-01, -3.54166448e-01,\n",
       "        -5.96197918e-02, -3.86700273e-01,  2.90099174e-01, -3.80910002e-04,\n",
       "        -1.12473406e-01, -6.44886851e-01, -3.83921057e-01, -4.12840128e-01,\n",
       "         5.51178157e-01, -6.88402891e-01,  5.79393327e-01,  1.36277661e-01,\n",
       "        -1.11305676e-01, -1.56752259e-01, -3.41449320e-01,  6.25160456e-01,\n",
       "        -5.42297542e-01, -5.74299455e-01, -8.26333702e-01,  6.23854697e-01,\n",
       "         1.17816985e-01, -6.08151615e-01,  1.43135130e-01,  1.46556199e-01,\n",
       "         7.03392327e-02, -3.44295114e-01, -5.19457698e-01,  1.49798706e-01,\n",
       "         6.67184711e-01,  6.13368303e-02, -5.18301502e-03, -7.04289794e-01,\n",
       "         3.46290648e-01,  8.32233906e-01,  3.35922271e-01,  5.66052258e-01,\n",
       "         4.48007397e-02, -1.44120884e+00, -8.13540161e-01, -1.65254042e-01,\n",
       "        -4.99960780e-01, -4.92351472e-01,  3.74977052e-01, -3.49497736e-01,\n",
       "        -1.37148488e+00, -5.38830101e-01,  3.50304365e-01,  1.03407574e+00,\n",
       "         3.07235181e-01, -7.55362749e-01, -7.50658333e-01, -6.25590026e-01,\n",
       "        -2.98807323e-01, -1.02015324e-01, -5.08486629e-01,  6.25245094e-01,\n",
       "        -2.55104899e-01,  3.18379492e-01,  3.26426208e-01,  1.76069513e-02,\n",
       "        -6.41839445e-01,  5.00403404e-01,  5.76184869e-01, -3.96846533e-01,\n",
       "        -3.21974993e-01, -1.33251309e+00,  1.05518436e+00,  5.83442673e-02,\n",
       "        -1.35874942e-01,  4.46693361e-01,  1.70699477e-01, -9.47012678e-02,\n",
       "         9.72768888e-02, -2.03137368e-01,  3.63133401e-01, -3.96805018e-01,\n",
       "         8.47540140e-01, -3.96550059e-01,  2.58477062e-01, -6.18186116e-01,\n",
       "        -3.36629748e-01,  1.36224163e+00, -3.67218070e-02, -2.03662906e-02,\n",
       "        -6.43461823e-01,  2.05260858e-01, -6.34201765e-01,  8.55912194e-02,\n",
       "         1.61926582e-01, -1.91722542e-01, -1.15351016e-02, -6.21569753e-01,\n",
       "        -8.05216372e-01, -9.03218508e-01,  1.43517420e-01, -2.47368172e-01,\n",
       "        -6.56117082e-01, -2.43461519e-01,  9.06916142e-01,  4.96391356e-01,\n",
       "        -5.59343457e-01, -1.14340258e+00,  1.07814789e-01,  1.57676041e-02,\n",
       "         4.56108689e-01,  2.68589169e-01, -5.38920909e-02, -4.90232229e-01,\n",
       "        -6.31477892e-01,  7.63541818e-01, -1.09382972e-01,  3.13195914e-01,\n",
       "        -6.72997311e-02,  8.33093524e-01,  7.03621358e-02, -3.90977919e-01,\n",
       "        -6.23404682e-02, -5.57730496e-01,  5.76523662e-01,  2.83523679e-01,\n",
       "         1.56840384e-01,  1.70076266e-01, -2.66713500e-01,  1.67383954e-01,\n",
       "        -1.01126239e-01,  2.06701547e-01,  1.36051893e+00,  3.64271104e-01,\n",
       "         1.96670651e-01,  1.56304568e-01, -1.24239013e-01, -6.76857531e-02,\n",
       "         2.14825556e-01,  6.73343599e-01, -5.82047760e-01, -2.07094729e-01,\n",
       "        -1.44600898e-01, -3.84976536e-01, -1.88092768e-01,  6.01117671e-01,\n",
       "        -1.33472428e-01,  1.74665302e-01, -6.01132035e-01, -9.41240788e-02,\n",
       "         1.82422325e-01,  5.20171762e-01,  2.70437270e-01,  2.81093001e-01,\n",
       "         5.37999570e-01,  6.50709212e-01, -4.58107501e-01, -1.79623552e-02,\n",
       "         2.73925722e-01, -1.28156632e-01, -1.74878627e-01, -8.57660919e-03,\n",
       "         1.82115674e-01, -1.11723177e-01, -6.45193815e-01,  3.51513505e-01,\n",
       "         5.33484459e-01,  1.48989171e-01,  5.21775305e-01, -3.71946692e-01,\n",
       "         5.44270799e-02, -6.73363984e-01, -5.73229015e-01,  9.91839886e-01,\n",
       "        -1.27328908e+00,  3.01806808e-01,  1.44363332e+00,  1.31552771e-01,\n",
       "         5.16766548e-01,  3.87785733e-01,  4.17441994e-01, -3.14756930e-01,\n",
       "        -2.04436362e-01, -2.70394892e-01,  4.26177010e-02,  3.04114878e-01,\n",
       "        -5.26721239e-01, -4.55119908e-01, -2.70716846e-01,  2.36647278e-01,\n",
       "        -3.96771431e-01, -2.08623946e-01,  2.73379743e-01, -5.39809942e-01,\n",
       "        -6.43666804e-01, -1.94901377e-01,  2.98511565e-01,  7.71474004e-01,\n",
       "        -1.31852889e+00, -3.58005285e-01,  7.79230475e-01, -2.96411484e-01,\n",
       "         2.93691196e-02, -4.73713070e-01,  1.23491526e-01,  1.20196640e-01,\n",
       "        -1.39933467e+00, -8.09322655e-01, -1.40471905e-02, -3.67536426e-01,\n",
       "        -1.14330880e-01, -3.80442351e-01,  2.12206185e-01, -7.00443923e-01,\n",
       "        -4.76197511e-01,  7.22880423e-01, -1.20474458e+00,  4.20401394e-01,\n",
       "        -1.82378992e-01,  6.56838298e-01, -1.27900556e-01, -2.06888288e-01,\n",
       "         3.48732680e-01, -6.52770400e-01,  3.18805873e-01, -3.09357762e-01,\n",
       "        -3.99806350e-01,  4.84913379e-01,  4.45327073e-01, -7.92018175e-01,\n",
       "        -3.60129744e-01, -5.80466747e-01, -1.92489505e-01,  4.15856421e-01,\n",
       "        -2.26936668e-01,  2.87099868e-01,  2.23115817e-01,  2.77427971e-01,\n",
       "        -4.59366143e-01, -4.55291092e-01,  3.21027011e-01,  2.48005033e-01,\n",
       "        -1.47222981e-01, -4.97339070e-01,  3.10131490e-01,  6.39766932e-01,\n",
       "         1.31248772e-01, -8.80643547e-01,  2.74162382e-01, -2.31851071e-01,\n",
       "        -3.03091824e-01, -4.14007753e-02,  1.95941865e-01, -3.09393197e-01,\n",
       "         2.29393691e-01, -4.32513207e-01, -7.82706663e-02,  7.65417516e-02,\n",
       "         1.34179860e-01,  3.55402440e-01,  1.69205010e-01,  8.63711298e-01,\n",
       "         3.50063831e-01, -4.40279469e-02, -9.01344478e-01,  2.63989568e-02,\n",
       "        -2.78980315e-01,  4.34704542e-01,  8.14384043e-01, -8.91986191e-01,\n",
       "        -6.88744962e-01,  6.16222203e-01,  1.13924396e+00,  5.19537866e-01,\n",
       "        -8.37931752e-01,  3.09368312e-01,  6.30427957e-01, -1.10480595e+00,\n",
       "         5.90722859e-02, -7.14452416e-02, -9.24422294e-02, -5.21551788e-01,\n",
       "         3.02107424e-01,  6.19477630e-01, -3.82043004e-01, -4.53852773e-01,\n",
       "         5.83492994e-01, -2.44722858e-01,  4.96255070e-01,  7.48545766e-01,\n",
       "         7.77805805e-01, -5.63156009e-01,  1.14000213e+00, -5.31222880e-01,\n",
       "         7.03502595e-01,  9.40881133e-01, -1.40090191e+00, -2.99445689e-01,\n",
       "         3.52125257e-01,  1.57771856e-01, -9.50680077e-01,  4.06508386e-01,\n",
       "        -1.02986336e+00,  8.23578358e-01, -1.79234207e-01, -8.31879377e-02,\n",
       "        -2.52255946e-01, -1.68312222e-01, -4.35264826e-01,  1.01626480e+00,\n",
       "         3.17887664e-01, -7.33033288e-03,  5.06844759e-01,  1.49133563e+00,\n",
       "         1.85552344e-01,  3.63761812e-01,  3.94512415e-01, -1.52876899e-01,\n",
       "         4.04026985e-01, -3.23206097e-01,  3.15391049e-02,  7.27796674e-01,\n",
       "         1.72097397e+00, -2.32478037e-01,  4.65726525e-01, -2.98632830e-01,\n",
       "         5.60695291e-01,  2.24446759e-01, -3.03330839e-01,  4.61736977e-01,\n",
       "         3.36963475e-01,  7.89721608e-01,  1.40470946e+00, -3.75586897e-01,\n",
       "        -5.95527291e-01,  3.15655112e-01,  3.43414485e-01,  1.27511293e-01,\n",
       "        -6.25307798e-01,  2.13733628e-01,  1.48065984e-01, -7.34093547e-01,\n",
       "        -6.84571341e-02, -7.14017868e-01, -1.65494949e-01,  6.16195425e-02,\n",
       "        -3.89909983e-01, -5.86887181e-01, -4.55221981e-01, -1.69298172e-01,\n",
       "         5.64329863e-01,  6.96997046e-01, -2.84756988e-01, -6.04262292e-01,\n",
       "        -2.14486375e-01, -6.05568290e-01,  3.44091356e-01, -6.77130818e-01,\n",
       "        -3.54398906e-01, -4.84710932e-02,  1.51721060e-01, -4.39760655e-01,\n",
       "         9.06487286e-01,  1.22158557e-01, -4.90492918e-02, -5.35835743e-01,\n",
       "         1.20539868e+00,  8.09238136e-01,  1.74691156e-01, -1.64131626e-01,\n",
       "        -1.24672927e-01,  4.64308381e-01, -6.57881916e-01,  9.11544561e-01,\n",
       "        -1.00508474e-01,  5.77838682e-02, -2.98434705e-01,  7.95158863e-01,\n",
       "         4.86934870e-01, -4.66168135e-01, -2.38464072e-01,  1.23191583e+00,\n",
       "        -1.02695212e-01,  2.43704990e-01,  5.38115129e-02,  3.33691388e-02,\n",
       "         3.12481612e-01, -1.24212429e-01, -1.22082375e-01,  7.82682776e-01,\n",
       "        -5.38013995e-01, -3.63457650e-01, -1.97694406e-01,  9.48480904e-01,\n",
       "        -9.58372951e-02, -6.45125806e-01,  1.65148526e-01,  4.60581869e-01,\n",
       "         6.05010986e-01, -1.29703626e-01, -1.70148596e-01,  1.28829986e-01,\n",
       "         7.21230209e-02,  2.43135452e-01,  3.42270374e-01,  5.36052465e-01,\n",
       "        -8.71829510e-01,  1.19933233e-01, -7.63774812e-01, -1.90970674e-02,\n",
       "        -7.69749939e-01,  3.09997588e-01, -3.75849038e-01, -5.90298891e-01,\n",
       "        -2.74046585e-02,  2.73615390e-01, -1.34821951e-01, -2.51138836e-01,\n",
       "         2.95306563e-01, -1.83274135e-01,  1.83106914e-01, -5.68414986e-01,\n",
       "        -2.66224623e-01, -2.44090244e-01,  2.88340956e-01,  2.82306761e-01,\n",
       "        -1.95522681e-01, -1.78492680e-01,  4.26197916e-01,  3.79507005e-01],\n",
       "       dtype=float32),\n",
       " array([ 2.74512112e-01, -4.26225662e-01,  5.72974682e-01,  2.54051015e-02,\n",
       "         2.30322242e-01,  1.11758992e-01,  3.38726908e-01, -8.06895196e-01,\n",
       "        -1.89685136e-01,  5.67737699e-01,  4.99465704e-01, -2.22940281e-01,\n",
       "        -6.89884797e-02,  3.35096031e-01, -2.22607061e-01,  7.04145968e-01,\n",
       "         1.15572669e-01, -6.35396719e-01, -9.71257865e-01, -2.38544419e-01,\n",
       "         2.88087577e-01,  6.87392578e-02,  9.53241996e-03,  5.69218874e-01,\n",
       "         6.74313188e-01, -2.23277718e-01, -1.01934850e-01,  2.09603041e-01,\n",
       "        -9.68517363e-02,  1.94736987e-01,  1.10781372e+00,  2.07509734e-02,\n",
       "        -1.34081706e-01, -3.52786005e-01, -4.06674296e-02, -6.53302252e-01,\n",
       "        -1.73040822e-01, -1.59133822e-01, -6.09662719e-02,  1.26290023e+00,\n",
       "        -6.24662377e-02,  6.44777000e-01,  5.28672516e-01, -1.78348690e-01,\n",
       "        -2.50133216e-01,  9.40364227e-02, -5.27399108e-02, -4.21056896e-01,\n",
       "         8.46338987e-01, -4.55614269e-01, -1.91263437e-01,  2.71546423e-01,\n",
       "        -3.43862861e-01,  1.26193523e-01,  1.84216172e-01,  9.78428721e-01,\n",
       "        -5.49701035e-01, -5.29281855e-01,  3.74328941e-01,  5.14134914e-02,\n",
       "        -6.51239306e-02, -1.94667205e-02,  4.63577777e-01, -7.45712876e-01,\n",
       "        -7.27854431e-01,  1.23629153e-01,  1.17762484e-01, -7.22036421e-01,\n",
       "        -4.21194881e-01, -1.53173000e-01, -2.87174076e-01,  1.62964016e-01,\n",
       "        -5.63505948e-01, -1.21104732e-01, -6.96410537e-01,  4.82981145e-01,\n",
       "        -6.92459762e-01,  3.12083185e-01,  2.10517943e-01, -3.86464633e-02,\n",
       "        -4.88995820e-01,  3.71734083e-01,  5.19110635e-02,  7.30029583e-01,\n",
       "         3.36067080e-01,  5.05063593e-01,  3.64885062e-01,  4.15394992e-01,\n",
       "         3.71866882e-01, -9.01634932e-01,  3.40453029e-01, -8.11894909e-02,\n",
       "        -3.28922600e-01,  8.80005583e-02, -1.28597245e-01, -1.13102742e-01,\n",
       "        -3.54428679e-01,  3.43050715e-03, -3.98837209e-01,  5.58444023e-01,\n",
       "         6.47843301e-01, -6.99292600e-01, -1.24156885e-01,  3.23299170e-02,\n",
       "        -6.68113083e-02,  3.15641582e-01, -1.48431987e-01,  1.59239173e-01,\n",
       "         3.49157333e-01,  1.12598276e+00, -1.24481976e-01, -5.64712524e-01,\n",
       "        -5.15548289e-01, -4.47532594e-01, -4.71102744e-01,  1.42875791e-01,\n",
       "        -4.16926071e-02,  3.49160641e-01, -1.36951447e-01, -3.24947357e-01,\n",
       "        -1.18412487e-01, -6.45950437e-01,  1.10430166e-01,  1.45953012e+00,\n",
       "         4.18240845e-01, -6.68320060e-01, -1.38937179e-02, -9.40658245e-03,\n",
       "        -3.28402460e-01,  2.84290314e-01, -9.50278267e-02, -7.71213369e-03,\n",
       "         1.75610155e-01, -4.57645297e-01, -1.16588421e-01,  3.21879506e-01,\n",
       "        -2.22103149e-01, -4.18173224e-01,  9.24943537e-02,  1.03902087e-01,\n",
       "        -3.68214339e-01,  2.26880297e-01, -2.99565464e-01,  1.95611566e-02,\n",
       "         1.79446653e-01, -1.12447999e-01,  5.05484827e-02,  1.97063401e-01,\n",
       "        -4.13982511e-01, -1.24059990e-01,  3.62030357e-01,  2.88616151e-01,\n",
       "        -3.25007066e-02, -4.70650196e-01, -4.06396925e-01, -3.00185233e-01,\n",
       "         7.79867992e-02, -1.86479092e-01, -4.54202622e-01, -7.54227161e-01,\n",
       "        -7.79073298e-01, -1.88009068e-02, -5.25975466e-01,  1.92578971e-01,\n",
       "        -5.75081348e-01, -5.03378361e-02,  3.11468124e-01,  3.45595241e-01,\n",
       "        -9.01130021e-01,  4.79579605e-02,  2.15164069e-02, -1.05861865e-01,\n",
       "         5.68407476e-01,  4.62796122e-01, -1.95604920e-01,  1.42144606e-01,\n",
       "         2.72852898e-01, -1.59310535e-01,  3.37526709e-01,  4.86649901e-01,\n",
       "         2.76626170e-01, -4.44746673e-01,  4.14035082e-01, -4.61935967e-01,\n",
       "         3.67338210e-01,  2.02440359e-02,  1.22308207e+00,  2.28340179e-02,\n",
       "        -5.35156131e-01,  5.00918806e-01,  3.48392963e-01, -1.38994396e-01,\n",
       "        -7.86732495e-01, -5.02417326e-01,  4.24977958e-01, -2.34858930e-01,\n",
       "         2.70747781e-01,  3.82895082e-01, -4.80425745e-01,  9.62061584e-02,\n",
       "         2.96021938e-01,  8.68576765e-02,  5.18183410e-03, -2.01594368e-01,\n",
       "        -5.51094770e-01, -4.13962245e-01, -1.18060455e-01, -5.29266655e-01,\n",
       "        -4.59649146e-01, -1.54051498e-01, -3.23739231e-01,  2.44259536e-01,\n",
       "        -9.52172130e-02,  4.55079317e-01,  2.15027809e-01, -6.28212020e-02,\n",
       "        -1.47249639e-01,  4.02256042e-01,  2.77950883e-01, -4.07945842e-01,\n",
       "         6.07134581e-01,  2.45095581e-01, -6.37906492e-02,  8.88650179e-01,\n",
       "        -4.39746499e-01,  1.20487177e+00,  6.46988630e-01, -5.33759356e-01,\n",
       "        -7.40959644e-01,  3.19931835e-01,  3.53049263e-02, -7.79400468e-02,\n",
       "        -2.23413110e-04, -2.80040324e-01, -2.35235348e-01, -9.12013501e-02,\n",
       "        -9.92121845e-02, -3.12888801e-01, -3.87539476e-01,  2.88279623e-01,\n",
       "        -3.86469603e-01, -3.05989206e-01,  1.86510563e-01,  1.54702798e-01,\n",
       "        -4.63218778e-01,  1.56580284e-01, -7.80455709e-01, -3.92206237e-02,\n",
       "         1.69438601e-01, -6.06846213e-02, -9.07114267e-01, -7.35159516e-02,\n",
       "        -2.00417072e-01, -5.77975452e-01,  1.82501554e-01,  1.51374012e-01,\n",
       "         1.68533668e-01,  8.10740814e-02, -2.94318020e-01, -1.53263003e-01,\n",
       "         9.61263895e-01, -7.26567388e-01, -2.36248851e-01, -1.98670238e-01,\n",
       "        -5.90809546e-02,  2.43155450e-01,  5.99010736e-02,  2.54456222e-01,\n",
       "        -1.52722690e-02,  4.57176983e-01,  2.75980756e-02,  8.41030851e-04,\n",
       "         1.38612628e-01,  1.29312992e+00, -2.88211197e-01, -5.59820414e-01,\n",
       "         3.56538832e-01,  2.40733802e-01,  5.17565489e-01, -1.06179619e+00,\n",
       "         6.53098881e-01,  1.65575236e-01,  6.04452938e-02, -1.32446170e-01,\n",
       "         1.53752059e-01, -1.47220373e-01,  1.18140556e-01,  1.15636981e+00,\n",
       "        -6.85656965e-01, -4.29402500e-01, -3.43505144e-02,  1.01284720e-01,\n",
       "        -9.72583890e-01, -1.53167382e-01,  3.60434443e-01,  5.36731720e-01,\n",
       "         2.04426706e-01,  4.48933780e-01,  3.42753053e-01, -3.21411550e-01,\n",
       "         1.21138848e-01, -3.47560346e-01,  6.73211634e-01, -1.89536393e-01,\n",
       "         4.61471170e-01,  3.45891267e-01, -3.25403303e-01, -8.24898556e-02,\n",
       "        -4.85743999e+00, -1.37726754e-01,  1.49050936e-01,  3.42560142e-01,\n",
       "        -6.54754415e-02,  4.32466865e-02, -1.62943751e-01, -2.85364926e-01,\n",
       "        -2.74994504e-03, -8.86181712e-01,  1.47202257e-02, -8.32056105e-02,\n",
       "         1.70595348e-01,  3.03582788e-01,  8.48363563e-02,  2.70417362e-01,\n",
       "        -2.57676840e-01, -1.42225966e-01, -4.43777233e-01,  4.57670242e-02,\n",
       "         1.90214068e-01, -4.01985228e-01,  5.86113691e-01,  1.53204620e-01,\n",
       "         6.21757150e-01, -1.93970650e-01, -4.67659473e-01,  5.89876175e-01,\n",
       "         6.65972352e-01,  8.72079059e-02, -1.18581021e+00, -1.22627534e-01,\n",
       "         9.84653771e-01,  1.02118337e+00,  2.98263505e-02,  7.63915405e-02,\n",
       "         7.06974491e-02, -6.96787834e-02,  1.12095594e-01,  8.26805890e-01,\n",
       "        -2.57142693e-01, -3.21777195e-01, -1.18381515e-01, -2.50764251e-01,\n",
       "         8.87596607e-01, -3.85070384e-01,  1.75140753e-01, -2.64752120e-01,\n",
       "         4.02824044e-01,  1.49916559e-01,  2.56243467e-01, -2.16357797e-01,\n",
       "        -2.28956044e-01, -8.91863406e-02,  1.30479708e-01,  8.95430371e-02,\n",
       "        -2.84153298e-02,  1.27535510e+00, -6.22215033e-01,  2.13072062e-01,\n",
       "        -2.73310781e-01, -2.20485270e-01, -7.99134493e-01,  4.92427349e-02,\n",
       "         5.33925176e-01,  1.64126784e-01, -8.53600562e-01, -7.79326618e-01,\n",
       "        -1.61315918e-01,  2.83698380e-01,  2.20306776e-02, -2.69006103e-01,\n",
       "         5.67716539e-01, -9.69270468e-01, -1.07859302e+00,  3.04259062e-01,\n",
       "         8.73596594e-02,  9.83625129e-02,  1.17740110e-01, -8.65902722e-01,\n",
       "        -2.61939615e-01, -8.11575830e-01, -1.34676069e-01,  8.73766661e-01,\n",
       "         2.44896084e-01, -2.84603179e-01, -3.43713127e-02,  1.24624558e-02,\n",
       "         1.50209025e-01, -3.50377798e-01, -1.60919547e-01, -7.98910335e-02,\n",
       "         8.96544829e-02, -3.19989204e-01, -5.18557489e-01,  2.30262846e-01,\n",
       "        -3.23726952e-01,  1.08688183e-01, -5.97472936e-02, -5.04540861e-01,\n",
       "        -1.67386085e-01, -1.63909979e-02,  1.94553837e-01,  2.71734893e-01,\n",
       "         7.11043417e-01,  5.83076179e-01, -1.62002981e-01, -2.46138304e-01,\n",
       "        -5.29419370e-02,  6.01179361e-01, -2.36253086e-02, -4.26954448e-01,\n",
       "         2.78626308e-02,  1.34426221e-01,  5.07717133e-01, -6.64885044e-01,\n",
       "        -5.37019193e-01,  8.92218053e-01,  8.66353571e-01,  1.02333546e-01,\n",
       "        -1.82436615e-01,  1.05575240e+00, -8.61517712e-02, -1.20468408e-01,\n",
       "        -1.00681037e-02, -1.99833717e-02, -7.67249584e-01, -2.23543853e-01,\n",
       "        -7.98249021e-02, -5.01878738e-01,  2.67009556e-01, -8.51754010e-01,\n",
       "         7.33488023e-01,  1.75379753e-01,  3.54014516e-01,  8.78819406e-01,\n",
       "         1.03314847e-01, -1.47004628e+00, -1.05681606e-01,  8.70758593e-01,\n",
       "         2.35838413e-01,  7.02688456e-01,  6.96801320e-02, -1.30057886e-01,\n",
       "         5.75956464e-01,  6.51820123e-01, -4.60173309e-01,  1.58384338e-01,\n",
       "         1.52382106e-01,  6.42122090e-01,  1.47843391e-01, -1.98538482e-01,\n",
       "        -9.03671756e-02,  1.54346526e-02,  6.26860142e-01, -4.44288313e-01,\n",
       "         1.16187501e+00,  2.41238892e-01, -1.66423216e-01, -1.05267847e+00,\n",
       "         3.83326858e-01,  4.48704779e-01,  1.13717943e-01,  5.83531678e-01,\n",
       "        -2.54057437e-01,  2.78103232e-01, -3.13640088e-01, -5.12831330e-01,\n",
       "         6.60674646e-03,  6.20215714e-01,  2.50624001e-01, -5.55782259e-01,\n",
       "        -8.43766332e-02, -7.80410469e-02,  3.15943480e-01,  6.72006071e-01,\n",
       "        -1.33163467e-01,  5.36216907e-02, -3.21875840e-01,  5.06563485e-01,\n",
       "        -1.15714833e-01,  1.06953643e-01,  4.93582189e-01, -7.69282039e-03,\n",
       "         3.87095869e-01,  5.28287053e-01, -3.51567417e-01,  1.37219084e-02,\n",
       "        -4.63585287e-01, -2.27852792e-01, -1.65101123e+00,  1.18221521e+00,\n",
       "         6.37971759e-01, -4.46946532e-01, -3.11223790e-02, -3.96006852e-01,\n",
       "         4.97259259e-01, -1.45168412e+00,  3.13698441e-01, -3.24465074e-02,\n",
       "         4.15988475e-01,  2.35108703e-01,  2.78254688e-01,  4.89025086e-01,\n",
       "         8.25807452e-02, -4.49041426e-01,  1.49314359e-01,  4.89921421e-02,\n",
       "        -4.51437905e-02,  4.26412784e-02,  1.35165274e-01, -7.87324429e-01,\n",
       "        -6.51973367e-01, -1.60836190e-01,  2.93687463e-01,  6.84339702e-02,\n",
       "         1.14903644e-01, -6.22146606e-01, -5.63779399e-02,  8.97188365e-01,\n",
       "        -2.46645823e-01,  3.52094233e-01,  4.95491803e-01, -4.67401296e-02,\n",
       "        -7.00682700e-01, -1.14461446e+00, -2.70769566e-01,  4.39249545e-01,\n",
       "        -5.77297628e-01,  6.64941519e-02, -1.10859737e-01, -1.24823248e+00,\n",
       "        -4.35785465e-02, -7.91261554e-01,  3.73887420e-01,  9.08306241e-01,\n",
       "        -7.25193143e-01, -4.17777121e-01, -5.23269996e-02,  3.36727798e-01,\n",
       "        -2.68390656e-01, -4.23169464e-01, -4.51764055e-02, -2.63282478e-01,\n",
       "         9.14163068e-02,  5.49241483e-01, -4.59653199e-01,  3.35248709e-02,\n",
       "        -8.91587138e-01, -7.51771033e-04, -2.86353767e-01, -2.21594870e-01,\n",
       "        -1.51978314e-01, -7.18329608e-01,  1.41069606e-01, -3.38034421e-01,\n",
       "         1.29637033e-01,  5.69657683e-01, -1.23854250e-01, -2.82922149e-01,\n",
       "        -5.68356216e-01,  6.97898194e-02,  1.40695460e-02,  3.08843136e-01,\n",
       "        -3.32704723e-01,  1.84100568e-01,  7.90362358e-01,  8.86825204e-01,\n",
       "         3.66377950e-01, -1.24158919e+00, -2.80330122e-01,  1.11841768e-01,\n",
       "         5.20611942e-01, -4.14139926e-01, -4.26654428e-01,  4.62028742e-01,\n",
       "        -3.86394888e-01, -6.24327421e-01,  1.43648684e-01,  5.49921989e-01,\n",
       "        -5.03643811e-01,  5.45661092e-01, -1.05181322e-01, -1.66378230e-01,\n",
       "        -2.15424225e-03,  1.77187145e-01,  2.86205649e-01, -6.80316746e-01,\n",
       "        -6.88710630e-01,  5.14206946e-01,  5.30471504e-01, -4.19051275e-02,\n",
       "        -6.16772234e-01, -8.60094845e-01,  4.21783209e-01,  1.01264119e-01,\n",
       "         2.04098091e-01,  7.97667801e-02,  7.13597178e-01,  2.56981194e-01,\n",
       "        -5.31182587e-01,  2.84503251e-01, -2.32036933e-01,  2.38144532e-01,\n",
       "         2.08734125e-01,  7.02429831e-01,  4.19822261e-02, -7.51746833e-01,\n",
       "        -8.50858390e-02, -1.52468562e-01, -4.46301460e-01, -3.31168234e-01,\n",
       "         2.14760259e-01,  8.43247592e-01, -3.16254914e-01, -3.46103877e-01,\n",
       "         6.29937947e-01,  1.04285955e+00, -5.32765388e-02,  4.35957223e-01,\n",
       "         1.77756622e-01,  3.82066965e-01, -3.75672221e-01,  2.09753022e-01,\n",
       "         5.21122277e-01,  1.13654840e+00, -7.32814193e-01,  1.84947833e-01,\n",
       "         1.15932025e-01,  2.42871523e-01, -4.40883726e-01, -1.59428626e-01,\n",
       "        -3.78993869e-01, -1.94859341e-01, -2.17458144e-01, -1.38908818e-01,\n",
       "         7.32945323e-01,  8.49812508e-01,  4.70877409e-01,  9.51393187e-01,\n",
       "         9.32842076e-01,  1.70651935e-02, -2.96060920e-01,  3.84975314e-01,\n",
       "        -7.60308564e-01, -3.73308569e-01,  2.35138327e-01, -7.88256079e-02,\n",
       "         2.97319479e-02, -5.37132248e-02,  9.57366601e-02,  6.78796470e-01,\n",
       "         4.12231445e-01,  2.76226431e-01, -8.58848244e-02,  8.79533589e-02,\n",
       "         3.93436939e-01,  1.29703060e-03,  1.23990327e-02,  5.50919116e-01,\n",
       "        -7.80741423e-02,  1.26914740e-01,  1.67832330e-01, -3.91443223e-01,\n",
       "         1.61210492e-01,  4.68182802e-01, -1.11425988e-01, -4.87402201e-01,\n",
       "         6.96737245e-02,  3.66339087e-01, -4.11681086e-02, -6.14223063e-01,\n",
       "         1.63709551e-01, -5.22114933e-01,  3.12365443e-01,  3.47805440e-01,\n",
       "         1.54349297e-01, -2.24243611e-01, -6.95901692e-01,  1.20379484e+00,\n",
       "        -8.44575837e-02,  5.51364958e-01,  7.50783011e-02,  1.33606791e-01,\n",
       "        -4.46849793e-01,  2.54813731e-01, -2.57781416e-01, -3.88277546e-02,\n",
       "        -1.68599010e-01, -4.64641541e-01, -8.82660225e-02,  2.35623330e-01,\n",
       "         8.22280467e-01, -3.29822302e-01, -4.20018971e-01,  9.27812681e-02,\n",
       "         5.98028153e-02,  3.21935043e-02,  6.29527390e-01, -1.53521374e-02,\n",
       "        -9.53963399e-01,  5.20946011e-02, -1.19553900e+00, -4.07975018e-01,\n",
       "        -2.87693501e-01,  3.58274043e-01,  1.40648231e-01,  5.96098423e-01,\n",
       "         7.10018873e-01, -8.10223401e-01, -9.56120193e-01,  7.34609962e-01,\n",
       "        -5.83184481e-01,  6.40192688e-01, -1.58957392e-01, -1.75746635e-01,\n",
       "        -5.27725101e-01, -1.85072958e-01, -1.95615739e-03, -4.91548061e-01,\n",
       "        -5.26209474e-01, -7.01111853e-02, -3.23278368e-01,  9.74982738e-01,\n",
       "         2.15078354e-01,  1.32319510e-01, -5.31793594e-01,  3.50295119e-02,\n",
       "         2.34492660e-01,  1.92946076e-01, -5.62151730e-01,  1.34156555e-01,\n",
       "        -4.82631922e-01,  3.83936428e-03,  1.63714021e-01, -2.42333263e-01,\n",
       "        -1.47574738e-01,  1.17257521e-01, -3.89027059e-01,  1.91333637e-01,\n",
       "        -7.18563139e-01,  6.68454826e-01, -9.12140846e-01,  6.71492219e-01,\n",
       "         2.53298640e-01,  2.35328197e-01, -7.00896740e-01, -9.27674234e-01,\n",
       "        -2.72744477e-01,  7.01861363e-03, -1.51015788e-01, -1.53764516e-01,\n",
       "         9.03812423e-02, -9.73512650e-01, -2.67778158e-01, -4.91296947e-01,\n",
       "         1.70608819e-01, -2.67526656e-01,  2.29523212e-01, -7.55910218e-01],\n",
       "       dtype=float32),\n",
       " array([-9.26766813e-01, -4.82310444e-01,  4.02568012e-01,  3.25135440e-01,\n",
       "         7.31130242e-02, -9.00134221e-02, -4.95494157e-01,  5.77262521e-01,\n",
       "         1.76989108e-01, -1.41824865e+00,  1.52699068e-01, -3.27498972e-01,\n",
       "         4.61476147e-01,  1.08887005e+00,  4.17560991e-03,  1.07287931e+00,\n",
       "         5.83791912e-01, -6.20298162e-02, -7.61379898e-01,  7.76317596e-01,\n",
       "         1.31226659e-01, -3.67255121e-01, -3.04948002e-01, -6.57078251e-03,\n",
       "         7.09009886e-01,  2.26417020e-01,  1.80246532e-02,  2.14166164e-01,\n",
       "        -1.57840624e-02, -6.78075731e-01, -2.44283959e-01,  4.71692793e-02,\n",
       "         2.18927801e-01, -6.64348185e-01, -7.21589565e-01, -4.49142873e-01,\n",
       "         1.49457440e-01, -4.80858684e-01, -4.74377811e-01,  3.23764384e-01,\n",
       "        -1.11879241e+00, -5.22085607e-01, -8.65936041e-01, -1.02981456e-01,\n",
       "        -4.59651165e-02, -1.58771247e-01,  3.64610434e-01, -5.27550101e-01,\n",
       "        -1.42614052e-01, -8.19433630e-01, -1.18261233e-01, -7.18723953e-01,\n",
       "        -3.79362434e-01, -1.11611605e-01, -5.03045768e-02,  3.53236407e-01,\n",
       "         2.12378189e-01, -5.48877180e-01, -1.98030710e-01,  5.52349389e-01,\n",
       "         4.65633094e-01, -2.06989273e-01,  6.15976095e-01, -9.09184337e-01,\n",
       "         1.77113652e-01,  8.41133893e-02, -1.25934422e-01,  5.90286292e-02,\n",
       "         2.74222046e-02, -5.87783992e-01, -1.63145602e-01, -6.17413640e-01,\n",
       "        -2.54176199e-01, -4.29988980e-01, -5.66020310e-01, -9.10943747e-01,\n",
       "         3.01929474e-01, -1.43382967e-01,  5.51119745e-01,  1.26062596e+00,\n",
       "        -7.13577121e-03,  1.13968754e+00,  7.25742653e-02,  7.82299519e-01,\n",
       "        -4.22353819e-02,  4.70700741e-01, -3.87537807e-01,  2.32093289e-01,\n",
       "         4.36380088e-01, -8.41591299e-01,  1.23454392e-01, -2.71966815e-01,\n",
       "         4.80277717e-01,  4.27399337e-01,  1.21776640e-01, -8.23983312e-01,\n",
       "         2.72248328e-01, -2.42739961e-01, -2.80331988e-02,  8.01862359e-01,\n",
       "         1.67486042e-01, -6.18013024e-01,  7.15068221e-01, -4.93351333e-02,\n",
       "         2.38313973e-01,  3.06746066e-01,  4.48067546e-01,  3.01666856e-02,\n",
       "         1.05853289e-01, -1.58692256e-01, -2.80660331e-01, -6.14466190e-01,\n",
       "        -4.98531282e-01,  1.87335476e-01,  2.28652760e-01,  5.72779000e-01,\n",
       "        -3.68191630e-01, -5.90569340e-02,  6.36125922e-01,  1.29852027e-01,\n",
       "        -7.07801059e-03, -1.25816274e+00,  6.26026452e-01,  5.80022156e-01,\n",
       "         4.44812953e-01, -5.04967213e-01, -5.50256312e-01,  4.42112803e-01,\n",
       "         1.02699414e-01, -3.91058415e-01,  7.13141188e-02,  5.99963777e-02,\n",
       "        -4.80244383e-02, -1.07909060e+00,  2.65895486e-01, -9.00336951e-02,\n",
       "        -4.14653212e-01, -8.76743674e-01, -4.75688010e-01, -4.60810483e-01,\n",
       "         6.45444810e-01, -1.50858834e-01, -4.31909785e-02, -1.43091455e-01,\n",
       "        -8.96571159e-01, -4.50607598e-01, -7.78926909e-01,  1.12565525e-01,\n",
       "         5.89688420e-02,  1.20342016e-01,  2.59324074e-01, -1.29229784e-01,\n",
       "        -7.00881302e-01, -7.36324668e-01,  3.26835215e-01, -1.25406951e-01,\n",
       "        -6.00354075e-01,  6.47242293e-02,  6.17494807e-02, -3.94896924e-01,\n",
       "        -6.34522289e-02, -2.32274801e-01,  2.58927792e-01, -3.37287158e-01,\n",
       "        -3.31668317e-01, -2.48809934e-01, -3.12521040e-01,  3.15377921e-01,\n",
       "         4.62519854e-01,  4.96250182e-01, -5.22060171e-02, -2.12043375e-01,\n",
       "         8.06401670e-01,  2.53990561e-01,  4.67738867e-01,  1.10526986e-01,\n",
       "         8.47045600e-01,  7.68400580e-02,  4.37279671e-01,  1.48842409e-02,\n",
       "        -3.82842422e-01,  7.62824774e-01,  3.01039428e-01,  9.47389454e-02,\n",
       "         2.38661408e-01,  5.09596169e-01,  2.15078950e-01,  2.21038088e-01,\n",
       "        -2.45299876e-01, -2.11516708e-01,  2.66466200e-01,  4.60509360e-01,\n",
       "        -6.34210765e-01,  2.30618969e-01, -9.88283038e-01, -9.57857609e-01,\n",
       "        -1.52105168e-01,  1.01597941e+00, -8.68452251e-01,  3.26532632e-01,\n",
       "         6.35557711e-01, -1.99377332e-02,  1.04648836e-01,  5.18448830e-01,\n",
       "         8.77600983e-02, -6.41797006e-01,  8.35237980e-01, -4.78480577e-01,\n",
       "        -3.88604760e-01,  3.19985956e-01, -1.16248347e-01,  8.57170641e-01,\n",
       "         8.04830372e-01, -7.10763037e-02,  1.39775082e-01,  4.74931866e-01,\n",
       "        -1.84615195e-01,  7.59776890e-01,  1.97298512e-01,  5.81718087e-01,\n",
       "         2.65055239e-01,  3.35437298e-01, -9.14238393e-01,  1.23259500e-01,\n",
       "         3.95919055e-01,  3.55924547e-01,  1.82075858e-01, -2.86262751e-01,\n",
       "         6.91213071e-01,  8.65310609e-01, -4.43233997e-01,  1.54306158e-01,\n",
       "        -1.63535520e-01,  2.53999203e-01,  1.93795949e-01,  2.25406766e-01,\n",
       "         3.54856223e-01,  7.66429901e-02,  7.42729127e-01, -3.41128647e-01,\n",
       "        -1.63134128e-01,  1.13266993e+00,  8.07947576e-01,  1.00520551e-01,\n",
       "        -5.24443746e-01,  4.11451489e-01, -6.50526360e-02, -2.21227765e-01,\n",
       "        -7.11968541e-01,  3.14701319e-01, -2.95387000e-01, -5.62259972e-01,\n",
       "        -1.99095845e-01, -3.35724801e-01, -5.91594219e-01,  2.65562907e-02,\n",
       "        -1.20918371e-01, -3.15333486e-01,  5.64096034e-01,  6.69530407e-03,\n",
       "         4.99612242e-02, -2.68167436e-01,  1.79847509e-01,  2.62912571e-01,\n",
       "         6.97031468e-02, -6.49443209e-01, -5.26791036e-01,  7.80334547e-02,\n",
       "         2.42113978e-01,  1.22069657e+00, -9.49797630e-02,  9.93783534e-01,\n",
       "         1.43791819e-02,  6.02075338e-01, -2.82458484e-01,  6.41468287e-01,\n",
       "        -4.62135762e-01,  3.57180536e-01, -9.39470947e-01, -2.97676146e-01,\n",
       "         6.30511165e-01,  5.35208225e-01, -6.18531764e-01, -4.37996417e-01,\n",
       "         4.68295962e-01, -7.60395348e-01,  2.65209228e-02, -7.88381100e-02,\n",
       "        -7.33607531e-01, -2.58105665e-01,  5.90425551e-01,  4.58647341e-01,\n",
       "        -5.11197090e-01, -4.09658581e-01,  9.26405370e-01,  3.56100380e-01,\n",
       "         2.89692014e-01,  6.92465305e-01, -2.74702013e-01, -4.82803792e-01,\n",
       "        -1.09161067e+00, -7.87246943e-01, -1.68074220e-01, -8.52989852e-02,\n",
       "         2.01986492e-01,  2.56765872e-01,  1.35930681e+00, -1.22163308e+00,\n",
       "        -4.27315569e+00,  4.23758239e-01,  4.60207492e-01, -1.82529762e-01,\n",
       "         3.80399466e-01, -3.37686151e-01, -1.77072257e-01, -2.58201748e-01,\n",
       "        -6.01878762e-01, -4.51728940e-01,  8.88876431e-03, -3.79913807e-01,\n",
       "         8.45349908e-01,  4.04301733e-01,  6.19332552e-01,  1.67573482e-01,\n",
       "        -8.68480086e-01, -8.34029615e-01, -7.81379789e-02,  6.09482646e-01,\n",
       "        -5.04414976e-01, -1.41144407e+00,  4.84224021e-01,  3.13075900e-01,\n",
       "         3.94281805e-01,  4.73279119e-01, -2.14320317e-01, -7.32832432e-01,\n",
       "        -8.15919280e-01, -2.24247411e-01, -5.31868041e-01, -4.01483625e-01,\n",
       "         2.14158237e-01,  1.18385233e-01,  3.23506474e-01, -3.64389211e-01,\n",
       "         8.38011354e-02, -5.27053475e-01,  4.19929236e-01,  9.43512321e-02,\n",
       "        -2.44771987e-01, -6.38801932e-01, -4.14219797e-01, -2.10902408e-01,\n",
       "         4.01142925e-01, -4.68084633e-01,  8.64097357e-01,  2.77000427e-01,\n",
       "        -1.05757095e-01, -1.47507980e-01, -2.95999080e-01,  5.37537217e-01,\n",
       "        -4.70924616e-01, -3.57938141e-01, -8.48334134e-01,  7.94854164e-01,\n",
       "         1.10614300e-01, -4.71309364e-01,  3.28868508e-01, -4.34913449e-02,\n",
       "         1.38403848e-01, -3.40775937e-01, -5.63201427e-01,  4.42484081e-01,\n",
       "         6.27768993e-01,  4.76139523e-02, -3.26743871e-02, -5.94552636e-01,\n",
       "         2.27223843e-01,  1.02334511e+00,  3.43370706e-01,  3.96377981e-01,\n",
       "        -1.40609890e-01, -1.30288076e+00, -5.64780295e-01, -2.68451214e-01,\n",
       "        -4.85885054e-01, -6.90246522e-01,  2.12831259e-01, -2.93251544e-01,\n",
       "        -1.56583345e+00, -3.66970241e-01, -6.67673647e-02,  9.97494936e-01,\n",
       "         2.24460363e-01, -6.85170591e-01, -8.22173893e-01, -2.88112402e-01,\n",
       "        -2.34632432e-01, -1.58432066e-01, -6.33988261e-01,  8.78808439e-01,\n",
       "        -1.09565154e-01,  5.27544796e-01,  4.28296834e-01, -1.29980460e-01,\n",
       "        -3.31269443e-01,  6.70571685e-01,  2.26475015e-01, -1.33314371e-01,\n",
       "         4.82740998e-02, -1.05836213e+00,  8.99660110e-01,  7.00188652e-02,\n",
       "        -7.42522478e-02,  3.73254538e-01,  1.88448668e-01,  2.44251624e-01,\n",
       "         1.32108163e-02,  1.08986199e-02,  3.98210049e-01,  2.07210332e-02,\n",
       "         1.00232446e+00, -8.66211295e-01,  3.85674983e-01, -7.10723817e-01,\n",
       "        -2.12400347e-01,  1.16289985e+00,  2.30420157e-01, -2.94662297e-01,\n",
       "        -4.86958921e-01,  2.36228496e-01, -6.97474241e-01,  6.98032528e-02,\n",
       "         3.12889934e-01, -1.83306821e-03, -1.51299804e-01, -5.22918403e-01,\n",
       "        -6.16970658e-01, -8.40548277e-01,  3.22652787e-01, -2.16274604e-01,\n",
       "        -6.65662408e-01, -1.44956291e-01,  6.97248936e-01,  5.01715779e-01,\n",
       "        -5.49086392e-01, -8.92217457e-01, -1.28746063e-01, -6.78543448e-02,\n",
       "         6.78146064e-01,  2.77283192e-01, -2.30982527e-01, -7.12296486e-01,\n",
       "        -6.52826905e-01,  7.29944825e-01, -2.43846446e-01,  3.56689423e-01,\n",
       "         2.89695635e-02,  1.07831764e+00,  8.04199651e-02, -5.37061810e-01,\n",
       "        -1.01492472e-01, -5.40543854e-01,  3.34709287e-01, -6.00069202e-02,\n",
       "        -7.12642521e-02,  2.82591701e-01, -1.51636243e-01,  5.40608406e-01,\n",
       "         9.79835913e-03,  6.53791949e-02,  1.38665259e+00,  3.62705439e-01,\n",
       "        -8.60125665e-03,  3.48909855e-01, -4.94079106e-03, -1.08394682e-01,\n",
       "         1.03010565e-01,  7.01992571e-01, -6.76426589e-01, -2.22106397e-01,\n",
       "        -2.81399310e-01, -2.76382625e-01, -4.99122918e-01,  5.29662728e-01,\n",
       "        -2.90562391e-01,  1.94240928e-01, -7.58979321e-01, -2.37653539e-01,\n",
       "        -7.36768171e-02,  5.66981792e-01,  6.23556554e-01,  3.29609931e-01,\n",
       "         2.39923224e-01,  3.09604615e-01, -4.70833033e-01, -2.83263266e-01,\n",
       "         4.53746647e-01, -2.10717618e-01, -2.60358006e-02,  9.15441513e-02,\n",
       "         2.26803407e-01,  2.63629079e-01, -5.34452438e-01,  4.27689284e-01,\n",
       "         6.93239495e-02,  1.90097302e-01,  3.20024759e-01, -1.17595002e-01,\n",
       "        -1.32362023e-01, -7.90958107e-01, -7.01386988e-01,  1.15574253e+00,\n",
       "        -1.54640734e+00,  2.14569062e-01,  1.03917778e+00, -1.69096142e-03,\n",
       "         4.91364002e-01,  2.35571176e-01,  2.42396504e-01, -3.18368971e-01,\n",
       "        -2.52894372e-01, -1.02698877e-02, -3.26802999e-01,  1.86315909e-01,\n",
       "        -4.60116923e-01, -3.92517596e-01, -3.42445791e-01,  1.98830087e-02,\n",
       "        -5.80977321e-01, -4.46324915e-01,  8.63751471e-02, -3.83219153e-01,\n",
       "        -4.57542390e-01, -2.33569086e-01,  1.84049428e-01,  5.94912291e-01,\n",
       "        -1.35278273e+00, -3.28393370e-01,  9.68057215e-01, -4.58163098e-02,\n",
       "         1.16302609e-01, -3.74844760e-01, -1.86597779e-02, -2.03841459e-02,\n",
       "        -1.24914563e+00, -7.05661058e-01, -8.38226900e-02, -3.93025279e-01,\n",
       "        -1.31092936e-01, -2.41838142e-01, -3.99680920e-02, -6.29760504e-01,\n",
       "        -5.07507741e-01,  6.43067300e-01, -9.53282475e-01,  3.93004864e-01,\n",
       "        -6.38655797e-02,  4.52875167e-01, -2.09263712e-01, -1.78935468e-01,\n",
       "         5.08943081e-01, -5.46261966e-01,  2.26352289e-01,  3.68709862e-02,\n",
       "        -3.80206496e-01,  1.84162900e-01,  4.19432551e-01, -8.05081606e-01,\n",
       "        -1.11664161e-01, -3.62003326e-01, -1.28801286e-01,  2.35708565e-01,\n",
       "        -4.02573943e-01,  2.01392800e-01,  1.17192820e-01,  1.43956691e-02,\n",
       "        -5.73992968e-01, -2.58954912e-01,  4.85395133e-01,  4.71334159e-01,\n",
       "        -2.52160192e-01, -5.51482975e-01,  7.20891654e-01,  5.17147005e-01,\n",
       "         2.01102406e-01, -8.90674829e-01,  5.30366421e-01, -9.93003994e-02,\n",
       "        -2.13140994e-01, -1.13488138e-01,  2.65980363e-01, -1.16968900e-01,\n",
       "         7.52095878e-02, -4.30871218e-01, -3.49975348e-01,  1.27257243e-01,\n",
       "        -1.30102830e-02,  3.87633085e-01, -8.98519605e-02,  9.70867038e-01,\n",
       "         6.02210283e-01,  2.70375431e-01, -9.97856915e-01,  7.54214674e-02,\n",
       "        -2.45849378e-02,  4.13148135e-01,  8.55723619e-01, -1.05951464e+00,\n",
       "        -5.11280954e-01,  7.05885828e-01,  8.60262632e-01,  5.39035022e-01,\n",
       "        -8.52713943e-01,  3.67731810e-01,  6.11192942e-01, -8.42221022e-01,\n",
       "        -1.00818865e-01,  1.54764503e-01,  1.21026784e-02, -5.12568295e-01,\n",
       "         3.33667994e-01,  7.54291713e-01, -3.85759532e-01, -6.14382625e-01,\n",
       "         5.39678931e-01, -1.61207020e-01,  5.67116261e-01,  8.44443381e-01,\n",
       "         7.74368942e-01, -3.26179683e-01,  1.20427620e+00, -4.45432782e-01,\n",
       "         6.69911861e-01,  6.77099109e-01, -8.54406595e-01, -3.20144176e-01,\n",
       "         4.29225147e-01, -2.83578932e-02, -9.20046568e-01,  6.88254356e-01,\n",
       "        -9.73869264e-01,  6.35502160e-01, -1.93311170e-01,  1.23234481e-01,\n",
       "        -3.08804989e-01, -1.96625963e-01, -4.23965037e-01,  8.38456571e-01,\n",
       "         2.07402617e-01,  2.21806094e-01,  5.19514859e-01,  1.12019694e+00,\n",
       "         2.75213271e-01,  5.91432631e-01,  3.21031958e-01, -1.26089558e-01,\n",
       "         2.06973612e-01, -2.31821552e-01,  8.31627399e-02,  6.30918682e-01,\n",
       "         1.47076106e+00, -2.89264582e-02,  3.59134048e-01, -2.96048969e-01,\n",
       "         5.16921163e-01,  1.79943576e-01, -3.41150999e-01,  4.18742895e-01,\n",
       "         4.10106480e-01,  8.06494117e-01,  1.40478694e+00, -1.56965896e-01,\n",
       "        -4.57431853e-01,  1.80195794e-01,  7.45687842e-01,  6.68157488e-02,\n",
       "        -4.22193617e-01,  1.86440930e-01,  3.80147934e-01, -4.98128712e-01,\n",
       "        -6.37121052e-02, -8.55451465e-01, -2.39885196e-01,  2.94360220e-02,\n",
       "        -2.78486133e-01, -7.61411905e-01, -3.54638696e-01, -1.72995061e-01,\n",
       "         4.43257391e-01,  4.88987207e-01, -4.24724966e-01, -5.98039448e-01,\n",
       "        -3.30051541e-01, -5.42868614e-01,  1.20295033e-01, -9.08183575e-01,\n",
       "        -4.90296960e-01,  6.33306801e-04,  2.47385323e-01, -5.04705846e-01,\n",
       "         6.25020087e-01, -1.21269405e-01,  2.68076882e-02, -6.81732535e-01,\n",
       "         1.25878406e+00,  5.20561099e-01,  2.48073190e-01, -4.10355449e-01,\n",
       "         2.78311595e-02,  6.65873945e-01, -4.75959629e-01,  5.97204268e-01,\n",
       "        -1.03015751e-02, -9.39218998e-02, -1.25618845e-01,  6.33164287e-01,\n",
       "         2.60328054e-01, -5.37085906e-02, -2.95228601e-01,  1.30774951e+00,\n",
       "        -1.94627136e-01,  3.36101949e-01,  5.67985699e-02,  2.08518043e-01,\n",
       "         3.65005493e-01, -5.79150915e-01, -7.45664015e-02,  3.83022130e-01,\n",
       "        -4.01311636e-01, -3.82228851e-01, -3.76042068e-01,  1.08998597e+00,\n",
       "        -1.91620350e-01, -2.84906507e-01,  1.58202142e-01,  2.92517066e-01,\n",
       "         4.59649056e-01,  1.62967257e-02, -3.29822421e-01, -8.33978653e-02,\n",
       "         1.60794571e-01,  2.63621747e-01,  4.02222186e-01,  8.44089150e-01,\n",
       "        -8.95745695e-01,  3.98335010e-01, -5.82860589e-01, -2.20626295e-01,\n",
       "        -7.18958497e-01,  5.38470030e-01, -4.11685705e-01, -7.67604649e-01,\n",
       "        -2.92140990e-02,  2.60460407e-01,  7.77724981e-02, -1.15505464e-01,\n",
       "         4.10516292e-01,  2.98889726e-03, -1.04236141e-01, -5.75002789e-01,\n",
       "        -2.68209934e-01, -1.79917395e-01,  1.39103860e-01,  2.86531836e-01,\n",
       "        -3.44792455e-01, -2.85072416e-01,  4.59470183e-01,  5.09635329e-01],\n",
       "       dtype=float32),\n",
       " array([-7.74148941e-01, -5.28416574e-01,  2.17746273e-01,  7.88041726e-02,\n",
       "        -1.99940428e-03, -9.17609692e-01, -2.97813773e-01, -4.51162189e-01,\n",
       "        -1.09810337e-01,  6.74657941e-01,  1.67750537e-01, -1.74799506e-02,\n",
       "        -1.61137804e-01, -3.56410816e-02,  2.02944413e-01,  2.95950115e-01,\n",
       "        -1.86719641e-01, -5.51133871e-01, -4.18219715e-01, -3.52657735e-02,\n",
       "         3.01728070e-01, -3.06671202e-01, -7.07531571e-01,  3.30880806e-02,\n",
       "         8.19369912e-01,  4.24296618e-01, -3.15263346e-02,  4.63495672e-01,\n",
       "        -1.37713507e-01, -6.22405410e-01,  7.21375704e-01, -9.66179371e-02,\n",
       "        -6.44106418e-02,  1.11837260e-01,  1.59542874e-01, -4.88165975e-01,\n",
       "        -5.23438752e-01, -1.47382542e-01, -6.24658167e-01,  9.27161932e-01,\n",
       "         1.82425201e-01, -6.10635877e-02,  3.03529173e-01, -5.72456479e-01,\n",
       "         1.77713692e-01, -3.79446268e-01,  3.35475326e-01, -5.57688773e-02,\n",
       "        -6.16644263e-01, -6.74431980e-01, -3.41727436e-01, -3.40864390e-01,\n",
       "        -6.93741083e-01,  4.03928868e-02, -3.19871604e-02,  5.92254639e-01,\n",
       "        -1.28249943e-01, -1.46558970e-01,  5.28587103e-01, -4.11979735e-01,\n",
       "         5.30141413e-01,  2.16147199e-01,  3.04120004e-01, -2.63194233e-01,\n",
       "        -2.82344550e-01,  4.95370865e-01,  2.44309276e-01, -1.06770456e+00,\n",
       "        -7.02100098e-02,  8.74592125e-01, -4.53006566e-01,  2.52671331e-01,\n",
       "        -2.55820632e-01,  1.68672249e-01, -3.29777420e-01,  3.75395387e-01,\n",
       "         1.77938323e-02,  3.44535887e-01,  3.49659204e-01,  1.67303488e-01,\n",
       "        -4.89793211e-01,  1.98902413e-02,  8.75416920e-02, -8.32078755e-02,\n",
       "         6.14835024e-01,  2.34845713e-01,  1.61280319e-01, -9.18169245e-02,\n",
       "         4.27640408e-01,  1.99865013e-01, -3.35428230e-02,  8.30273256e-02,\n",
       "        -4.61446121e-03, -2.01534033e-01,  4.83960547e-02, -5.09101570e-01,\n",
       "        -6.25009120e-01, -6.55894428e-02, -1.25506625e-01,  4.86598238e-02,\n",
       "         4.41356242e-01, -1.26257539e-01, -5.77153504e-01, -2.09032930e-02,\n",
       "        -4.47784811e-01,  2.30969056e-01, -1.62969694e-01, -2.54705884e-02,\n",
       "         1.91060722e-01,  9.99722838e-01,  3.94352913e-01, -5.48781037e-01,\n",
       "         2.10712209e-01, -4.62314129e-01, -3.51168603e-01,  7.17018723e-01,\n",
       "        -2.62731552e-01, -2.41104335e-01,  2.48548687e-01, -1.84851244e-01,\n",
       "        -7.00116217e-01, -7.32997954e-01,  5.08806109e-01,  9.98954594e-01,\n",
       "        -2.30370387e-02, -4.62116957e-01,  4.82429117e-02, -4.81373489e-01,\n",
       "         1.01549074e-01, -3.40032205e-02,  2.13398226e-02,  2.96531301e-02,\n",
       "        -3.07817049e-02,  2.11947024e-01, -4.09001887e-01,  4.25581932e-01,\n",
       "         4.54853654e-01, -4.64161724e-01,  2.65286863e-01, -6.38984799e-01,\n",
       "        -2.43733287e-01,  3.97283524e-01,  2.24516779e-01,  2.92394429e-01,\n",
       "        -1.24913141e-01, -3.11531991e-01,  1.44066468e-01,  4.96675968e-02,\n",
       "        -2.75720209e-01, -7.86621034e-01, -1.70352876e-01, -6.68940246e-02,\n",
       "         6.93463609e-02, -2.15919852e-01, -1.07860476e-01, -1.80444360e-01,\n",
       "         8.42237100e-03, -2.27177352e-01,  1.09074734e-01, -5.26983500e-01,\n",
       "        -1.11971654e-01,  4.96330261e-01, -5.75543404e-01,  6.59769058e-01,\n",
       "        -4.80683625e-01,  1.67827532e-02, -3.28545719e-02,  1.00959063e+00,\n",
       "        -6.91421270e-01,  5.11828959e-01, -3.05951804e-01, -1.63903803e-01,\n",
       "         1.06945932e+00,  4.10306692e-01, -6.35168195e-01,  4.71301824e-01,\n",
       "         3.38035017e-01, -8.42817575e-02,  9.82565582e-02,  6.56583384e-02,\n",
       "         3.11741531e-01, -4.43160295e-01,  9.23060253e-03, -4.47100192e-01,\n",
       "         8.77276480e-01, -8.29077736e-02,  9.15913165e-01, -7.23828077e-01,\n",
       "        -1.50048226e-01,  9.44161937e-02, -5.67844659e-02, -2.52952546e-01,\n",
       "        -7.04579532e-01, -3.01419556e-01,  1.51974976e-01, -3.70957583e-01,\n",
       "         3.66542876e-01,  5.96342266e-01, -4.41958398e-01,  1.28657788e-01,\n",
       "         1.25926226e-01,  2.69462496e-01, -2.13322148e-01,  3.18750322e-01,\n",
       "        -2.67232060e-01, -5.66534579e-01,  2.62114704e-01,  6.77858293e-03,\n",
       "        -5.82711518e-01, -2.78379530e-01, -2.58404464e-01,  5.43864191e-01,\n",
       "         5.65775156e-01,  5.85930884e-01, -1.18990079e-01, -6.05820835e-01,\n",
       "         7.95110688e-02,  5.16989291e-01, -2.09810108e-01,  1.60262287e-01,\n",
       "         1.07095647e+00,  6.42882943e-01,  1.68143287e-01,  8.78387392e-01,\n",
       "        -3.27050060e-01,  3.93878937e-01,  4.88870800e-01, -4.99816954e-01,\n",
       "        -4.03017044e-01,  1.13309741e+00, -4.13007528e-01, -6.29912972e-01,\n",
       "        -2.89064169e-01, -4.15456653e-01, -7.13533163e-01, -1.09310918e-01,\n",
       "         7.09006786e-02, -2.64806636e-02, -6.49312794e-01,  1.13968968e-01,\n",
       "        -6.00949824e-01,  1.80519968e-01,  4.68027890e-01, -2.37783194e-02,\n",
       "        -4.84673679e-01,  2.26349786e-01,  1.15198016e-01, -4.53485772e-02,\n",
       "         2.87070602e-01,  1.80695772e-01, -5.64859271e-01, -9.89572927e-02,\n",
       "        -4.69054222e-01,  2.14902349e-02, -2.39974290e-01, -4.37298238e-01,\n",
       "         2.82017112e-01,  2.60434821e-02,  8.60085487e-02,  3.56358469e-01,\n",
       "         1.69109434e-01,  5.80412447e-02,  3.75929803e-01,  5.18807948e-01,\n",
       "         2.24364161e-01,  2.17176169e-01,  4.90522623e-01,  4.76013958e-01,\n",
       "        -1.95239246e-01,  5.03868043e-01,  1.45833001e-01,  8.69946778e-02,\n",
       "         2.88794458e-01,  8.40611219e-01,  5.52533984e-01, -9.31868494e-01,\n",
       "         3.35190743e-02,  1.32340658e-02,  7.28415370e-01, -7.08669960e-01,\n",
       "         6.52848899e-01,  5.34471460e-02, -2.69448340e-01, -1.93821609e-01,\n",
       "         7.26280093e-01, -1.20979853e-01,  1.29789814e-01,  3.71350706e-01,\n",
       "        -2.09391892e-01, -3.16979587e-01,  2.00810786e-02,  1.48828831e-02,\n",
       "        -4.93170738e-01, -8.34135354e-01,  8.09660494e-01,  6.51808560e-01,\n",
       "        -1.68435827e-01,  4.46513116e-01,  4.30677012e-02, -3.52095932e-01,\n",
       "        -8.09009433e-01, -1.18068360e-01,  2.08861902e-01, -3.71134996e-01,\n",
       "         1.01010978e+00,  5.50961435e-01, -2.50898510e-01, -6.14798903e-01,\n",
       "        -5.13915634e+00, -3.56224597e-01, -9.01753083e-02,  1.90825522e-01,\n",
       "        -3.17737162e-01, -1.15399640e-02, -1.41228035e-01,  1.93323940e-05,\n",
       "        -5.85286856e-01, -5.12357116e-01,  4.40050393e-01,  1.16102397e-02,\n",
       "        -3.07077765e-01,  1.24042988e-01,  2.19302475e-01, -3.03621888e-01,\n",
       "        -4.63529192e-02, -3.14701982e-02, -2.52182513e-01,  1.80023983e-01,\n",
       "         6.21168911e-02, -5.01027584e-01,  9.24100995e-01, -5.83803058e-01,\n",
       "         3.92868817e-01,  7.39460588e-01,  4.88937013e-02,  1.45069823e-01,\n",
       "        -7.27713406e-02, -1.89166635e-01, -3.85542870e-01, -1.98701948e-01,\n",
       "         1.63792104e-01,  9.90713358e-01,  2.37774432e-01,  1.98505819e-01,\n",
       "         3.03139150e-01, -7.65531436e-02,  6.90332174e-01,  3.58308166e-01,\n",
       "         7.29628876e-02, -1.76091641e-02,  6.96559995e-03,  2.98387349e-01,\n",
       "         9.25717533e-01, -4.42581952e-01,  6.79257929e-01,  2.44940117e-01,\n",
       "         6.30279183e-01, -1.31679013e-01,  2.06626162e-01,  1.46891445e-01,\n",
       "         2.95587927e-02, -3.88391674e-01,  2.98069000e-01,  2.43551701e-01,\n",
       "         9.10827965e-02,  7.72306085e-01, -5.90046763e-01,  2.26242244e-01,\n",
       "         1.09606579e-01, -3.15796852e-01, -3.93063188e-01,  9.41116214e-02,\n",
       "        -5.39243370e-02,  4.82160375e-02, -7.66508102e-01, -5.26435316e-01,\n",
       "         1.12214714e-01,  8.45333859e-02,  3.38147581e-02, -5.21275461e-01,\n",
       "         1.30460978e+00, -1.21192133e+00, -6.22144401e-01,  4.81911182e-01,\n",
       "        -3.39790463e-01, -4.49601620e-01,  8.87644529e-01, -1.08191884e+00,\n",
       "         4.34786409e-01, -8.02435935e-01,  3.48732620e-02,  6.77979767e-01,\n",
       "         2.29948591e-02, -4.35754836e-01,  5.69554031e-01, -3.22253525e-01,\n",
       "         2.78138131e-01,  1.02457002e-01, -5.23415864e-01, -2.25500137e-01,\n",
       "         2.35728264e-01,  3.96307707e-02,  1.51163936e-01, -6.91784143e-01,\n",
       "        -2.52322644e-01,  1.18945368e-01,  5.21523654e-01, -5.56095362e-01,\n",
       "        -3.10635954e-01, -3.87789488e-01,  4.36362475e-01, -2.74659395e-01,\n",
       "         3.14027667e-01, -1.13088183e-01, -5.17055690e-01, -3.11127007e-01,\n",
       "         4.25273418e-01,  2.59614676e-01,  2.39447922e-01, -5.17619312e-01,\n",
       "         9.52506065e-02,  1.70317635e-01, -3.53878647e-01, -1.01134253e+00,\n",
       "        -2.63487846e-01,  7.72103608e-01, -1.52671248e-01, -2.86194921e-01,\n",
       "         2.74280965e-01,  8.01059961e-01, -1.89627796e-01,  4.77262288e-02,\n",
       "        -5.21218777e-01, -3.98103058e-01,  4.39261347e-02, -6.85919285e-01,\n",
       "        -7.44678557e-01, -2.22219497e-01,  1.57971069e-01, -9.51043308e-01,\n",
       "         2.69433796e-01, -3.60141397e-02,  4.17419732e-01,  3.96929830e-01,\n",
       "        -6.60761818e-02, -1.01006746e+00, -2.25172341e-01,  8.24422419e-01,\n",
       "         6.18124783e-01,  1.19101271e-01, -4.89328295e-01, -3.58946860e-01,\n",
       "         2.25114807e-01,  3.55321318e-01,  8.51262510e-02,  1.69221953e-01,\n",
       "        -4.32606846e-01,  4.17621315e-01,  4.78526235e-01, -6.19192421e-01,\n",
       "         8.76870081e-02, -3.55166942e-01, -4.16421473e-01,  4.17384863e-01,\n",
       "         6.85712039e-01,  4.59540412e-02, -4.73468930e-01, -5.90809107e-01,\n",
       "         8.36090446e-01,  4.77623641e-01,  9.55545008e-02,  6.69913292e-01,\n",
       "        -5.10149419e-01,  7.98504949e-01, -3.62606674e-01, -3.58601004e-01,\n",
       "        -4.33598965e-01,  9.10309106e-02,  4.80979323e-01,  1.49703473e-01,\n",
       "        -3.41623485e-01, -1.88323818e-02,  4.94435936e-01,  6.84697866e-01,\n",
       "         3.64586189e-02,  1.50264576e-01, -3.76254618e-01,  8.90652239e-01,\n",
       "         8.89077783e-02, -2.06090271e-01,  4.34929393e-02, -6.52271509e-01,\n",
       "         6.07781947e-01,  1.24901295e-01, -6.48985505e-01,  1.69487577e-02,\n",
       "         3.52980345e-02,  1.26366049e-01,  1.66746646e-01,  7.57211328e-01,\n",
       "         3.58315855e-01, -8.94563437e-01, -2.32485205e-01, -3.31993610e-01,\n",
       "        -7.80873075e-02, -3.82706165e-01,  2.64770567e-01,  1.01978302e-01,\n",
       "         4.73301500e-01, -7.25093067e-01, -1.38914526e-01, -5.77820092e-02,\n",
       "         2.66302019e-01, -4.20884103e-01,  7.00528800e-01,  4.35614824e-01,\n",
       "        -1.06619608e+00,  1.71756312e-01,  2.17827231e-01, -7.96443880e-01,\n",
       "         6.40250444e-02, -4.22520071e-01, -3.42364877e-01,  6.70277119e-01,\n",
       "         9.66075510e-02, -5.48977017e-01, -5.13378739e-01,  1.90771207e-01,\n",
       "        -7.19141781e-01, -3.33042115e-01, -7.90043771e-02,  1.31199509e-01,\n",
       "        -1.29704499e+00, -3.28465044e-01,  1.08526833e-01,  5.89058161e-01,\n",
       "         3.12833697e-01, -2.63089128e-02,  8.20463449e-02,  1.21769950e-01,\n",
       "        -1.27844840e-01, -7.26295471e-01, -2.65153170e-01,  1.17295645e-01,\n",
       "        -4.34831738e-01,  2.14651078e-02,  3.36228490e-01, -4.90988821e-01,\n",
       "        -2.51677990e-01, -1.25134289e-01, -8.19172919e-01, -6.39611185e-01,\n",
       "         5.37464842e-02,  1.93504766e-01, -4.87677038e-01,  3.91550809e-01,\n",
       "        -7.08752573e-01,  7.52638340e-01, -1.01582813e+00, -1.08427517e-02,\n",
       "        -7.65796781e-01, -5.38058221e-01, -6.72262087e-02, -5.66648245e-01,\n",
       "         4.31582063e-01, -1.18657067e-01, -1.09956868e-01,  2.98561692e-01,\n",
       "        -6.72349095e-01,  5.14328778e-01,  9.98665541e-02,  6.01302624e-01,\n",
       "        -6.81057453e-01,  3.08196545e-01,  5.47888160e-01,  8.99042130e-01,\n",
       "         2.89345622e-01, -3.73462826e-01, -8.23127508e-01,  2.33087048e-01,\n",
       "         1.18402973e-01, -4.90406930e-01, -5.38908660e-01, -2.10927591e-01,\n",
       "         3.02028954e-01, -3.33308518e-01,  9.54083741e-01,  1.05713643e-01,\n",
       "        -6.57945931e-01,  7.04843938e-01,  1.20232739e-01,  3.57391596e-01,\n",
       "         5.75565934e-01,  3.18776518e-01,  2.37207547e-01, -1.69230789e-01,\n",
       "        -6.82192326e-01,  2.87172347e-01,  7.97111511e-01,  1.07841134e-01,\n",
       "        -1.97429493e-01, -2.42521241e-01, -3.12604681e-02,  4.18522298e-01,\n",
       "        -6.98314905e-01, -1.25116765e-01,  1.47607312e-01,  4.08277422e-01,\n",
       "        -5.09068668e-01,  2.53589153e-01, -3.72093350e-01,  1.67178646e-01,\n",
       "        -9.72552657e-01,  4.52803493e-01,  2.99741834e-01, -1.13314235e+00,\n",
       "        -8.45981166e-02, -2.32006118e-01,  2.73990035e-01, -5.12139678e-01,\n",
       "        -1.82705551e-01,  9.53646898e-01, -6.17976248e-01, -5.28689802e-01,\n",
       "         7.39738405e-01,  9.77759659e-01,  1.74397260e-01,  6.88436747e-01,\n",
       "         5.52339911e-01, -3.56001817e-02,  2.29234651e-01,  2.22822592e-01,\n",
       "         6.59739494e-01,  9.54483271e-01, -4.51161861e-02,  3.57678115e-01,\n",
       "         1.36948943e-01,  6.30419075e-01,  1.13905594e-03, -2.09087431e-01,\n",
       "        -2.97413856e-01,  1.49159387e-01,  5.33106029e-01,  3.22374582e-01,\n",
       "         8.97706509e-01,  6.73788846e-01, -6.65124774e-01,  8.53718698e-01,\n",
       "         1.71831936e-01,  1.07434757e-01, -3.04359160e-02,  1.21290043e-01,\n",
       "        -2.34385461e-01,  2.06281170e-01,  4.36739214e-02, -1.75321102e-01,\n",
       "        -3.00680339e-01,  3.81545395e-01,  9.00010705e-01,  8.16243887e-02,\n",
       "         2.19148457e-01, -3.77940118e-01, -4.84956384e-01,  3.22934210e-01,\n",
       "         5.46755552e-01,  1.36337906e-01, -6.74239635e-01,  3.17568064e-01,\n",
       "        -3.67055573e-02,  1.34543628e-01,  1.42136112e-01, -5.14312923e-01,\n",
       "         3.58402908e-01,  6.47326469e-01, -5.08351922e-01, -4.37688798e-01,\n",
       "         3.19562376e-01,  1.20421007e-01,  3.89672726e-01,  7.03565776e-01,\n",
       "         4.77689236e-01, -6.56084001e-01,  3.49763781e-01, -1.58695225e-02,\n",
       "         9.85278785e-02,  2.93785810e-01, -4.25345838e-01, -5.81226423e-02,\n",
       "        -6.07466698e-01, -7.41145909e-02, -3.92811120e-01,  4.38809656e-02,\n",
       "        -1.85986862e-01,  3.62104863e-01,  1.69722848e-02, -7.19585776e-01,\n",
       "         6.19003534e-01, -4.26357180e-01,  6.19343519e-01,  1.37889251e-01,\n",
       "        -5.19064128e-01, -3.64604950e-01,  1.19406961e-01,  8.48894939e-02,\n",
       "        -4.01210934e-02, -3.45433921e-01,  5.81653297e-01, -2.44737580e-01,\n",
       "        -1.56682823e-02,  1.44530237e-02, -4.99085307e-01,  4.74076495e-02,\n",
       "        -7.38775209e-02,  2.40243107e-01,  1.99817896e-01,  1.53494149e-01,\n",
       "         2.13996470e-01, -3.75533462e-01, -7.12095618e-01,  4.54963744e-01,\n",
       "        -4.62653130e-01,  4.88708645e-01, -1.90663248e-01,  1.01303026e-01,\n",
       "        -3.60754937e-01, -2.11116284e-01,  1.94387332e-01, -2.71946043e-01,\n",
       "        -6.69794738e-01,  9.87232849e-03, -5.87857306e-01,  4.54181582e-01,\n",
       "        -4.49327260e-01, -8.46639514e-01, -9.57540721e-02, -1.40036628e-01,\n",
       "        -1.32432193e-01,  1.71439677e-01, -6.33441985e-01, -6.82699084e-02,\n",
       "         1.68388054e-01, -4.81696576e-02,  6.78424001e-01,  6.30847692e-01,\n",
       "         2.90135086e-01, -2.53532454e-03, -6.63070977e-02,  3.33252549e-01,\n",
       "         1.28800362e-01,  1.48516357e-01, -3.39905508e-02,  5.09538874e-02,\n",
       "        -1.17910475e-01,  7.11153865e-01, -8.07044446e-01, -5.41603923e-01,\n",
       "        -4.13101494e-01, -1.61030591e-01,  2.43609846e-01, -1.66136324e-01,\n",
       "        -2.39442170e-01,  9.93960500e-02,  4.19062376e-01, -5.19924223e-01,\n",
       "         1.79417565e-01, -5.20738780e-01,  3.75729918e-01, -3.70807141e-01],\n",
       "       dtype=float32),\n",
       " array([ 7.53713548e-01,  1.32492483e-02, -3.18587124e-01,  3.11426193e-01,\n",
       "        -3.34498018e-01, -6.91283882e-01,  3.24184179e-01, -3.92638206e-01,\n",
       "         7.32019842e-01,  7.49620348e-02,  4.10966754e-01,  3.95780325e-01,\n",
       "         1.75471187e-01, -4.73535866e-01, -4.77209985e-01, -1.55121326e-01,\n",
       "         1.69145316e-01, -2.00731725e-01,  2.66649276e-01,  3.71901423e-01,\n",
       "         6.99223042e-01, -3.46256495e-01,  5.47118723e-01,  2.32374847e-01,\n",
       "         1.50180638e-01,  1.61021248e-01, -2.30184644e-01,  4.84587848e-02,\n",
       "        -2.93296933e-01, -3.69456649e-01, -3.27637374e-01, -4.20585543e-01,\n",
       "        -3.52668524e-01,  4.16265309e-01,  3.61483395e-01, -1.86076120e-01,\n",
       "         1.83478519e-01, -2.81265706e-01, -4.15451288e-01, -3.46971273e-01,\n",
       "        -3.29029322e-01, -1.81518625e-02, -3.37089449e-01,  3.36698949e-01,\n",
       "        -2.94065848e-02, -4.33295369e-01,  4.25421834e-01,  4.26738709e-01,\n",
       "        -2.40377516e-01,  9.25331950e-01,  2.22440839e-01,  1.63495556e-01,\n",
       "        -3.42762619e-01,  3.42610598e-01,  3.42531711e-01,  7.04239547e-01,\n",
       "         1.26217127e-01, -7.08752573e-01, -1.36396624e-02,  1.99221417e-01,\n",
       "         1.17777973e-01,  4.06086862e-01, -1.49784699e-01, -3.20274293e-01,\n",
       "         3.49944025e-01,  3.68678451e-01, -5.99228032e-02, -2.22412333e-01,\n",
       "        -6.07581139e-01, -2.57032812e-01, -4.67601091e-01, -7.03880787e-01,\n",
       "         7.61761904e-01,  2.57606298e-01, -1.55424014e-01,  3.09997290e-01,\n",
       "        -5.40081620e-01,  6.58621311e-01,  6.80411041e-01,  3.87369633e-01,\n",
       "        -1.17459238e-01,  5.99931359e-01, -1.05266534e-01,  4.82225686e-01,\n",
       "         3.52598131e-01, -8.09051692e-02, -2.04979062e-01,  1.94817428e-02,\n",
       "        -3.31806272e-01, -1.91073492e-01,  1.22863241e-01,  2.48806834e-01,\n",
       "         1.89273894e-01, -4.01914343e-02, -1.18818387e-01,  5.16714036e-01,\n",
       "        -2.65126884e-01,  1.66427612e-01, -4.80386943e-01,  1.92875057e-01,\n",
       "         8.02038088e-02,  3.28011215e-02,  9.14474279e-02,  8.93976748e-01,\n",
       "        -1.39201522e-01, -1.81966975e-01,  2.60431260e-01,  2.79138684e-01,\n",
       "         3.37096661e-01,  1.22745085e+00,  6.71196759e-01, -1.17104471e-01,\n",
       "         3.09033722e-01,  9.07272995e-02, -1.67326570e-01, -3.00123215e-01,\n",
       "         4.31365639e-01, -7.95452595e-02,  2.56706029e-01, -6.21800907e-02,\n",
       "        -3.58216584e-01, -1.11784482e+00,  6.36820316e-01,  1.14280891e+00,\n",
       "         3.38432603e-02, -2.21057713e-01, -1.82927504e-01, -3.71373922e-01,\n",
       "        -4.75936905e-02, -3.95983875e-01, -6.68278694e-01,  4.77367073e-01,\n",
       "         6.18296087e-01,  5.00966012e-01, -1.53700083e-01,  5.08338094e-01,\n",
       "        -1.20945737e-01,  4.90885451e-02, -6.74526989e-01,  2.20340401e-01,\n",
       "        -2.08573818e-01,  7.20138311e-01,  3.64689618e-01, -6.99993193e-01,\n",
       "         1.90223098e-01,  3.28335226e-01,  8.19175482e-01,  5.03708236e-03,\n",
       "         4.67416167e-01, -2.50108063e-01,  1.23687696e+00, -3.81427646e-01,\n",
       "        -2.86172330e-01, -1.53867587e-01, -2.78157026e-01, -2.88234428e-02,\n",
       "        -3.00153613e-01, -2.10223705e-01,  5.08475006e-01,  8.83082747e-01,\n",
       "         1.70865372e-01,  2.80786306e-01,  5.28507352e-01,  1.88977435e-01,\n",
       "        -7.32018769e-01,  2.71544084e-02, -7.15490699e-01,  2.38787711e-01,\n",
       "         7.70684630e-02,  4.89117056e-01, -5.57945371e-01, -2.63869524e-01,\n",
       "         1.78151071e-01,  1.65447697e-01, -1.96658581e-01,  3.06574777e-02,\n",
       "         5.65500893e-02, -2.36802548e-02, -1.52558997e-01, -6.95836246e-01,\n",
       "        -8.17623901e+00, -2.13217646e-01,  1.71420678e-01,  9.99266356e-02,\n",
       "         1.25833482e-01, -4.47532445e-01, -7.67464161e-01, -2.92215347e-01,\n",
       "        -6.49806023e-01, -9.49621081e-01, -2.58826673e-01, -5.39540574e-02,\n",
       "        -7.11155355e-01,  4.13283348e-01,  2.02640176e-01, -2.15362329e-02,\n",
       "        -2.88498521e-01,  1.57588810e-01, -4.98961419e-01,  1.51377216e-01,\n",
       "         1.04515567e-01, -2.20051967e-02, -2.50666618e-01,  5.73149800e-01,\n",
       "        -5.43579876e-01, -1.68882442e+00,  2.90686727e-01, -1.08373284e-01,\n",
       "         3.14606786e-01, -1.08284995e-01, -1.31882608e+00,  9.28586423e-02,\n",
       "         1.20248340e-01, -5.33852339e-01,  3.06811072e-02, -3.63302022e-01,\n",
       "         2.96752274e-01, -5.97770393e-01, -7.26415336e-01, -6.34721518e-02,\n",
       "        -3.96362543e-01, -2.67838746e-01, -6.95786119e-01, -4.07513306e-02,\n",
       "         6.10470355e-01, -1.77350950e+00,  4.35777783e-01,  7.29202747e-01,\n",
       "         5.45295358e-01,  1.40041947e-01,  2.77290940e-02, -4.28315364e-02,\n",
       "         3.88068914e-01,  1.31065056e-01, -1.69289455e-01, -2.09185630e-01,\n",
       "        -2.35256746e-01,  9.19014066e-02,  4.62494940e-02, -1.17432141e+00,\n",
       "        -2.39699587e-01,  4.88932043e-01,  4.03102845e-01, -2.80054025e-02,\n",
       "        -2.03174159e-01, -9.12830830e-01,  8.57144594e-02,  6.51615500e-01,\n",
       "         8.20137739e-01, -1.27959996e-01, -3.41168165e-01, -3.32253993e-01,\n",
       "         4.76801813e-01, -6.88391149e-01,  3.46200138e-01,  3.22935522e-01,\n",
       "         1.12262607e-01, -4.79752459e-02,  1.01053584e+00, -3.53151828e-01,\n",
       "         7.07843184e-01,  6.19962752e-01,  6.57356918e-01, -1.31527320e-01,\n",
       "        -3.13490540e-01,  6.78887188e-01,  4.14412141e-01,  2.21506804e-01,\n",
       "        -1.23977132e-01,  4.03575540e-01,  5.35190940e-01,  1.16137452e-01,\n",
       "         1.19703956e-01,  7.85307765e-01,  7.24131465e-02, -9.40962970e-01,\n",
       "         3.10371578e-01, -4.89650428e-01, -8.76083821e-02, -6.92922056e-01,\n",
       "        -1.09035596e-02,  1.71256676e-01, -4.83416408e-01,  2.68035710e-01,\n",
       "         5.14239311e-01, -3.68752956e-01, -9.01653171e-01,  6.58523589e-02,\n",
       "         3.29570830e-01, -1.04200149e+00,  2.47841731e-01, -4.46533829e-01,\n",
       "        -9.66275930e-02, -1.86459534e-02, -1.03919551e-01,  3.69664371e-01,\n",
       "         8.87882113e-01, -2.22625762e-01, -2.70492196e-01, -4.55184504e-02,\n",
       "         2.54914075e-01, -6.63060188e-01,  3.14068139e-01, -3.76312077e-01,\n",
       "        -4.93841767e-01,  1.78926915e-01,  5.35606802e-01,  2.86356360e-01,\n",
       "         1.17566347e+00,  8.95574838e-02,  4.19468015e-01, -5.96132338e-01,\n",
       "         1.03136107e-01,  1.09308481e-01,  2.49287993e-01,  2.36941352e-02,\n",
       "        -1.96941957e-01, -3.17502260e-01,  5.18819317e-02, -6.86940491e-01,\n",
       "         5.37225783e-01,  8.67721587e-02,  1.10676229e-01,  5.79380155e-01,\n",
       "         1.78661615e-01, -3.45138878e-01, -4.47639227e-01, -5.23490548e-01,\n",
       "        -2.59740114e-01,  3.65046412e-02,  5.45441985e-01, -1.13023475e-01,\n",
       "         1.10027194e+00, -3.69038492e-01, -1.99374378e-01,  3.46209317e-01,\n",
       "         3.34129632e-02,  1.33366495e-01, -3.15764546e-01, -6.75324619e-01,\n",
       "        -5.26257455e-01, -3.33873093e-01,  3.69516879e-01, -4.02536780e-01,\n",
       "         9.57054272e-03,  4.04037833e-01,  3.06193620e-01, -6.79208457e-01,\n",
       "         2.46047452e-01,  4.64002997e-01, -2.35723078e-01, -7.01804817e-01,\n",
       "        -6.04335368e-01, -3.10310513e-01, -2.87379116e-01, -6.24557771e-03,\n",
       "         4.23442796e-02,  3.55108738e-01,  7.34696984e-01, -1.16330162e-01,\n",
       "        -6.12290144e-01,  2.70606995e-01, -6.15351915e-01, -6.75399125e-01,\n",
       "         1.12218887e-01,  2.72690535e-01, -2.97252834e-01, -2.60813057e-01,\n",
       "         2.32200757e-01, -5.77888548e-01,  3.13251853e-01,  5.33707812e-02,\n",
       "        -1.74722880e-01, -5.82506545e-02,  3.60026538e-01,  4.90641564e-01,\n",
       "        -6.62531912e-01,  2.07371831e-01, -5.96163794e-03, -4.55782175e-01,\n",
       "        -2.32392356e-01, -6.59976363e-01, -6.80655122e-01, -4.73103896e-02,\n",
       "        -5.83657920e-01,  9.33102444e-02,  9.27019954e-01,  4.47912335e-01,\n",
       "         3.42976213e-01, -8.30023065e-02, -1.67527944e-02,  3.11220914e-01,\n",
       "        -3.25903982e-01, -4.72078174e-01, -2.15001553e-01,  7.31227696e-02,\n",
       "         6.04124904e-01, -6.77286744e-01,  2.70899147e-01,  1.42688304e-01,\n",
       "        -2.03362375e-01,  9.33069140e-02, -6.24570027e-02,  2.88259983e-01,\n",
       "         2.71681249e-01,  1.48825198e-01,  3.08834791e-01,  1.59396157e-01,\n",
       "        -6.46159112e-01, -1.82358116e-01,  5.85883200e-01, -4.16645221e-02,\n",
       "         4.61410731e-03,  4.39426243e-01, -6.94420218e-01, -6.97301269e-01,\n",
       "        -5.85881829e-01, -5.24448037e-01,  3.43164772e-01, -5.03369212e-01,\n",
       "         4.34169263e-01,  8.03001374e-02, -1.08528458e-01, -6.66131556e-01,\n",
       "         1.33604914e-01,  1.01439369e+00,  7.29209334e-02,  5.62682152e-01,\n",
       "         2.97161341e-01, -2.05566399e-02,  6.29659772e-01,  2.90849894e-01,\n",
       "         7.55264014e-02, -1.38702244e-01,  3.63191694e-01, -5.39649017e-02,\n",
       "         1.98222980e-01, -2.85592139e-01, -1.30743787e-01,  5.16334921e-02,\n",
       "        -8.99195001e-02, -3.94454598e-01, -2.66135670e-02,  4.45963949e-01,\n",
       "         4.53793883e-01,  6.13490522e-01,  3.49205911e-01,  6.30073309e-01,\n",
       "         3.07988197e-01,  4.66908693e-01, -9.73762453e-01, -3.88808906e-01,\n",
       "        -9.44064483e-02,  8.92122805e-01, -4.70767319e-01,  4.97644812e-01,\n",
       "         5.98423541e-01,  8.07439163e-02, -1.69870943e-01,  3.47259164e-01,\n",
       "         1.69700652e-01, -1.21253157e+00,  3.10547054e-01, -4.24857408e-01,\n",
       "         1.59346238e-01,  1.83076829e-01, -3.97120535e-01,  4.66683842e-02,\n",
       "        -2.68223524e-01,  1.71481490e-01,  7.09890544e-01,  2.25366354e-01,\n",
       "        -6.36192024e-01, -6.75438166e-01,  6.69848561e-01, -6.93411887e-01,\n",
       "        -5.72989166e-01,  3.23899150e-01,  4.39727187e-01,  3.79599184e-02,\n",
       "         3.45206141e-01, -4.90942389e-01, -4.57419217e-01,  6.51345074e-01,\n",
       "        -4.42044809e-02, -4.11459267e-01, -2.37372220e-01,  4.21626896e-01,\n",
       "         6.80162311e-02, -8.63839328e-01, -1.38732925e-01,  2.17242494e-01,\n",
       "         3.92601311e-01,  1.21852875e-01, -2.17999205e-01, -9.02931035e-01,\n",
       "         4.77305725e-02, -2.56178468e-01,  2.81520307e-01, -1.72773808e-01,\n",
       "        -6.65948033e-01,  1.95281357e-01, -2.46560663e-01,  4.04156446e-01,\n",
       "         6.65348887e-01, -5.12745142e-01,  9.32059526e-01,  1.14732862e-01,\n",
       "         7.95430720e-01,  2.44916275e-01, -5.08850992e-01,  1.80867493e-01,\n",
       "        -3.79489660e-01, -2.44365215e-01,  4.46607292e-01, -1.08217567e-01,\n",
       "        -1.99943453e-01, -3.32640499e-01, -4.05779094e-01, -6.99891329e-01,\n",
       "        -5.71048796e-01, -8.12274069e-02,  5.94854176e-01,  4.45613921e-01,\n",
       "         3.96710426e-01, -7.84442574e-02,  1.23851466e+00, -2.64506757e-01,\n",
       "        -6.44817233e-01, -2.16387987e-01,  1.30153313e-01,  1.30433753e-01,\n",
       "        -1.58367649e-01, -8.66971970e-01, -7.49941468e-01,  5.33651173e-01,\n",
       "        -6.38505220e-01,  2.30902761e-01,  3.88987035e-01,  6.58474565e-01,\n",
       "        -3.94336164e-01, -7.93575495e-02,  7.42258787e-01,  3.90435755e-01,\n",
       "        -1.55147821e-01, -1.44647092e-01,  5.56948632e-02, -2.88038373e-01,\n",
       "        -3.66591543e-01, -2.47813627e-01, -3.76616389e-01,  1.70293748e-01,\n",
       "         5.13184428e-01, -1.63554102e-01,  1.65534824e-01,  1.42834389e+00,\n",
       "         1.05518833e-01, -8.99581552e-01, -1.39551193e-01, -3.34184378e-01,\n",
       "         1.54220343e-01,  2.13458747e-01, -5.31451344e-01, -3.47043157e-01,\n",
       "        -2.00292245e-01,  3.67152750e-01, -1.28746673e-01, -5.21747768e-01,\n",
       "        -1.74723998e-01, -4.26484704e-01,  8.52606118e-01, -6.99598908e-01,\n",
       "         5.58240533e-01, -7.26210698e-02, -7.88983852e-02,  2.12008193e-01,\n",
       "         3.28117535e-02, -3.76163535e-02, -1.61940262e-01,  4.13503557e-01,\n",
       "        -1.10823497e-01,  4.18330990e-02, -8.61994326e-01,  4.63375390e-01,\n",
       "         3.86858612e-01, -6.48267210e-01, -5.70168436e-01, -4.66848880e-01,\n",
       "        -3.01978111e-01,  3.55555415e-01, -1.17194355e-01, -2.99699306e-01,\n",
       "         1.02637783e-01, -3.35790843e-01,  5.77651784e-02,  2.97520638e-01,\n",
       "        -4.26449120e-01, -5.47842383e-01,  1.09238982e+00, -1.91385388e-01,\n",
       "        -6.95970133e-02, -8.17581639e-02, -3.03735316e-01,  1.76990718e-01,\n",
       "        -6.93601668e-01,  2.49547482e-01,  9.76866260e-02,  9.40670967e-02,\n",
       "         7.19078854e-02,  4.78764385e-01,  1.20192885e-01,  1.15709692e-01,\n",
       "        -1.80072904e-01, -1.27266377e-01,  3.00370604e-01, -1.33153617e-01,\n",
       "         7.00768605e-02,  1.25574470e-01, -8.02564383e-01,  6.76430821e-01,\n",
       "         2.42828146e-01,  5.84684730e-01, -1.47825408e+00,  1.93634555e-01,\n",
       "         2.51385450e-01, -6.52217567e-01,  1.58115864e-01,  7.31939852e-01,\n",
       "         1.86258823e-01, -1.24404624e-01,  4.01150346e-01, -4.50618416e-01,\n",
       "         2.49673292e-01,  1.49029985e-01, -1.01758063e+00,  7.61276484e-02,\n",
       "        -2.54536927e-01, -1.45019978e-01,  6.13956988e-01,  7.29146540e-01,\n",
       "        -3.53066474e-01,  6.72495425e-01,  8.75806212e-02, -1.42036140e-01,\n",
       "         2.23135799e-01,  4.83346581e-01,  8.53538141e-02, -4.17210191e-01,\n",
       "         6.62248805e-02,  2.18324319e-01, -2.86330521e-01,  4.36643481e-01,\n",
       "         1.14099465e-01,  2.24059150e-01,  1.91675186e-01, -5.85998416e-01,\n",
       "         2.12990478e-01, -3.53619128e-01,  3.91070187e-01, -2.57480145e-02,\n",
       "         2.35087365e-01,  5.28828800e-02, -5.75551569e-01, -1.83613092e-01,\n",
       "         3.26065630e-01,  2.24547639e-01,  3.10065091e-01,  3.98071945e-01,\n",
       "        -2.18561277e-01, -3.17620605e-01, -6.03663802e-01, -4.65324134e-01,\n",
       "        -4.56821173e-04,  9.25641954e-01,  3.38344686e-02, -4.50275123e-01,\n",
       "        -7.95501888e-01,  1.67967647e-01,  6.60163820e-01,  5.44434428e-01,\n",
       "        -3.07312161e-01, -6.23272240e-01, -1.13064796e-01,  2.84650594e-01,\n",
       "        -2.81920254e-01,  6.27423882e-01, -8.67053747e-01,  4.39489000e-02,\n",
       "         7.00969815e-01, -1.94983691e-01, -3.91153663e-01, -2.61858523e-01,\n",
       "         1.56425193e-01, -3.51088613e-01, -6.94418550e-01, -4.02664989e-01,\n",
       "         1.80743515e-01,  6.07589297e-02,  2.45695472e-01, -7.25539744e-01,\n",
       "        -3.55212539e-02, -1.59380004e-01,  7.11887896e-01,  2.74995938e-02,\n",
       "         6.05032325e-01,  2.28316858e-02,  6.01977885e-01,  4.07503873e-01,\n",
       "         6.20993733e-01, -3.05410475e-01, -8.09407592e-01,  4.47485238e-01,\n",
       "         2.67041326e-01,  2.57850349e-01,  1.21970272e+00, -2.96304226e-01,\n",
       "         7.69479513e-01, -3.13917428e-01, -6.65857613e-01, -2.19733134e-01,\n",
       "        -3.39243531e+00,  3.50746542e-01, -1.48283303e-01,  1.94524124e-01,\n",
       "        -1.79309204e-01,  2.99230784e-01,  3.86923581e-01, -1.45898044e-01,\n",
       "        -3.44572514e-01, -2.93618828e-01,  3.37542832e-01,  8.26708525e-02,\n",
       "        -5.11102796e-01,  4.05834913e-01, -1.04820877e-02,  3.80203098e-01,\n",
       "         1.13103747e-01, -4.04038310e-01,  4.80548233e-01,  4.02259767e-01,\n",
       "         1.72136739e-01,  1.47812098e-01,  3.87116164e-01, -4.82008964e-01,\n",
       "        -3.44028115e-01,  6.46112680e-01, -5.15827656e-01, -4.75316882e-01,\n",
       "         5.40166311e-02, -3.17905515e-01,  1.42975017e-01, -8.30597728e-02,\n",
       "         6.21417880e-01, -3.11496317e-01,  5.64982712e-01, -3.63391697e-01,\n",
       "        -1.26336440e-02, -1.34408232e-02, -1.09162524e-01, -3.11725736e-01,\n",
       "        -1.99339747e-01, -9.51275289e-01, -4.38707415e-03, -5.14985561e-01,\n",
       "         1.47049516e-01, -1.66683286e-01, -6.35205865e-01, -1.74504399e-01],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 768)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embedding_0 = sentence_embedding.detach().numpy()[0]\n",
    "sentence_embedding_1 = np.mean(token_vecs, axis=0)\n",
    "len(sentence_embedding_0), len(sentence_embedding_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [CLS]\n",
      "1 absolutely\n",
      "2 wonderful\n",
      "3 -\n",
      "4 silky\n",
      "5 and\n",
      "6 sexy\n",
      "7 and\n",
      "8 comfortable\n",
      "9 [SEP]\n"
     ]
    }
   ],
   "source": [
    "for i, token_str in enumerate(tokenized_text):\n",
    "    print(i, token_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031909264624118805"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - cosine(sentence_embedding_0, sentence_embedding_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector(text, word_id, model, tokenizer):\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    word_embeddings, sentence_embeddings = model(tokens_tensor)   \n",
    "    vector = word_embeddings[0][word_id].detach().numpy()\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_4 = word_vector(text, 5, model_embedding, tokenizer)\n",
    "word_5 = word_vector(text, 4, model_embedding, tokenizer)\n",
    "word_6 = word_vector(text, 6, model_embedding, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_vector(text, model, tokenizer, method=\"average\"):\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    word_embeddings, sentence_embeddings = model(tokens_tensor)\n",
    "    token_vecs = []\n",
    "    \n",
    "    for embedding in word_embeddings[0]:\n",
    "        cat_vec = embedding.detach().numpy()\n",
    "        token_vecs.append(cat_vec)\n",
    "        \n",
    "    if method == \"average\":\n",
    "        sentence_embedding = np.mean(token_vecs, axis=0)\n",
    "    if method == \"model\":\n",
    "        sentence_embedding = sentence_embeddings\n",
    "    # do something\n",
    "    return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_vec_0 = sentence_vector(text, model_embedding, tokenizer)\n",
    "sen_vec_1 = sentence_vector(text, model_embedding, tokenizer, method=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.66597006e-02, -1.14628233e-01,  2.25870922e-01,  1.92374006e-01,\n",
       "        1.38262779e-01, -1.04091883e-01, -4.56632860e-02, -5.65509796e-02,\n",
       "        3.37098539e-02, -1.43111467e-01,  1.27343804e-01, -2.08311826e-01,\n",
       "        2.03987315e-01,  5.24847388e-01, -7.77174979e-02,  5.64874351e-01,\n",
       "        2.41172507e-01, -1.10864624e-01, -3.92622948e-01,  1.28040165e-01,\n",
       "        3.05907071e-01, -3.20705205e-01, -2.15200692e-01,  2.22033545e-01,\n",
       "        6.30764604e-01,  2.42748093e-02, -9.63131189e-02,  1.93873912e-01,\n",
       "        1.26300100e-02, -2.53424555e-01,  4.81704950e-01, -3.29156891e-02,\n",
       "       -1.26535743e-01, -2.24385768e-01, -4.20149952e-01, -4.65344012e-01,\n",
       "       -3.92766371e-02, -3.26360524e-01, -4.73033249e-01,  1.14377335e-01,\n",
       "       -2.69786894e-01, -2.35798761e-01, -7.26560503e-02, -9.70358774e-02,\n",
       "       -1.27273515e-01, -2.15317205e-01, -2.76455224e-01, -6.26460463e-02,\n",
       "       -6.96362481e-02, -3.28973442e-01, -2.17520520e-01,  1.11001711e-02,\n",
       "       -2.17285901e-01, -6.11748695e-02, -1.03783605e-04,  5.16818941e-01,\n",
       "       -3.13097566e-01, -3.06320131e-01,  4.70948443e-02,  1.58813283e-01,\n",
       "       -1.69217885e-01,  2.65811980e-02,  3.24830532e-01, -5.40019631e-01,\n",
       "        2.58263238e-02,  4.09028053e-01,  5.15236929e-02, -1.72913522e-01,\n",
       "       -4.61772382e-02,  4.02750298e-02, -2.71656215e-01, -3.88646603e-01,\n",
       "       -8.30824003e-02, -9.72787961e-02, -4.65490401e-01, -1.28378883e-01,\n",
       "       -7.47656748e-02,  1.09639861e-01,  2.44259521e-01,  4.84482944e-01,\n",
       "       -3.80362540e-01,  5.75511336e-01,  2.13009596e-01,  4.93504107e-01,\n",
       "        1.45970151e-01,  3.97230208e-01, -1.90219074e-01,  2.74107039e-01,\n",
       "        2.80813962e-01, -2.21126884e-01,  5.57803214e-02, -1.15227457e-02,\n",
       "        1.62226409e-01,  1.61316484e-01,  1.51463807e-01, -4.17877674e-01,\n",
       "       -2.43650362e-01, -5.56473807e-02, -1.70874223e-01,  1.85296476e-01,\n",
       "        1.87566042e-01, -3.37306082e-01,  8.49031210e-02, -2.23559793e-02,\n",
       "       -1.47437364e-01,  1.02518380e-01,  1.18235126e-01,  3.85381058e-02,\n",
       "        2.32435197e-01,  2.20846564e-01,  6.88437894e-02, -2.33175799e-01,\n",
       "       -1.31401479e-01, -5.30154109e-02, -2.53440291e-01,  2.88377225e-01,\n",
       "        7.15157166e-02,  2.84438878e-01,  1.62683636e-01, -1.08841732e-01,\n",
       "       -1.28306419e-01, -5.74297905e-01,  5.19687772e-01,  7.96183348e-01,\n",
       "        4.07839864e-01, -3.54266971e-01, -1.49183720e-01,  7.34893829e-02,\n",
       "       -1.26642361e-01, -1.14252627e-01, -8.98330845e-03,  7.82638192e-02,\n",
       "       -3.38760242e-02, -3.58853251e-01, -2.41861731e-01,  1.89896792e-01,\n",
       "       -9.97911021e-02, -4.18898880e-01, -1.71850875e-01, -1.08263053e-01,\n",
       "       -1.16051652e-01,  2.75813729e-01, -5.42633653e-01,  1.47573873e-01,\n",
       "       -8.27658772e-02, -1.04577564e-01, -2.65473370e-02,  2.54541785e-01,\n",
       "       -1.44335702e-01, -3.33270282e-01,  3.04697216e-01,  1.01594590e-01,\n",
       "       -3.15766275e-01, -6.01565659e-01, -2.49073822e-02,  3.26978154e-02,\n",
       "       -1.20370053e-01, -2.74479445e-02,  2.23233670e-01, -3.00220549e-01,\n",
       "       -2.25491375e-01,  1.40600622e-01,  3.58594023e-02,  1.19641617e-01,\n",
       "       -4.74309444e-01, -4.90528867e-02, -4.44531143e-02,  6.73542380e-01,\n",
       "       -1.20428219e-01,  4.22596216e-01, -4.88898791e-02, -2.15632245e-01,\n",
       "        4.95298207e-01,  4.68515337e-01, -5.83052635e-02,  2.30824910e-02,\n",
       "        3.29281777e-01,  1.81187354e-02,  2.52330333e-01, -2.18922235e-02,\n",
       "       -8.52793515e-01,  2.63660461e-01,  3.30427080e-01, -1.33861989e-01,\n",
       "        2.91292667e-01,  3.52895266e-04,  4.49043274e-01,  1.65344235e-02,\n",
       "       -4.24540669e-01,  1.10393584e-01,  2.66141295e-02,  3.20849389e-01,\n",
       "       -2.00601429e-01, -5.18098883e-02, -1.35444343e-01, -2.29900330e-01,\n",
       "        6.75413832e-02,  2.71228313e-01, -5.00669241e-01,  2.69944072e-01,\n",
       "        4.98533726e-01, -1.13857510e-02, -8.21524709e-02,  1.56157881e-01,\n",
       "       -3.47470969e-01,  1.04326412e-01,  2.62996435e-01, -2.41455838e-01,\n",
       "       -2.75501311e-01, -1.38339549e-01, -1.98909730e-01,  3.83265674e-01,\n",
       "        4.65667099e-01, -1.09623238e-01,  1.76444218e-01, -9.68783870e-02,\n",
       "        1.38552431e-02,  2.12315157e-01,  1.26950264e-01, -5.38784079e-02,\n",
       "        3.78033847e-01,  2.84567565e-01, -1.66235372e-01,  3.87776911e-01,\n",
       "        5.51801932e-04,  3.41043472e-01,  2.56157249e-01, -1.40079975e-01,\n",
       "        8.44451040e-02,  3.11613888e-01, -3.01841825e-01, -1.73481107e-01,\n",
       "       -8.91913921e-02, -4.49348018e-02, -3.19676511e-02,  9.04360265e-02,\n",
       "       -3.65627110e-02,  4.84574623e-02,  1.72941312e-01, -1.52899876e-01,\n",
       "       -2.38103151e-01,  4.96701866e-01,  5.43671012e-01,  2.48642474e-01,\n",
       "       -5.39407372e-01,  2.84285009e-01, -1.57451093e-01, -6.78905696e-02,\n",
       "       -1.17826641e-01,  1.09957203e-01, -3.74532759e-01, -2.27711529e-01,\n",
       "       -1.10627748e-01, -3.00266922e-01, -2.09702939e-01,  2.09751725e-03,\n",
       "       -8.18794221e-02,  1.17877044e-01,  3.09179723e-02,  1.16472796e-01,\n",
       "        2.21396491e-01, -2.31788471e-01,  3.62634748e-01, -2.19694465e-01,\n",
       "       -2.09721535e-01, -1.52099058e-01, -1.54017702e-01,  1.19654261e-01,\n",
       "        5.64831123e-02,  6.98652208e-01, -2.27049589e-02,  2.29567721e-01,\n",
       "        9.34472308e-02,  2.30477571e-01,  5.20830229e-02, -3.11624229e-01,\n",
       "        1.52088240e-01,  8.70906748e-03, -3.51398475e-02, -7.19235361e-01,\n",
       "        3.37932497e-01,  3.92385691e-01, -2.72055656e-01, -1.74383730e-01,\n",
       "        3.64710152e-01, -4.12422836e-01, -8.17682296e-02, -1.43921286e-01,\n",
       "       -3.21259558e-01, -3.89916927e-01,  1.11314967e-01, -8.68508779e-03,\n",
       "       -6.36183381e-01, -2.52788067e-01,  5.56217790e-01,  3.23231936e-01,\n",
       "        2.89854139e-01,  2.92343885e-01, -2.18999535e-01, -3.61752182e-01,\n",
       "       -3.75947505e-01, -2.44006395e-01,  2.08127610e-02, -1.59378216e-01,\n",
       "        1.22473896e-01,  2.95477450e-01,  2.96951532e-01, -5.33465147e-01,\n",
       "       -3.95641589e+00, -8.48102421e-02,  9.98514667e-02, -4.20089103e-02,\n",
       "       -6.56063843e-04, -1.13332428e-01, -6.88312054e-02, -1.70830414e-01,\n",
       "       -3.54250252e-01, -3.69891524e-01,  8.58515278e-02, -1.49843901e-01,\n",
       "        1.64264530e-01,  9.17125419e-02,  2.52197593e-01,  9.70839113e-02,\n",
       "       -1.54692635e-01, -3.53712529e-01, -5.86610138e-02,  3.39910984e-01,\n",
       "       -2.67072886e-01, -4.47484732e-01,  3.98100764e-01, -5.28381541e-02,\n",
       "        4.76046801e-01,  1.97146267e-01, -1.15931749e-01,  2.98533682e-02,\n",
       "       -2.10481808e-01,  5.52321747e-02, -8.53998184e-01, -3.26376736e-01,\n",
       "        1.30935818e-01,  4.42319244e-01,  2.76740491e-01, -1.78975999e-01,\n",
       "        2.45656565e-01, -1.56620011e-01,  3.89953673e-01,  4.23402973e-02,\n",
       "       -4.31906171e-02, -2.68901199e-01, -7.48318285e-02,  2.31119990e-03,\n",
       "        3.88126075e-01, -4.06011581e-01,  2.78184593e-01, -7.50141963e-02,\n",
       "        3.43528926e-01, -6.61364347e-02,  1.28792346e-01,  2.09797114e-01,\n",
       "        1.12629775e-02, -3.09984088e-01, -3.15352857e-01,  2.62250274e-01,\n",
       "        6.14012033e-03,  1.55491546e-01, -2.92820275e-01,  1.09904431e-01,\n",
       "       -3.26248892e-02, -2.90103316e-01, -1.70588166e-01,  1.56809121e-01,\n",
       "        4.97736514e-01,  1.96259499e-01, -2.47981116e-01, -4.86160427e-01,\n",
       "       -1.50147125e-01,  3.66714716e-01,  6.24591820e-02, -2.53126234e-01,\n",
       "        2.04902127e-01, -1.08795750e+00, -6.20687127e-01, -1.59219548e-01,\n",
       "       -3.30022395e-01, -1.45579904e-01,  5.66010773e-01, -5.19032896e-01,\n",
       "       -5.51877797e-01, -5.47955513e-01,  1.03883088e-01,  6.71847403e-01,\n",
       "       -3.83845274e-03, -5.46463966e-01,  2.98995879e-02, -1.17203571e-01,\n",
       "        1.25831515e-01, -7.42562860e-02, -8.18763599e-02,  3.26046020e-01,\n",
       "        9.88536701e-02, -6.27411902e-02, -2.59825941e-02,  5.41849136e-02,\n",
       "       -1.92466944e-01,  5.79965599e-02,  4.39534485e-01, -3.22986752e-01,\n",
       "       -3.88362288e-01, -4.52488661e-01,  3.59106332e-01,  2.53116548e-01,\n",
       "        1.56627297e-02,  1.13665842e-01, -2.81365097e-01, -2.51159519e-01,\n",
       "        9.64479893e-02,  1.56716593e-02,  2.15199381e-01, -2.67979801e-01,\n",
       "        3.33814591e-01, -7.86689669e-02,  2.95528650e-01, -6.47629797e-01,\n",
       "       -2.86818862e-01,  8.52259755e-01,  2.09800482e-01, -5.25373444e-02,\n",
       "        1.11293700e-02,  4.37719524e-01, -2.65091598e-01,  6.06840476e-02,\n",
       "       -7.44229183e-02, -1.83641352e-02, -1.64950788e-01, -2.89019048e-01,\n",
       "       -5.16355634e-01, -4.00571436e-01,  1.56365167e-02, -5.15032232e-01,\n",
       "        6.83608502e-02, -2.81177610e-01,  5.64304411e-01,  5.39341569e-01,\n",
       "       -2.22986653e-01, -8.10771108e-01, -1.50150269e-01,  3.76318634e-01,\n",
       "        3.23234648e-01,  4.18606669e-01, -2.26990908e-01,  1.81303862e-02,\n",
       "        1.03457533e-02,  5.17856598e-01, -1.65517017e-01,  3.15609396e-01,\n",
       "       -1.07951760e-01,  4.86561447e-01,  1.78760439e-01, -1.66738138e-01,\n",
       "        1.91297859e-01, -4.92955834e-01,  3.94786969e-02, -8.62206221e-02,\n",
       "        5.22805452e-01,  4.71859425e-02, -2.77068853e-01, -3.14841270e-01,\n",
       "        1.38235897e-01,  1.75886214e-01,  4.41909790e-01,  4.52460378e-01,\n",
       "        1.40009876e-02,  2.69751102e-01, -1.82636864e-02, -2.53012985e-01,\n",
       "       -1.11249708e-01,  5.06038547e-01,  2.44315103e-01, -2.85912752e-02,\n",
       "       -1.82671100e-01, -2.32616186e-01, -2.94768363e-02,  6.42183900e-01,\n",
       "       -1.49367183e-01,  1.27590135e-01, -1.75423026e-01,  5.70841312e-01,\n",
       "        4.23355401e-02, -1.24964155e-01,  2.69509733e-01,  2.05123276e-01,\n",
       "        4.33810323e-01,  4.02037710e-01, -4.54374462e-01, -2.86781549e-01,\n",
       "        5.49353287e-03, -1.04547217e-01, -3.98482382e-01,  4.98282194e-01,\n",
       "        1.16192326e-01, -3.44649702e-01, -4.23534960e-01, -1.56032920e-01,\n",
       "        2.86591440e-01, -4.17359531e-01,  4.36096579e-01,  4.04944941e-02,\n",
       "        1.63965300e-01, -1.68741852e-01, -2.38805085e-01,  5.12474418e-01,\n",
       "       -3.82132709e-01, -2.31841654e-01,  8.35023999e-01,  1.61049068e-01,\n",
       "       -3.48176062e-01,  2.19867378e-01,  2.66019497e-02, -4.62241411e-01,\n",
       "       -5.03376238e-02, -1.72029853e-01, -1.69385120e-01,  1.63470462e-01,\n",
       "        1.07276857e-01, -4.28436935e-01, -2.36357525e-01,  3.06344807e-01,\n",
       "       -5.21661341e-01, -1.22354724e-01,  2.77229965e-01, -2.51870483e-01,\n",
       "       -6.32864416e-01, -3.82889718e-01,  1.26032889e-01,  3.18164825e-01,\n",
       "       -4.46373284e-01, -6.84061497e-02,  1.73817843e-01, -1.19932532e-01,\n",
       "       -2.42896639e-02, -4.46241438e-01, -9.20709968e-03,  3.26342702e-01,\n",
       "       -4.36260551e-01, -2.72809803e-01,  1.58721328e-01, -1.39948040e-01,\n",
       "       -1.55346900e-01, -4.49110210e-01, -7.31734931e-02, -7.90248513e-02,\n",
       "       -5.60556054e-02,  5.11305869e-01, -5.67100644e-01,  3.18597376e-01,\n",
       "       -4.08342123e-01,  2.18152910e-01, -2.75508255e-01, -9.69102979e-02,\n",
       "       -6.41172901e-02, -6.71265185e-01,  2.93538660e-01, -1.62702918e-01,\n",
       "        1.91286668e-01,  1.79688096e-01,  2.97523793e-02, -6.85306042e-02,\n",
       "       -3.61744881e-01,  1.82865262e-02,  1.46267757e-01,  1.06525399e-01,\n",
       "       -3.17294210e-01,  2.40676165e-01,  3.74758780e-01,  5.21324277e-01,\n",
       "       -1.48312718e-01, -4.12312686e-01, -1.79023184e-02,  3.64194900e-01,\n",
       "        2.73934416e-02, -2.26810053e-01, -1.03805616e-01,  8.91421214e-02,\n",
       "        2.20653385e-01, -5.78642428e-01,  3.18444669e-01, -6.36851937e-02,\n",
       "       -1.84727743e-01,  2.75001228e-01,  3.16504166e-02, -8.86051208e-02,\n",
       "        4.60081585e-02, -6.23636544e-02, -4.84859534e-02, -1.43256038e-01,\n",
       "       -2.64608592e-01,  2.78099924e-01,  5.45816541e-01,  2.37556607e-01,\n",
       "        1.06547058e-01, -1.29741997e-01, -3.24063420e-01,  1.32273361e-01,\n",
       "       -2.39090770e-01,  4.04024795e-02,  4.29412782e-01, -4.67916951e-02,\n",
       "       -4.48864371e-01,  3.48598838e-01,  1.25799820e-01,  3.27396065e-01,\n",
       "       -4.12699133e-01,  3.59172016e-01,  3.53757530e-01, -7.46251523e-01,\n",
       "       -1.91736400e-01, -1.62176281e-01, -6.54996336e-02, -1.10133171e-01,\n",
       "        2.74755917e-02,  5.86873651e-01, -4.17338371e-01, -2.12501958e-01,\n",
       "        5.09799778e-01,  1.45335142e-02,  4.47910205e-02,  5.83738863e-01,\n",
       "        5.14768362e-01, -2.04281211e-01,  2.27250382e-01, -1.61616087e-01,\n",
       "        3.69255155e-01,  7.09592223e-01, -6.18215919e-01,  1.54303368e-02,\n",
       "        3.10916454e-01,  2.72778183e-01, -1.49294093e-01,  1.35985062e-01,\n",
       "       -5.61442375e-01,  3.02164495e-01, -2.38147983e-03, -1.66544601e-01,\n",
       "        1.63261026e-01,  1.84772670e-01, -2.86648214e-01,  6.50651991e-01,\n",
       "        2.94273853e-01,  4.82620299e-02,  7.83057064e-02,  4.05899465e-01,\n",
       "       -2.00624064e-01,  2.90536702e-01,  1.87359005e-01, -2.00049520e-01,\n",
       "       -5.50662987e-02, -3.02556336e-01,  3.67181480e-01,  4.92671579e-01,\n",
       "        6.39418483e-01, -1.58457831e-01,  2.81163268e-02,  9.70135480e-02,\n",
       "        3.87323827e-01,  1.74476847e-01, -1.93475798e-01, -1.93796635e-01,\n",
       "       -8.51647835e-03,  1.73545867e-01,  3.97986323e-01, -1.79784447e-01,\n",
       "        4.41916995e-02,  5.55466771e-01, -1.04485430e-01,  5.27639799e-02,\n",
       "       -3.22372168e-01,  2.27668718e-01,  1.52556375e-01, -2.22874597e-01,\n",
       "       -5.79608008e-02, -5.45793414e-01, -2.36794166e-02,  1.29585177e-01,\n",
       "       -7.34682083e-02, -1.15517698e-01, -2.13319987e-01,  2.42623731e-01,\n",
       "        3.01094115e-01,  1.86145976e-01, -2.80541807e-01, -1.55633241e-01,\n",
       "       -1.22682407e-01, -2.46180102e-01,  6.13289587e-02, -3.86222720e-01,\n",
       "        1.20078204e-02, -1.43401399e-01,  4.22383696e-01, -1.85352489e-01,\n",
       "        2.45620921e-01,  3.29205394e-02, -2.85347514e-02, -2.18560502e-01,\n",
       "        4.03264105e-01,  7.29909912e-02,  2.51252472e-01, -2.03092843e-01,\n",
       "        1.07524656e-01,  2.80142456e-01, -5.65016210e-01,  2.70164579e-01,\n",
       "       -1.18529417e-01,  3.08224082e-01, -6.83344156e-02,  4.58329380e-01,\n",
       "        2.01889634e-01, -5.87638736e-01, -4.99172151e-01,  6.21370435e-01,\n",
       "       -6.50518119e-01,  3.98991615e-01, -1.91687495e-02, -6.10019788e-02,\n",
       "       -3.95800099e-02, -1.12609088e-01, -5.82626350e-02,  1.02045938e-01,\n",
       "       -5.10640621e-01, -1.30498007e-01, -1.63056687e-01,  6.28899336e-01,\n",
       "       -1.70580864e-01, -3.34613204e-01, -2.04947107e-02,  1.97542340e-01,\n",
       "        1.46417722e-01, -6.10884614e-02, -2.81241775e-01,  1.76330492e-01,\n",
       "        1.00996420e-01,  1.21455573e-01,  3.18689138e-01,  2.86239088e-01,\n",
       "       -2.35738903e-01,  2.59002596e-01, -1.40191793e-01, -1.33745790e-01,\n",
       "       -2.30339438e-01,  2.13375181e-01, -4.31798518e-01, -2.83291452e-02,\n",
       "       -1.24102116e+00,  1.42506197e-01, -3.90851289e-01, -3.90684545e-01,\n",
       "       -1.66125260e-02, -1.65788502e-01,  2.69625425e-01, -3.55311811e-01,\n",
       "        4.95901890e-02, -4.41117287e-01,  2.87071848e-03, -1.48396879e-01,\n",
       "       -3.29144821e-02, -3.66557628e-01,  2.17549950e-01,  1.02361463e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_vec_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.3152e-01, -1.6142e-01, -6.6025e-01,  6.9478e-01,  6.3269e-01,\n",
       "          2.0186e-03,  5.9858e-01,  3.6002e-02, -3.0995e-01, -9.9944e-01,\n",
       "         -1.4121e-01,  6.9023e-01,  9.2246e-01,  1.5797e-01,  8.4201e-01,\n",
       "         -4.6704e-01,  9.1086e-02, -4.2290e-01,  9.7482e-02, -1.8251e-01,\n",
       "          5.5152e-01,  9.9961e-01,  2.3644e-01,  1.8933e-01,  2.9118e-01,\n",
       "          7.8276e-01, -4.8583e-01,  8.5905e-01,  9.1691e-01,  6.7787e-01,\n",
       "         -3.5032e-01,  4.6418e-02, -9.7380e-01,  2.3026e-02, -7.2224e-01,\n",
       "         -9.6038e-01,  1.2741e-01, -4.7933e-01,  2.9103e-01,  2.1464e-01,\n",
       "         -8.2852e-01,  5.1502e-02,  9.9917e-01, -5.6137e-01,  8.2981e-03,\n",
       "         -7.7006e-02, -9.9992e-01,  3.3902e-02, -7.8570e-01,  6.1217e-01,\n",
       "          5.3885e-01,  5.8188e-01, -3.9071e-02,  3.8031e-01,  2.0052e-01,\n",
       "         -1.3369e-01, -2.1647e-01,  1.0166e-01, -7.8609e-02, -4.3171e-01,\n",
       "         -4.6709e-01,  1.1096e-01, -6.1312e-01, -8.1470e-01,  4.4204e-01,\n",
       "          3.8159e-01,  3.8427e-02, -6.1329e-02, -4.9066e-03, -1.4936e-01,\n",
       "          6.1602e-01,  6.1557e-03,  6.0753e-02, -7.3431e-01,  1.3100e-01,\n",
       "          9.9836e-02, -5.6450e-01,  1.0000e+00, -4.0336e-02, -9.3972e-01,\n",
       "          6.8588e-01,  3.1013e-01,  5.0638e-01,  5.1013e-02, -3.1218e-02,\n",
       "         -1.0000e+00,  3.9523e-01,  4.3099e-03, -9.6985e-01,  1.0832e-01,\n",
       "          3.6614e-01, -6.3355e-02,  2.4025e-01,  4.9311e-01, -1.8863e-01,\n",
       "         -2.1217e-01, -8.0099e-02, -6.2066e-01, -8.1989e-02, -2.2180e-01,\n",
       "         -1.2735e-01, -4.1514e-02, -4.9998e-02, -1.6818e-01,  1.6945e-01,\n",
       "         -3.4562e-01, -1.8941e-01,  3.3679e-01,  1.3577e-02,  4.5646e-01,\n",
       "          4.7436e-01, -2.1985e-01,  2.1871e-01, -8.8992e-01,  2.9606e-01,\n",
       "         -1.5760e-01, -9.7237e-01, -5.4472e-01, -9.7758e-01,  3.9547e-01,\n",
       "          1.9435e-01, -1.1264e-01,  8.7998e-01,  1.4370e-01,  1.5701e-01,\n",
       "          1.0224e-01, -4.2912e-01, -1.0000e+00, -4.0640e-01, -3.5342e-01,\n",
       "          4.1527e-03, -1.5386e-01, -9.3458e-01, -9.4041e-01,  3.9473e-01,\n",
       "          9.2195e-01, -6.3106e-03,  9.9743e-01, -1.2027e-01,  8.4773e-01,\n",
       "          8.9686e-04, -4.0186e-01,  1.6669e-01, -2.3567e-01,  6.2610e-01,\n",
       "         -2.3317e-01, -7.8101e-02,  2.9553e-02, -1.0568e-01, -1.2326e-02,\n",
       "         -2.8582e-01, -7.8725e-02, -4.5966e-01, -8.5037e-01, -2.3846e-01,\n",
       "          9.0610e-01, -2.6738e-01, -6.0837e-01,  1.8702e-01, -8.4887e-02,\n",
       "         -1.4086e-01,  6.9318e-01,  4.3690e-01,  2.1602e-01, -2.2380e-02,\n",
       "          2.7955e-01, -3.5231e-01,  3.0544e-01, -5.5486e-01,  2.4158e-01,\n",
       "          2.4570e-01, -2.2128e-01, -6.5490e-01, -9.5611e-01, -1.6597e-01,\n",
       "          8.9567e-02,  9.7472e-01,  5.5203e-01,  6.4760e-02,  3.6558e-01,\n",
       "         -1.1740e-01,  3.7658e-01, -9.0985e-01,  9.6219e-01, -1.3179e-01,\n",
       "          2.1527e-01, -2.6536e-02,  2.1597e-01, -7.3046e-01, -2.0004e-02,\n",
       "          5.2858e-01, -6.1374e-01, -7.6655e-01,  9.1636e-02, -3.6710e-01,\n",
       "         -2.5195e-01, -6.3797e-01,  1.3335e-01, -1.2033e-01, -2.9244e-01,\n",
       "          6.2669e-02,  8.2467e-01,  8.5577e-01,  6.3561e-01, -2.3137e-01,\n",
       "          5.0005e-01, -8.4782e-01, -3.0393e-01,  5.6150e-02, -3.0222e-02,\n",
       "          1.4461e-01,  9.8338e-01, -3.0692e-01,  9.8824e-02, -8.8859e-01,\n",
       "         -9.6222e-01, -1.5364e-01, -8.4384e-01, -7.2971e-02, -3.4329e-01,\n",
       "          3.4492e-01, -8.9301e-02, -5.4632e-02,  1.4920e-01, -9.3687e-01,\n",
       "         -5.9788e-01,  1.7323e-01, -7.8081e-02,  1.7468e-01, -5.3595e-02,\n",
       "          5.4741e-01,  8.1113e-01, -3.5699e-01,  2.6806e-01,  8.5743e-01,\n",
       "         -7.4311e-01, -6.5063e-01,  6.0092e-01, -1.8750e-01,  7.1098e-01,\n",
       "         -3.9279e-01,  9.2615e-01,  6.0202e-01,  3.8569e-01, -7.8213e-01,\n",
       "         -3.4193e-01, -7.8093e-01, -9.5312e-02,  8.9815e-03, -4.7582e-01,\n",
       "          4.4887e-01,  5.9278e-01,  3.0765e-01,  5.9358e-01, -1.9340e-01,\n",
       "          9.4335e-01, -5.5611e-01, -9.2079e-01, -3.6729e-01,  1.4112e-01,\n",
       "         -9.6972e-01,  6.3624e-01,  2.1669e-01,  3.7638e-01, -2.2946e-01,\n",
       "         -2.2081e-01, -8.7514e-01,  6.5003e-01, -1.0431e-02,  9.1772e-01,\n",
       "         -4.6561e-02, -6.4448e-01, -3.0449e-01, -8.0211e-01, -1.9103e-01,\n",
       "         -3.9797e-02,  2.5836e-02, -1.6541e-01, -9.1721e-01,  4.0974e-01,\n",
       "          2.9627e-01,  2.7183e-01, -2.8082e-01,  9.6992e-01,  9.9999e-01,\n",
       "          8.9961e-01,  7.9229e-01,  5.6818e-01, -9.9517e-01, -7.1850e-01,\n",
       "          9.9983e-01, -9.0507e-01, -1.0000e+00, -8.8154e-01, -4.7779e-01,\n",
       "         -1.8676e-02, -1.0000e+00, -2.8361e-02,  1.5065e-01, -8.1169e-01,\n",
       "         -3.7283e-05,  9.1700e-01,  9.0475e-01, -1.0000e+00,  5.7146e-01,\n",
       "          8.9224e-01, -5.9826e-01,  6.5691e-01, -1.9512e-01,  9.1128e-01,\n",
       "          4.4863e-01,  3.7894e-01,  6.0172e-02,  9.1212e-02, -7.7134e-01,\n",
       "         -4.9092e-01, -5.4696e-02, -4.4868e-01,  9.8363e-01,  8.5798e-02,\n",
       "         -5.4694e-01, -7.4431e-01,  3.6006e-01,  3.9783e-02, -1.0892e-01,\n",
       "         -9.3772e-01, -6.9878e-02,  3.9163e-02,  5.1792e-01, -1.7459e-02,\n",
       "          1.5606e-01, -5.7663e-01,  1.7960e-01, -1.7985e-01, -2.9166e-01,\n",
       "          5.9992e-01, -7.8814e-01, -2.8500e-01, -3.4093e-01, -4.1876e-01,\n",
       "         -2.7520e-01, -9.2504e-01,  8.9478e-01, -3.0038e-01,  4.5216e-01,\n",
       "          1.0000e+00,  1.8940e-01, -6.6188e-01,  5.3169e-01,  7.0504e-02,\n",
       "         -5.4448e-01,  1.0000e+00,  7.8486e-01, -9.3764e-01, -5.2675e-01,\n",
       "          5.1559e-01, -3.0831e-01, -3.5499e-01,  9.9197e-01, -2.0692e-01,\n",
       "         -1.5350e-01,  5.2282e-02,  9.4679e-01, -9.7504e-01,  9.6142e-01,\n",
       "         -7.4619e-01, -9.5543e-01,  9.1516e-01,  8.8004e-01, -3.8748e-01,\n",
       "         -5.0161e-01,  1.1865e-02, -2.5495e-01,  1.9620e-01, -8.8888e-01,\n",
       "          5.5097e-01,  8.4740e-02,  2.4177e-02,  8.0579e-01, -4.8090e-01,\n",
       "         -5.2383e-01,  2.1178e-01, -4.3791e-01,  1.4759e-01,  7.5940e-01,\n",
       "          3.4845e-01, -7.7600e-02, -1.5018e-01, -1.9260e-01,  3.1912e-02,\n",
       "         -9.4691e-01,  4.9536e-01,  1.0000e+00, -2.2609e-01,  3.7730e-01,\n",
       "         -6.1499e-02,  2.1103e-02, -2.7052e-01,  2.8672e-01,  3.3955e-01,\n",
       "         -2.3308e-01, -4.5134e-01,  4.9091e-01, -7.9652e-01, -9.6858e-01,\n",
       "          5.8809e-01,  1.1494e-01,  6.1058e-02,  9.9873e-01,  2.2253e-01,\n",
       "          7.1860e-02,  2.4983e-02,  7.0108e-01, -2.6226e-01,  1.4204e-01,\n",
       "          3.3751e-01,  9.5057e-01, -7.7238e-02,  5.9529e-01,  6.4546e-01,\n",
       "         -4.7301e-01, -7.9601e-02, -4.4659e-01, -1.2446e-01, -8.5734e-01,\n",
       "          2.4049e-01, -9.1812e-01,  9.4697e-01,  5.2250e-01,  2.0165e-01,\n",
       "          2.2606e-01,  7.5039e-01,  1.0000e+00, -5.7833e-01,  3.0477e-01,\n",
       "          4.0167e-01,  4.4087e-01, -9.9750e-01, -4.0460e-01, -2.3340e-01,\n",
       "          1.2572e-01, -3.9177e-01, -1.2280e-01,  8.6449e-02, -9.1581e-01,\n",
       "          3.3331e-01,  3.0746e-01, -8.9737e-01, -9.6418e-01,  1.2912e-01,\n",
       "          5.5654e-01, -2.0591e-02, -8.8268e-01, -1.7092e-01, -3.9980e-01,\n",
       "          2.4817e-01, -1.8561e-01, -9.1538e-01,  2.0512e-01, -1.7649e-01,\n",
       "          2.5746e-01, -1.3969e-01,  5.0928e-01,  4.2669e-01,  8.5367e-01,\n",
       "         -6.9951e-01, -2.2245e-01,  9.3857e-02, -6.3576e-01,  3.7559e-01,\n",
       "         -5.1973e-01, -7.4583e-01,  9.0832e-03,  1.0000e+00, -3.4417e-01,\n",
       "          6.1437e-01,  3.7720e-01,  4.1954e-01, -1.0344e-01,  1.7081e-01,\n",
       "          7.6626e-01,  7.2329e-02, -3.1048e-01, -2.9568e-01,  1.0921e-01,\n",
       "         -2.1028e-01,  3.2972e-01,  9.7488e-02,  2.1688e-01,  6.6248e-01,\n",
       "          5.9117e-01, -2.0613e-02,  7.5295e-02, -2.1445e-01,  9.8595e-01,\n",
       "          2.0243e-02, -2.3686e-02, -1.8948e-01, -7.6192e-03, -1.3298e-01,\n",
       "          4.3606e-01,  1.0000e+00,  1.5027e-01,  1.0607e-02, -9.7083e-01,\n",
       "         -5.3412e-01, -7.0418e-01,  9.9998e-01,  7.5226e-01, -5.0995e-01,\n",
       "          4.8314e-01,  5.5910e-01,  5.6007e-02,  3.4503e-01, -1.4404e-01,\n",
       "         -1.0166e-01,  8.8373e-02,  6.0367e-02,  8.7531e-01, -3.3373e-01,\n",
       "         -9.0498e-01, -3.2475e-01,  2.2695e-01, -9.1389e-01,  9.9837e-01,\n",
       "         -2.9549e-01, -3.1906e-02, -6.3501e-02,  6.9799e-02, -2.4293e-01,\n",
       "         -1.0473e-01, -9.5564e-01, -1.2389e-02,  1.3663e-02,  9.1006e-01,\n",
       "          2.3716e-03, -5.5485e-01, -8.1209e-01,  4.1454e-01,  5.4623e-01,\n",
       "         -5.1101e-01, -8.5065e-01,  8.9398e-01, -9.6133e-01,  5.6564e-01,\n",
       "          9.9999e-01,  2.5568e-01, -3.1372e-01,  5.1037e-02, -3.1864e-02,\n",
       "          1.8017e-01, -2.8889e-01,  2.5562e-01, -9.0576e-01, -2.1795e-01,\n",
       "          4.4862e-02,  1.7386e-01, -5.9369e-03, -4.6256e-01,  4.3406e-01,\n",
       "         -2.3579e-03, -4.6894e-01, -4.2008e-01,  1.6321e-01,  3.2175e-01,\n",
       "          6.3779e-01, -1.8681e-01, -4.7004e-02, -5.4548e-02,  1.6202e-01,\n",
       "         -7.6653e-01, -1.1493e-01, -1.7077e-01, -9.9962e-01,  5.0513e-01,\n",
       "         -1.0000e+00,  4.0021e-01, -3.8835e-01, -6.2926e-02,  8.0326e-01,\n",
       "          5.4273e-01,  4.5032e-01, -5.4586e-01, -5.1865e-01,  7.4956e-01,\n",
       "          6.4193e-01, -7.5280e-02, -2.0356e-02, -5.2036e-01,  6.8901e-02,\n",
       "          2.1584e-01,  1.6030e-01, -4.5218e-01,  5.7743e-01, -8.0573e-02,\n",
       "          1.0000e+00,  3.9065e-02, -2.3053e-01, -9.0635e-01,  9.9623e-02,\n",
       "         -5.4146e-02,  9.9999e-01, -6.6935e-01, -9.0492e-01,  1.4078e-01,\n",
       "         -3.0776e-01, -6.8717e-01,  2.4732e-01, -1.8985e-01, -5.5627e-01,\n",
       "         -6.6527e-01,  8.3088e-01,  6.8511e-01, -6.0861e-01,  3.3327e-01,\n",
       "         -2.1912e-01, -4.1484e-01, -7.4109e-02,  5.5317e-01,  9.6954e-01,\n",
       "          3.1031e-01,  6.2972e-01,  4.7731e-02,  3.2061e-02,  9.2707e-01,\n",
       "          6.5907e-02,  1.2629e-01,  3.5214e-02,  1.0000e+00,  2.3778e-01,\n",
       "         -8.5057e-01,  1.0114e-01, -9.4135e-01, -5.6050e-02, -9.0512e-01,\n",
       "          2.0321e-01,  1.2440e-01,  8.4603e-01, -1.4218e-01,  8.5516e-01,\n",
       "         -2.4082e-01,  2.8687e-03, -2.2093e-01, -4.2497e-02,  2.6554e-01,\n",
       "         -8.7878e-01, -9.3924e-01, -9.6112e-01,  4.4979e-01, -2.4952e-01,\n",
       "          1.4793e-01,  8.7544e-02, -6.3096e-02,  2.4781e-01,  2.3022e-01,\n",
       "         -1.0000e+00,  8.9089e-01,  2.5895e-01,  4.9301e-01,  9.0640e-01,\n",
       "          6.1304e-01,  4.8358e-01,  2.3401e-01, -9.5171e-01, -8.4789e-01,\n",
       "         -9.6723e-02, -2.2022e-01,  5.0089e-01,  6.1404e-01,  7.0803e-01,\n",
       "          1.8836e-01, -3.7865e-01, -8.3836e-02, -3.7215e-01, -7.5787e-01,\n",
       "         -9.8606e-01,  2.2718e-01, -3.7923e-02, -7.4622e-01,  9.1610e-01,\n",
       "         -3.6020e-01, -1.6280e-02,  3.1935e-01, -6.8176e-01,  7.5068e-01,\n",
       "          4.5070e-01, -5.6081e-02,  5.3959e-02,  2.8219e-01,  7.4469e-01,\n",
       "          7.8419e-01,  9.4999e-01, -4.1532e-01,  5.3873e-01, -4.5729e-01,\n",
       "          2.5152e-01,  5.8821e-01, -8.5912e-01,  6.1899e-02,  3.1329e-01,\n",
       "         -8.1139e-02,  8.2116e-02, -1.0417e-01, -8.4363e-01,  4.9517e-01,\n",
       "         -1.9285e-01,  1.8806e-01, -1.8450e-01,  2.4128e-01, -2.6015e-01,\n",
       "         -1.2344e-01, -2.9723e-01, -2.7195e-01,  6.3402e-01, -4.7697e-02,\n",
       "          7.9536e-01,  6.8927e-01,  2.5405e-02, -3.4923e-01, -7.4815e-02,\n",
       "         -3.3537e-01, -8.7048e-01,  6.0291e-01,  2.3221e-01,  2.3824e-01,\n",
       "          4.8273e-01, -1.7685e-01,  7.7228e-01, -2.8772e-01, -2.8504e-01,\n",
       "         -1.5518e-01, -4.5508e-01,  6.4363e-01, -3.8095e-01, -3.5316e-01,\n",
       "         -3.6530e-01,  4.5639e-01,  1.1688e-01,  9.9917e-01, -3.2255e-01,\n",
       "         -4.4638e-01, -3.6950e-01, -2.3048e-01,  3.3480e-01, -2.2019e-01,\n",
       "         -1.0000e+00,  1.7358e-01, -4.0572e-01,  7.7976e-02, -5.7601e-01,\n",
       "          5.3005e-01, -4.1474e-01, -9.3675e-01,  8.4032e-02,  1.0674e-02,\n",
       "          5.0930e-01, -1.9578e-01, -4.5290e-01,  5.3901e-01,  4.0322e-02,\n",
       "          8.2259e-01,  7.1243e-01, -8.8639e-02,  4.5777e-01,  6.0856e-01,\n",
       "         -6.4211e-01, -5.3792e-01,  7.9749e-01]], grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_vec_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U-vjYgNGMWjF"
   },
   "source": [
    "# <span style=\"color:red\">*Exercise 3*</span>\n",
    "\n",
    "<span style=\"color:red\">Construct cells immediately below this that generate a BERT-powered chatbot tuned on text related to your final project. What is interesting about this model, and how to does it compare to an untrained model? What does it reveal about the social game involved with your dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CdyRVOlbOak7"
   },
   "source": [
    "In this exercise, I would like to use another dataset - trump_tweets_full.csv I used in my homework 7 which is different from the instructional notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n8i9AdCHIBch"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e3XA5b-ZOWPy"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"trump_tweets_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "rKAVpa8ZMVeF",
    "outputId": "bad18d53-24cd-4a8a-9310-fb5952825c5c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>id_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Just another Shifty Schiff leak. Isn’t there a...</td>\n",
       "      <td>02-23-2020 01:55:18</td>\n",
       "      <td>8444.0</td>\n",
       "      <td>26492</td>\n",
       "      <td>false</td>\n",
       "      <td>1.231397e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>“The Kremlin is reportedly backing Bernie Sand...</td>\n",
       "      <td>02-23-2020 00:17:24</td>\n",
       "      <td>13784.0</td>\n",
       "      <td>53063</td>\n",
       "      <td>false</td>\n",
       "      <td>1.231372e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Looks like Crazy Bernie is doing well in the G...</td>\n",
       "      <td>02-22-2020 23:55:36</td>\n",
       "      <td>15341.0</td>\n",
       "      <td>71155</td>\n",
       "      <td>false</td>\n",
       "      <td>1.231367e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>RT @mattgaetz: Zeldin is absolutely correct.Ka...</td>\n",
       "      <td>02-22-2020 22:54:18</td>\n",
       "      <td>5323.0</td>\n",
       "      <td>0</td>\n",
       "      <td>true</td>\n",
       "      <td>1.231352e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>RT @fonzy1984: @RubinReport What about the His...</td>\n",
       "      <td>02-22-2020 22:47:57</td>\n",
       "      <td>3725.0</td>\n",
       "      <td>0</td>\n",
       "      <td>true</td>\n",
       "      <td>1.231350e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               source  ...        id_str\n",
       "0  Twitter for iPhone  ...  1.231397e+18\n",
       "1  Twitter for iPhone  ...  1.231372e+18\n",
       "2  Twitter for iPhone  ...  1.231367e+18\n",
       "3  Twitter for iPhone  ...  1.231352e+18\n",
       "4  Twitter for iPhone  ...  1.231350e+18\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VqTp8IMHyk0R",
    "outputId": "2cb85396-fd7e-4053-b4c6-f608a9ab0d35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42982, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "liF-aTHByyDW"
   },
   "source": [
    "We can only keep the first 5000 tweets for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SNeWI77Zy9oB"
   },
   "outputs": [],
   "source": [
    "df = df[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xz6-BP1vNMZe"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_text, test_text = train_test_split(df['text'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "PWdTnDyANU9r",
    "outputId": "89d16063-b9ef-4738-d513-52f50b02a4d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4810                                  KEEP AMERICA GREAT!\n",
       "3589    False stories are being reported that a few Re...\n",
       "2493    I don’t know what report current Director of t...\n",
       "4679    ....a Nancy Pelosi/Chuck Schumer Democrat (Joh...\n",
       "4361            Sleepy Joe Biden! https://t.co/oZtytImXqq\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w6tkoGonNYFO"
   },
   "outputs": [],
   "source": [
    "train_text.to_frame().to_csv(r'train_text_trump', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7jYvqlYzNa-U"
   },
   "outputs": [],
   "source": [
    "test_text.to_frame().to_csv(r'test_text_trump', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oxopm8-ONdNr"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "sh4KWKp31SJ2",
    "outputId": "6e1e159f-6699-42ad-bc4c-9dc7dc484787"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/03/2020 06:44:48 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "03/03/2020 06:44:49 - INFO - filelock -   Lock 140311816739080 acquired on /root/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.699bbd1c449e9861456f359d6daa51bd523ac085b4b531ab0aad5a55d091e942.lock\n",
      "03/03/2020 06:44:49 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpf7ndq3le\n",
      "Downloading: 100% 224/224 [00:00<00:00, 250kB/s]\n",
      "03/03/2020 06:44:49 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json in cache at /root/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.699bbd1c449e9861456f359d6daa51bd523ac085b4b531ab0aad5a55d091e942\n",
      "03/03/2020 06:44:49 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.699bbd1c449e9861456f359d6daa51bd523ac085b4b531ab0aad5a55d091e942\n",
      "03/03/2020 06:44:49 - INFO - filelock -   Lock 140311816739080 released on /root/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.699bbd1c449e9861456f359d6daa51bd523ac085b4b531ab0aad5a55d091e942.lock\n",
      "03/03/2020 06:44:49 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /root/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.699bbd1c449e9861456f359d6daa51bd523ac085b4b531ab0aad5a55d091e942\n",
      "03/03/2020 06:44:49 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_ids\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "03/03/2020 06:44:50 - INFO - filelock -   Lock 140312189519688 acquired on /root/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71.lock\n",
      "03/03/2020 06:44:50 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpbg7479zf\n",
      "Downloading: 100% 1.04M/1.04M [00:00<00:00, 2.03MB/s]\n",
      "03/03/2020 06:44:50 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json in cache at /root/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "03/03/2020 06:44:50 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "03/03/2020 06:44:50 - INFO - filelock -   Lock 140312189519688 released on /root/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71.lock\n",
      "03/03/2020 06:44:51 - INFO - filelock -   Lock 140312189519688 acquired on /root/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n",
      "03/03/2020 06:44:51 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpcsg99nk5\n",
      "Downloading: 100% 456k/456k [00:00<00:00, 1.34MB/s]\n",
      "03/03/2020 06:44:52 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt in cache at /root/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "03/03/2020 06:44:52 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "03/03/2020 06:44:52 - INFO - filelock -   Lock 140312189519688 released on /root/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n",
      "03/03/2020 06:44:52 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /root/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "03/03/2020 06:44:52 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /root/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "03/03/2020 06:44:52 - INFO - filelock -   Lock 140311816705472 acquired on /root/.cache/torch/transformers/4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1.lock\n",
      "03/03/2020 06:44:52 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpu_eazm0b\n",
      "Downloading: 100% 548M/548M [00:21<00:00, 25.4MB/s]\n",
      "03/03/2020 06:45:14 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin in cache at /root/.cache/torch/transformers/4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "03/03/2020 06:45:14 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "03/03/2020 06:45:14 - INFO - filelock -   Lock 140311816705472 released on /root/.cache/torch/transformers/4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1.lock\n",
      "03/03/2020 06:45:14 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at /root/.cache/torch/transformers/4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "03/03/2020 06:45:28 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=1024, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=True, eval_all_checkpoints=False, eval_data_file='/content/test_text_trump', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=False, mlm_probability=0.15, model_name_or_path='gpt2', model_type='gpt2', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output_gpt_trump', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=1, per_gpu_train_batch_size=1, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/train_text_trump', warmup_steps=0, weight_decay=0.0)\n",
      "03/03/2020 06:45:28 - INFO - __main__ -   Creating features from dataset file at /content\n",
      "03/03/2020 06:45:28 - INFO - __main__ -   Saving features into cached file /content/gpt2_cached_lm_1024_train_text_trump\n",
      "03/03/2020 06:45:28 - INFO - __main__ -   ***** Running training *****\n",
      "03/03/2020 06:45:28 - INFO - __main__ -     Num examples = 153\n",
      "03/03/2020 06:45:28 - INFO - __main__ -     Num Epochs = 1\n",
      "03/03/2020 06:45:28 - INFO - __main__ -     Instantaneous batch size per GPU = 1\n",
      "03/03/2020 06:45:28 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "03/03/2020 06:45:28 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
      "03/03/2020 06:45:28 - INFO - __main__ -     Total optimization steps = 153\n",
      "Epoch:   0% 0/1 [00:00<?, ?it/s]\n",
      "Iteration:   0% 0/153 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   1% 1/153 [00:00<01:38,  1.55it/s]\u001b[A\n",
      "Iteration:   1% 2/153 [00:01<01:26,  1.74it/s]\u001b[A\n",
      "Iteration:   2% 3/153 [00:01<01:19,  1.88it/s]\u001b[A\n",
      "Iteration:   3% 4/153 [00:01<01:14,  2.01it/s]\u001b[A\n",
      "Iteration:   3% 5/153 [00:02<01:10,  2.09it/s]\u001b[A\n",
      "Iteration:   4% 6/153 [00:02<01:08,  2.15it/s]\u001b[A\n",
      "Iteration:   5% 7/153 [00:03<01:05,  2.22it/s]\u001b[A\n",
      "Iteration:   5% 8/153 [00:03<01:04,  2.24it/s]\u001b[A\n",
      "Iteration:   6% 9/153 [00:04<01:03,  2.27it/s]\u001b[A\n",
      "Iteration:   7% 10/153 [00:04<01:02,  2.28it/s]\u001b[A\n",
      "Iteration:   7% 11/153 [00:04<01:01,  2.31it/s]\u001b[A\n",
      "Iteration:   8% 12/153 [00:05<01:01,  2.31it/s]\u001b[A\n",
      "Iteration:   8% 13/153 [00:05<01:00,  2.30it/s]\u001b[A\n",
      "Iteration:   9% 14/153 [00:06<00:59,  2.32it/s]\u001b[A\n",
      "Iteration:  10% 15/153 [00:06<00:59,  2.31it/s]\u001b[A\n",
      "Iteration:  10% 16/153 [00:07<00:59,  2.32it/s]\u001b[A\n",
      "Iteration:  11% 17/153 [00:07<00:59,  2.28it/s]\u001b[A\n",
      "Iteration:  12% 18/153 [00:07<00:58,  2.32it/s]\u001b[A\n",
      "Iteration:  12% 19/153 [00:08<00:57,  2.31it/s]\u001b[A\n",
      "Iteration:  13% 20/153 [00:08<00:57,  2.31it/s]\u001b[A\n",
      "Iteration:  14% 21/153 [00:09<00:57,  2.31it/s]\u001b[A\n",
      "Iteration:  14% 22/153 [00:09<00:56,  2.30it/s]\u001b[A\n",
      "Iteration:  15% 23/153 [00:10<00:56,  2.30it/s]\u001b[A\n",
      "Iteration:  16% 24/153 [00:10<00:56,  2.29it/s]\u001b[A\n",
      "Iteration:  16% 25/153 [00:10<00:55,  2.29it/s]\u001b[A\n",
      "Iteration:  17% 26/153 [00:11<00:55,  2.28it/s]\u001b[A\n",
      "Iteration:  18% 27/153 [00:11<00:55,  2.28it/s]\u001b[A\n",
      "Iteration:  18% 28/153 [00:12<00:54,  2.28it/s]\u001b[A\n",
      "Iteration:  19% 29/153 [00:12<00:54,  2.28it/s]\u001b[A\n",
      "Iteration:  20% 30/153 [00:13<00:54,  2.28it/s]\u001b[A\n",
      "Iteration:  20% 31/153 [00:13<00:54,  2.26it/s]\u001b[A\n",
      "Iteration:  21% 32/153 [00:14<00:53,  2.27it/s]\u001b[A\n",
      "Iteration:  22% 33/153 [00:14<00:53,  2.26it/s]\u001b[A\n",
      "Iteration:  22% 34/153 [00:14<00:52,  2.26it/s]\u001b[A\n",
      "Iteration:  23% 35/153 [00:15<00:52,  2.25it/s]\u001b[A\n",
      "Iteration:  24% 36/153 [00:15<00:52,  2.25it/s]\u001b[A\n",
      "Iteration:  24% 37/153 [00:16<00:51,  2.25it/s]\u001b[A\n",
      "Iteration:  25% 38/153 [00:16<00:51,  2.24it/s]\u001b[A\n",
      "Iteration:  25% 39/153 [00:17<00:50,  2.24it/s]\u001b[A\n",
      "Iteration:  26% 40/153 [00:17<00:50,  2.23it/s]\u001b[A\n",
      "Iteration:  27% 41/153 [00:18<00:50,  2.24it/s]\u001b[A\n",
      "Iteration:  27% 42/153 [00:18<00:49,  2.23it/s]\u001b[A\n",
      "Iteration:  28% 43/153 [00:18<00:49,  2.23it/s]\u001b[A\n",
      "Iteration:  29% 44/153 [00:19<00:49,  2.22it/s]\u001b[A\n",
      "Iteration:  29% 45/153 [00:19<00:48,  2.23it/s]\u001b[A\n",
      "Iteration:  30% 46/153 [00:20<00:48,  2.22it/s]\u001b[A\n",
      "Iteration:  31% 47/153 [00:20<00:47,  2.22it/s]\u001b[A\n",
      "Iteration:  31% 48/153 [00:21<00:47,  2.22it/s]\u001b[A\n",
      "Iteration:  32% 49/153 [00:21<00:47,  2.21it/s]\u001b[A\n",
      "Iteration:  33% 50/153 [00:22<00:46,  2.21it/s]\u001b[A\n",
      "Iteration:  33% 51/153 [00:22<00:46,  2.20it/s]\u001b[A\n",
      "Iteration:  34% 52/153 [00:23<00:45,  2.20it/s]\u001b[A\n",
      "Iteration:  35% 53/153 [00:23<00:45,  2.19it/s]\u001b[A\n",
      "Iteration:  35% 54/153 [00:23<00:45,  2.19it/s]\u001b[A\n",
      "Iteration:  36% 55/153 [00:24<00:44,  2.18it/s]\u001b[A\n",
      "Iteration:  37% 56/153 [00:24<00:44,  2.18it/s]\u001b[A\n",
      "Iteration:  37% 57/153 [00:25<00:43,  2.19it/s]\u001b[A\n",
      "Iteration:  38% 58/153 [00:25<00:43,  2.18it/s]\u001b[A\n",
      "Iteration:  39% 59/153 [00:26<00:43,  2.17it/s]\u001b[A\n",
      "Iteration:  39% 60/153 [00:26<00:42,  2.17it/s]\u001b[A\n",
      "Iteration:  40% 61/153 [00:27<00:42,  2.17it/s]\u001b[A\n",
      "Iteration:  41% 62/153 [00:27<00:41,  2.17it/s]\u001b[A\n",
      "Iteration:  41% 63/153 [00:28<00:41,  2.17it/s]\u001b[A\n",
      "Iteration:  42% 64/153 [00:28<00:41,  2.17it/s]\u001b[A\n",
      "Iteration:  42% 65/153 [00:29<00:40,  2.16it/s]\u001b[A\n",
      "Iteration:  43% 66/153 [00:29<00:40,  2.16it/s]\u001b[A\n",
      "Iteration:  44% 67/153 [00:29<00:39,  2.16it/s]\u001b[A\n",
      "Iteration:  44% 68/153 [00:30<00:39,  2.17it/s]\u001b[A\n",
      "Iteration:  45% 69/153 [00:30<00:38,  2.16it/s]\u001b[A\n",
      "Iteration:  46% 70/153 [00:31<00:38,  2.16it/s]\u001b[A\n",
      "Iteration:  46% 71/153 [00:31<00:37,  2.16it/s]\u001b[A\n",
      "Iteration:  47% 72/153 [00:32<00:37,  2.16it/s]\u001b[A\n",
      "Iteration:  48% 73/153 [00:32<00:36,  2.17it/s]\u001b[A\n",
      "Iteration:  48% 74/153 [00:33<00:36,  2.17it/s]\u001b[A\n",
      "Iteration:  49% 75/153 [00:33<00:35,  2.17it/s]\u001b[A\n",
      "Iteration:  50% 76/153 [00:34<00:35,  2.18it/s]\u001b[A\n",
      "Iteration:  50% 77/153 [00:34<00:34,  2.18it/s]\u001b[A\n",
      "Iteration:  51% 78/153 [00:35<00:34,  2.18it/s]\u001b[A\n",
      "Iteration:  52% 79/153 [00:35<00:33,  2.19it/s]\u001b[A\n",
      "Iteration:  52% 80/153 [00:35<00:33,  2.19it/s]\u001b[A\n",
      "Iteration:  53% 81/153 [00:36<00:32,  2.20it/s]\u001b[A\n",
      "Iteration:  54% 82/153 [00:36<00:32,  2.20it/s]\u001b[A\n",
      "Iteration:  54% 83/153 [00:37<00:31,  2.21it/s]\u001b[A\n",
      "Iteration:  55% 84/153 [00:37<00:31,  2.21it/s]\u001b[A\n",
      "Iteration:  56% 85/153 [00:38<00:30,  2.21it/s]\u001b[A\n",
      "Iteration:  56% 86/153 [00:38<00:30,  2.22it/s]\u001b[A\n",
      "Iteration:  57% 87/153 [00:39<00:29,  2.22it/s]\u001b[A\n",
      "Iteration:  58% 88/153 [00:39<00:29,  2.22it/s]\u001b[A\n",
      "Iteration:  58% 89/153 [00:40<00:28,  2.22it/s]\u001b[A\n",
      "Iteration:  59% 90/153 [00:40<00:28,  2.22it/s]\u001b[A\n",
      "Iteration:  59% 91/153 [00:40<00:27,  2.23it/s]\u001b[A\n",
      "Iteration:  60% 92/153 [00:41<00:27,  2.23it/s]\u001b[A\n",
      "Iteration:  61% 93/153 [00:41<00:26,  2.24it/s]\u001b[A\n",
      "Iteration:  61% 94/153 [00:42<00:26,  2.24it/s]\u001b[A\n",
      "Iteration:  62% 95/153 [00:42<00:25,  2.24it/s]\u001b[A\n",
      "Iteration:  63% 96/153 [00:43<00:25,  2.24it/s]\u001b[A\n",
      "Iteration:  63% 97/153 [00:43<00:24,  2.24it/s]\u001b[A\n",
      "Iteration:  64% 98/153 [00:44<00:24,  2.24it/s]\u001b[A\n",
      "Iteration:  65% 99/153 [00:44<00:24,  2.24it/s]\u001b[A\n",
      "Iteration:  65% 100/153 [00:44<00:23,  2.24it/s]\u001b[A\n",
      "Iteration:  66% 101/153 [00:45<00:23,  2.24it/s]\u001b[A\n",
      "Iteration:  67% 102/153 [00:45<00:22,  2.24it/s]\u001b[A\n",
      "Iteration:  67% 103/153 [00:46<00:22,  2.25it/s]\u001b[A\n",
      "Iteration:  68% 104/153 [00:46<00:21,  2.26it/s]\u001b[A\n",
      "Iteration:  69% 105/153 [00:47<00:21,  2.26it/s]\u001b[A\n",
      "Iteration:  69% 106/153 [00:47<00:20,  2.26it/s]\u001b[A\n",
      "Iteration:  70% 107/153 [00:48<00:20,  2.25it/s]\u001b[A\n",
      "Iteration:  71% 108/153 [00:48<00:19,  2.26it/s]\u001b[A\n",
      "Iteration:  71% 109/153 [00:48<00:19,  2.27it/s]\u001b[A\n",
      "Iteration:  72% 110/153 [00:49<00:18,  2.28it/s]\u001b[A\n",
      "Iteration:  73% 111/153 [00:49<00:18,  2.28it/s]\u001b[A\n",
      "Iteration:  73% 112/153 [00:50<00:17,  2.28it/s]\u001b[A\n",
      "Iteration:  74% 113/153 [00:50<00:17,  2.28it/s]\u001b[A\n",
      "Iteration:  75% 114/153 [00:51<00:17,  2.28it/s]\u001b[A\n",
      "Iteration:  75% 115/153 [00:51<00:16,  2.28it/s]\u001b[A\n",
      "Iteration:  76% 116/153 [00:51<00:16,  2.28it/s]\u001b[A\n",
      "Iteration:  76% 117/153 [00:52<00:15,  2.28it/s]\u001b[A\n",
      "Iteration:  77% 118/153 [00:52<00:15,  2.28it/s]\u001b[A\n",
      "Iteration:  78% 119/153 [00:53<00:14,  2.28it/s]\u001b[A\n",
      "Iteration:  78% 120/153 [00:53<00:14,  2.28it/s]\u001b[A\n",
      "Iteration:  79% 121/153 [00:54<00:13,  2.29it/s]\u001b[A\n",
      "Iteration:  80% 122/153 [00:54<00:13,  2.29it/s]\u001b[A\n",
      "Iteration:  80% 123/153 [00:55<00:13,  2.29it/s]\u001b[A\n",
      "Iteration:  81% 124/153 [00:55<00:12,  2.30it/s]\u001b[A\n",
      "Iteration:  82% 125/153 [00:55<00:12,  2.29it/s]\u001b[A\n",
      "Iteration:  82% 126/153 [00:56<00:11,  2.30it/s]\u001b[A\n",
      "Iteration:  83% 127/153 [00:56<00:11,  2.30it/s]\u001b[A\n",
      "Iteration:  84% 128/153 [00:57<00:10,  2.30it/s]\u001b[A\n",
      "Iteration:  84% 129/153 [00:57<00:10,  2.30it/s]\u001b[A\n",
      "Iteration:  85% 130/153 [00:58<00:10,  2.30it/s]\u001b[A\n",
      "Iteration:  86% 131/153 [00:58<00:09,  2.30it/s]\u001b[A\n",
      "Iteration:  86% 132/153 [00:58<00:09,  2.31it/s]\u001b[A\n",
      "Iteration:  87% 133/153 [00:59<00:08,  2.30it/s]\u001b[A\n",
      "Iteration:  88% 134/153 [00:59<00:08,  2.31it/s]\u001b[A\n",
      "Iteration:  88% 135/153 [01:00<00:07,  2.30it/s]\u001b[A\n",
      "Iteration:  89% 136/153 [01:00<00:07,  2.31it/s]\u001b[A\n",
      "Iteration:  90% 137/153 [01:01<00:06,  2.31it/s]\u001b[A\n",
      "Iteration:  90% 138/153 [01:01<00:06,  2.31it/s]\u001b[A\n",
      "Iteration:  91% 139/153 [01:01<00:06,  2.31it/s]\u001b[A\n",
      "Iteration:  92% 140/153 [01:02<00:05,  2.31it/s]\u001b[A\n",
      "Iteration:  92% 141/153 [01:02<00:05,  2.31it/s]\u001b[A\n",
      "Iteration:  93% 142/153 [01:03<00:04,  2.31it/s]\u001b[A\n",
      "Iteration:  93% 143/153 [01:03<00:04,  2.31it/s]\u001b[A\n",
      "Iteration:  94% 144/153 [01:04<00:03,  2.31it/s]\u001b[A\n",
      "Iteration:  95% 145/153 [01:04<00:03,  2.31it/s]\u001b[A\n",
      "Iteration:  95% 146/153 [01:04<00:03,  2.31it/s]\u001b[A\n",
      "Iteration:  96% 147/153 [01:05<00:02,  2.31it/s]\u001b[A\n",
      "Iteration:  97% 148/153 [01:05<00:02,  2.31it/s]\u001b[A\n",
      "Iteration:  97% 149/153 [01:06<00:01,  2.31it/s]\u001b[A\n",
      "Iteration:  98% 150/153 [01:06<00:01,  2.32it/s]\u001b[A\n",
      "Iteration:  99% 151/153 [01:07<00:00,  2.32it/s]\u001b[A\n",
      "Iteration:  99% 152/153 [01:07<00:00,  2.32it/s]\u001b[A\n",
      "Iteration: 100% 153/153 [01:08<00:00,  2.32it/s]\u001b[A\n",
      "Epoch: 100% 1/1 [01:08<00:00, 68.02s/it]\n",
      "03/03/2020 06:46:36 - INFO - __main__ -    global_step = 153, average loss = 3.647780231401032\n",
      "03/03/2020 06:46:36 - INFO - __main__ -   Saving model checkpoint to output_gpt_trump\n",
      "03/03/2020 06:46:36 - INFO - transformers.configuration_utils -   Configuration saved in output_gpt_trump/config.json\n",
      "03/03/2020 06:46:38 - INFO - transformers.modeling_utils -   Model weights saved in output_gpt_trump/pytorch_model.bin\n",
      "03/03/2020 06:46:38 - INFO - transformers.configuration_utils -   loading configuration file output_gpt_trump/config.json\n",
      "03/03/2020 06:46:38 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_ids\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "03/03/2020 06:46:38 - INFO - transformers.modeling_utils -   loading weights file output_gpt_trump/pytorch_model.bin\n",
      "03/03/2020 06:46:42 - INFO - transformers.tokenization_utils -   Model name 'output_gpt_trump' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming 'output_gpt_trump' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "03/03/2020 06:46:42 - INFO - transformers.tokenization_utils -   Didn't find file output_gpt_trump/added_tokens.json. We won't load it.\n",
      "03/03/2020 06:46:42 - INFO - transformers.tokenization_utils -   loading file output_gpt_trump/vocab.json\n",
      "03/03/2020 06:46:42 - INFO - transformers.tokenization_utils -   loading file output_gpt_trump/merges.txt\n",
      "03/03/2020 06:46:42 - INFO - transformers.tokenization_utils -   loading file None\n",
      "03/03/2020 06:46:42 - INFO - transformers.tokenization_utils -   loading file output_gpt_trump/special_tokens_map.json\n",
      "03/03/2020 06:46:42 - INFO - transformers.tokenization_utils -   loading file output_gpt_trump/tokenizer_config.json\n",
      "03/03/2020 06:46:42 - INFO - __main__ -   Evaluate the following checkpoints: ['output_gpt_trump']\n",
      "03/03/2020 06:46:42 - INFO - transformers.configuration_utils -   loading configuration file output_gpt_trump/config.json\n",
      "03/03/2020 06:46:42 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_ids\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "03/03/2020 06:46:42 - INFO - transformers.modeling_utils -   loading weights file output_gpt_trump/pytorch_model.bin\n",
      "03/03/2020 06:46:45 - INFO - __main__ -   Creating features from dataset file at /content\n",
      "03/03/2020 06:46:46 - INFO - __main__ -   Saving features into cached file /content/gpt2_cached_lm_1024_test_text_trump\n",
      "03/03/2020 06:46:46 - INFO - __main__ -   ***** Running evaluation  *****\n",
      "03/03/2020 06:46:46 - INFO - __main__ -     Num examples = 38\n",
      "03/03/2020 06:46:46 - INFO - __main__ -     Batch size = 1\n",
      "Evaluating: 100% 38/38 [00:05<00:00,  7.62it/s]\n",
      "03/03/2020 06:46:51 - INFO - __main__ -   ***** Eval results  *****\n",
      "03/03/2020 06:46:51 - INFO - __main__ -     perplexity = tensor(29.5508)\n"
     ]
    }
   ],
   "source": [
    "!python /content/run_language_modelling.py --output_dir=output_gpt_trump --model_type=gpt2 --model_name_or_path=gpt2 --do_train --train_data_file=/content/train_text_trump --do_eval --eval_data_file=/content/test_text_trump --per_gpu_train_batch_size=1 --per_gpu_eval_batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nhWKHg8-JrU5",
    "outputId": "fc863ab2-71d9-45f9-acfd-804d7c09ad9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/03/2020 06:57:04 - INFO - transformers.tokenization_utils -   Model name '/content/output_gpt_trump' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming '/content/output_gpt_trump' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "03/03/2020 06:57:04 - INFO - transformers.tokenization_utils -   Didn't find file /content/output_gpt_trump/added_tokens.json. We won't load it.\n",
      "03/03/2020 06:57:04 - INFO - transformers.tokenization_utils -   loading file /content/output_gpt_trump/vocab.json\n",
      "03/03/2020 06:57:04 - INFO - transformers.tokenization_utils -   loading file /content/output_gpt_trump/merges.txt\n",
      "03/03/2020 06:57:04 - INFO - transformers.tokenization_utils -   loading file None\n",
      "03/03/2020 06:57:04 - INFO - transformers.tokenization_utils -   loading file /content/output_gpt_trump/special_tokens_map.json\n",
      "03/03/2020 06:57:04 - INFO - transformers.tokenization_utils -   loading file /content/output_gpt_trump/tokenizer_config.json\n",
      "03/03/2020 06:57:04 - INFO - transformers.configuration_utils -   loading configuration file /content/output_gpt_trump/config.json\n",
      "03/03/2020 06:57:04 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_ids\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "03/03/2020 06:57:04 - INFO - transformers.modeling_utils -   loading weights file /content/output_gpt_trump/pytorch_model.bin\n",
      "03/03/2020 06:57:12 - INFO - __main__ -   Namespace(device=device(type='cuda'), k=0, length=20, model_name_or_path='/content/output_gpt_trump', model_type='gpt2', n_gpu=1, no_cuda=False, num_return_sequences=1, p=0.9, padding_text='', prompt='', repetition_penalty=1.0, seed=42, stop_token=None, temperature=1.0, xlm_language='')\n",
      "Model prompt >>> president election is\n",
      "=== GENERATED SEQUENCE 1 ===\n",
      "president election is very disappointing for both parties. The party has been running on the idea of ending unlawful government contracts and\n"
     ]
    }
   ],
   "source": [
    "!python run_generation.py --model_type=gpt2 --model_name_or_path=/content/output_gpt_trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nWzaEhtZMiOi"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelWithLMHead, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NGqf-2sMeZrM"
   },
   "outputs": [],
   "source": [
    "tokenizer_trump = AutoTokenizer.from_pretrained(\"output_gpt_trump\")\n",
    "model_trump = AutoModelWithLMHead.from_pretrained(\"output_gpt_trump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "BQFWlx7JeujQ",
    "outputId": "dbb46b1d-3ed0-45d7-c76c-e22ee7f363d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "president election is over.\"\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "sequence = \"president election is\"\n",
    "\n",
    "input = tokenizer_trump.encode(sequence, return_tensors=\"pt\")\n",
    "generated = model_trump.generate(input, max_length=50, bos_token_id=1, pad_token_id=1, eos_token_ids=1)\n",
    "\n",
    "resulting_string = tokenizer_trump.decode(generated.tolist()[0])\n",
    "print(resulting_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qNY_7TIqfyzV"
   },
   "outputs": [],
   "source": [
    "tokenizer_gpt = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model_gpt = AutoModelWithLMHead.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "KoStWf3KfBzp",
    "outputId": "6706f7e1-6225-4158-f9fe-8653d39c14ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "president election is not enough. Our Party is on the path to becoming the country we desire,\" he said, adding that he cannot accept the result if he does not address the issue. He did offer that the government will not hold the second referendum in\n"
     ]
    }
   ],
   "source": [
    "sequence = \"president election is\"\n",
    "\n",
    "input = tokenizer_gpt.encode(sequence, return_tensors=\"pt\")\n",
    "generated = model_gpt.generate(input, max_length=50, bos_token_id=1, pad_token_id=1, eos_token_ids=1)\n",
    "\n",
    "resulting_string = tokenizer_gpt.decode(generated.tolist()[0])\n",
    "print(resulting_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T2W2z4zVf6yb"
   },
   "source": [
    "It is very interesting to see that is quite contrast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g3CfpLekMYhW"
   },
   "source": [
    "# <span style=\"color:red\">*Exercise 4*</span>\n",
    "\n",
    "<span style=\"color:red\">Construct cells immediately below this that tune BERT to at least two different textual samples. These could be from different corpora, distinct time periods, separate authors, alternative publishing outlets, etc. Then compare the meaning of words, phrases and sentences to each other across the separate models. What do they reveal about the social worlds inscribed by the distinctive samples?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZjYNm9Du6zKS"
   },
   "source": [
    "In this exercise, I continue to use the review dataset I used in previous homeworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U8mZ7GUs6ygO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "D8zhE6jx7GVA",
    "outputId": "abe63dab-0931-466e-ac6e-1b12ea45427b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Clothing ID  Age  ...   Division Name Department Name  Class Name\n",
       "0           0          767   33  ...       Initmates        Intimate   Intimates\n",
       "1           1         1080   34  ...         General         Dresses     Dresses\n",
       "2           2         1077   60  ...         General         Dresses     Dresses\n",
       "3           3         1049   50  ...  General Petite         Bottoms       Pants\n",
       "4           4          847   47  ...         General            Tops     Blouses\n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "review_raw = pd.read_csv(\"review.csv\")\n",
    "review_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qns7nfDQ7R77"
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig, RobertaModel, RobertaTokenizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "4DOaCgLU7cs8",
    "outputId": "be8fbcac-bc52-4c41-f4bf-335569fbd89b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>Intimates</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>Pants</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review Text  Rating Class Name  Age\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4  Intimates   33\n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5    Dresses   34\n",
       "2  I had such high hopes for this dress and reall...       3    Dresses   60\n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5      Pants   50\n",
       "4  This shirt is very flattering to all due to th...       5    Blouses   47"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# form the analysis dataset\n",
    "review = review_raw[['Review Text','Rating','Class Name','Age']]\n",
    "review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qZfXhT0M9wIu"
   },
   "outputs": [],
   "source": [
    "# fill NA values by space\n",
    "review['Review Text'] = review['Review Text'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QwCwzYwt9_Of"
   },
   "outputs": [],
   "source": [
    "# rating = 3 neutral\n",
    "# rating >= 4 postive\n",
    "# rating <= 2 negative\n",
    "df1 = review[review['Rating']==3]\n",
    "df2 = review[review['Rating']>=4]\n",
    "df3 = review[review['Rating']<=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "a0BXGZV3_DUV",
    "outputId": "ce6d00b7-a6a8-46d2-9a59-4f6448192796"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dress runs small esp where the zipper area run...</td>\n",
       "      <td>3</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>This is a nice choice for holiday gatherings. ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Material and color is nice.  the leg opening i...</td>\n",
       "      <td>3</td>\n",
       "      <td>Pants</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Cute little dress fits tts. it is a little hig...</td>\n",
       "      <td>3</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Review Text  Rating Class Name  Age\n",
       "2   I had such high hopes for this dress and reall...       3    Dresses   60\n",
       "10  Dress runs small esp where the zipper area run...       3    Dresses   53\n",
       "14  This is a nice choice for holiday gatherings. ...       3    Dresses   50\n",
       "16  Material and color is nice.  the leg opening i...       3      Pants   34\n",
       "23  Cute little dress fits tts. it is a little hig...       3    Dresses   34"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# neutral reviews\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "JFBHyo1KAcb4",
    "outputId": "47b245df-48c1-473d-9378-5d8da794cf21"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>Intimates</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>Pants</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I aded this in my basket at hte last mintue to...</td>\n",
       "      <td>5</td>\n",
       "      <td>Knits</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review Text  Rating Class Name  Age\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4  Intimates   33\n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5    Dresses   34\n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5      Pants   50\n",
       "4  This shirt is very flattering to all due to th...       5    Blouses   47\n",
       "6  I aded this in my basket at hte last mintue to...       5      Knits   39"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# positve reviews\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "pdVs2clIAnbU",
    "outputId": "0fc7de72-07d7-451a-bd1d-d069aac1c7fd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I love tracy reese dresses, but this one is no...</td>\n",
       "      <td>2</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>First of all, this is not pullover styling. th...</td>\n",
       "      <td>2</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>I have been waiting for this sweater coat to s...</td>\n",
       "      <td>2</td>\n",
       "      <td>Sweaters</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>I ordered this 3 months ago, and it finally ca...</td>\n",
       "      <td>2</td>\n",
       "      <td>Sweaters</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>I am pregnant and i thought this would be a gr...</td>\n",
       "      <td>2</td>\n",
       "      <td>Intimates</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Review Text  Rating Class Name  Age\n",
       "5   I love tracy reese dresses, but this one is no...       2    Dresses   49\n",
       "22  First of all, this is not pullover styling. th...       2    Dresses   31\n",
       "26  I have been waiting for this sweater coat to s...       2   Sweaters   33\n",
       "33  I ordered this 3 months ago, and it finally ca...       2   Sweaters   36\n",
       "56  I am pregnant and i thought this would be a gr...       2  Intimates   33"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# negative reviews\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s7O9xIBwAq-L"
   },
   "outputs": [],
   "source": [
    "train_text1, test_text1 = train_test_split(df1['Review Text'], test_size=0.2)\n",
    "train_text2, test_text2 = train_test_split(df2['Review Text'], test_size=0.2)\n",
    "train_text3, test_text3 = train_test_split(df3['Review Text'], test_size=0.2)\n",
    "train_text1.to_frame().to_csv(r'train_text_rev1', header=None, index=None, sep=' ', mode='a')\n",
    "test_text1.to_frame().to_csv(r'test_text_rev1', header=None, index=None, sep=' ', mode='a')\n",
    "train_text2.to_frame().to_csv(r'train_text_rev2', header=None, index=None, sep=' ', mode='a')\n",
    "test_text2.to_frame().to_csv(r'test_text_rev2', header=None, index=None, sep=' ', mode='a')\n",
    "train_text3.to_frame().to_csv(r'train_text_rev3', header=None, index=None, sep=' ', mode='a')\n",
    "test_text3.to_frame().to_csv(r'test_text_rev3', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "vw4KmMiwBJjm",
    "outputId": "a2a2edcc-cfe9-49f2-8bc3-6cbf7d6d50e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/06/2020 18:05:29 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "03/06/2020 18:05:30 - INFO - filelock -   Lock 139959119375216 acquired on /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.a7ab0e5de2d8321d6d6a15b199110f2c99be72976b7d151423cb8d8c261a13b6.lock\n",
      "03/06/2020 18:05:30 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpfn6sdjdl\n",
      "Downloading: 100% 524/524 [00:00<00:00, 482kB/s]\n",
      "03/06/2020 18:05:30 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json in cache at /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.a7ab0e5de2d8321d6d6a15b199110f2c99be72976b7d151423cb8d8c261a13b6\n",
      "03/06/2020 18:05:30 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.a7ab0e5de2d8321d6d6a15b199110f2c99be72976b7d151423cb8d8c261a13b6\n",
      "03/06/2020 18:05:30 - INFO - filelock -   Lock 139959119375216 released on /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.a7ab0e5de2d8321d6d6a15b199110f2c99be72976b7d151423cb8d8c261a13b6.lock\n",
      "03/06/2020 18:05:30 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.a7ab0e5de2d8321d6d6a15b199110f2c99be72976b7d151423cb8d8c261a13b6\n",
      "03/06/2020 18:05:30 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"eos_token_ids\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "03/06/2020 18:05:30 - INFO - filelock -   Lock 139959119346992 acquired on /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b.lock\n",
      "03/06/2020 18:05:30 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpb35ixf9w\n",
      "Downloading: 100% 899k/899k [00:00<00:00, 2.80MB/s]\n",
      "03/06/2020 18:05:31 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json in cache at /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "03/06/2020 18:05:31 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "03/06/2020 18:05:31 - INFO - filelock -   Lock 139959119346992 released on /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b.lock\n",
      "03/06/2020 18:05:31 - INFO - filelock -   Lock 139959119346992 acquired on /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n",
      "03/06/2020 18:05:31 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpwcg0ta_u\n",
      "Downloading: 100% 456k/456k [00:00<00:00, 1.76MB/s]\n",
      "03/06/2020 18:05:32 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt in cache at /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "03/06/2020 18:05:32 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "03/06/2020 18:05:32 - INFO - filelock -   Lock 139959119346992 released on /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n",
      "03/06/2020 18:05:32 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "03/06/2020 18:05:32 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "03/06/2020 18:05:32 - INFO - filelock -   Lock 139959119373872 acquired on /root/.cache/torch/transformers/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e.lock\n",
      "03/06/2020 18:05:32 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpithd4oll\n",
      "Downloading: 100% 501M/501M [00:12<00:00, 38.7MB/s]\n",
      "03/06/2020 18:05:45 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin in cache at /root/.cache/torch/transformers/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
      "03/06/2020 18:05:45 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
      "03/06/2020 18:05:45 - INFO - filelock -   Lock 139959119373872 released on /root/.cache/torch/transformers/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e.lock\n",
      "03/06/2020 18:05:45 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
      "03/06/2020 18:05:50 - INFO - transformers.modeling_utils -   Weights of RobertaForMaskedLM not initialized from pretrained model: ['lm_head.decoder.bias']\n",
      "03/06/2020 18:05:59 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=True, eval_all_checkpoints=False, eval_data_file='test_text_rev1', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='roberta-base', model_type='roberta', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output_roberta_rev1', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='train_text_rev1', warmup_steps=0, weight_decay=0.0)\n",
      "03/06/2020 18:05:59 - INFO - __main__ -   Creating features from dataset file at \n",
      "03/06/2020 18:06:00 - INFO - __main__ -   Saving features into cached file roberta_cached_lm_510_train_text_rev1\n",
      "03/06/2020 18:06:00 - INFO - __main__ -   ***** Running training *****\n",
      "03/06/2020 18:06:00 - INFO - __main__ -     Num examples = 355\n",
      "03/06/2020 18:06:00 - INFO - __main__ -     Num Epochs = 1\n",
      "03/06/2020 18:06:00 - INFO - __main__ -     Instantaneous batch size per GPU = 4\n",
      "03/06/2020 18:06:00 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "03/06/2020 18:06:00 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
      "03/06/2020 18:06:00 - INFO - __main__ -     Total optimization steps = 89\n",
      "Epoch:   0% 0/1 [00:00<?, ?it/s]\n",
      "Iteration:   0% 0/89 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   1% 1/89 [00:00<00:58,  1.49it/s]\u001b[A\n",
      "Iteration:   2% 2/89 [00:00<00:49,  1.76it/s]\u001b[A\n",
      "Iteration:   3% 3/89 [00:01<00:42,  2.02it/s]\u001b[A\n",
      "Iteration:   4% 4/89 [00:01<00:37,  2.25it/s]\u001b[A\n",
      "Iteration:   6% 5/89 [00:01<00:34,  2.44it/s]\u001b[A\n",
      "Iteration:   7% 6/89 [00:02<00:31,  2.60it/s]\u001b[A\n",
      "Iteration:   8% 7/89 [00:02<00:30,  2.73it/s]\u001b[A\n",
      "Iteration:   9% 8/89 [00:02<00:28,  2.83it/s]\u001b[A\n",
      "Iteration:  10% 9/89 [00:03<00:27,  2.88it/s]\u001b[A\n",
      "Iteration:  11% 10/89 [00:03<00:27,  2.92it/s]\u001b[A\n",
      "Iteration:  12% 11/89 [00:03<00:26,  2.97it/s]\u001b[A\n",
      "Iteration:  13% 12/89 [00:04<00:25,  2.99it/s]\u001b[A\n",
      "Iteration:  15% 13/89 [00:04<00:25,  3.01it/s]\u001b[A\n",
      "Iteration:  16% 14/89 [00:04<00:24,  3.03it/s]\u001b[A\n",
      "Iteration:  17% 15/89 [00:05<00:24,  3.05it/s]\u001b[A\n",
      "Iteration:  18% 16/89 [00:05<00:23,  3.06it/s]\u001b[A\n",
      "Iteration:  19% 17/89 [00:05<00:23,  3.06it/s]\u001b[A\n",
      "Iteration:  20% 18/89 [00:06<00:23,  3.07it/s]\u001b[A\n",
      "Iteration:  21% 19/89 [00:06<00:22,  3.07it/s]\u001b[A\n",
      "Iteration:  22% 20/89 [00:06<00:22,  3.08it/s]\u001b[A\n",
      "Iteration:  24% 21/89 [00:07<00:22,  3.07it/s]\u001b[A\n",
      "Iteration:  25% 22/89 [00:07<00:21,  3.07it/s]\u001b[A\n",
      "Iteration:  26% 23/89 [00:07<00:21,  3.07it/s]\u001b[A\n",
      "Iteration:  27% 24/89 [00:08<00:21,  3.07it/s]\u001b[A\n",
      "Iteration:  28% 25/89 [00:08<00:20,  3.07it/s]\u001b[A\n",
      "Iteration:  29% 26/89 [00:08<00:20,  3.06it/s]\u001b[A\n",
      "Iteration:  30% 27/89 [00:09<00:20,  3.05it/s]\u001b[A\n",
      "Iteration:  31% 28/89 [00:09<00:19,  3.06it/s]\u001b[A\n",
      "Iteration:  33% 29/89 [00:09<00:19,  3.06it/s]\u001b[A\n",
      "Iteration:  34% 30/89 [00:10<00:19,  3.07it/s]\u001b[A\n",
      "Iteration:  35% 31/89 [00:10<00:18,  3.06it/s]\u001b[A\n",
      "Iteration:  36% 32/89 [00:10<00:18,  3.07it/s]\u001b[A\n",
      "Iteration:  37% 33/89 [00:11<00:18,  3.07it/s]\u001b[A\n",
      "Iteration:  38% 34/89 [00:11<00:17,  3.07it/s]\u001b[A\n",
      "Iteration:  39% 35/89 [00:11<00:17,  3.07it/s]\u001b[A\n",
      "Iteration:  40% 36/89 [00:12<00:17,  3.07it/s]\u001b[A\n",
      "Iteration:  42% 37/89 [00:12<00:16,  3.07it/s]\u001b[A\n",
      "Iteration:  43% 38/89 [00:12<00:16,  3.07it/s]\u001b[A\n",
      "Iteration:  44% 39/89 [00:13<00:16,  3.07it/s]\u001b[A\n",
      "Iteration:  45% 40/89 [00:13<00:15,  3.07it/s]\u001b[A\n",
      "Iteration:  46% 41/89 [00:13<00:15,  3.05it/s]\u001b[A\n",
      "Iteration:  47% 42/89 [00:14<00:15,  3.06it/s]\u001b[A\n",
      "Iteration:  48% 43/89 [00:14<00:15,  3.06it/s]\u001b[A\n",
      "Iteration:  49% 44/89 [00:14<00:14,  3.05it/s]\u001b[A\n",
      "Iteration:  51% 45/89 [00:15<00:14,  3.06it/s]\u001b[A\n",
      "Iteration:  52% 46/89 [00:15<00:14,  3.07it/s]\u001b[A\n",
      "Iteration:  53% 47/89 [00:15<00:13,  3.06it/s]\u001b[A\n",
      "Iteration:  54% 48/89 [00:16<00:13,  3.06it/s]\u001b[A\n",
      "Iteration:  55% 49/89 [00:16<00:13,  3.03it/s]\u001b[A\n",
      "Iteration:  56% 50/89 [00:16<00:12,  3.04it/s]\u001b[A\n",
      "Iteration:  57% 51/89 [00:16<00:12,  3.05it/s]\u001b[A\n",
      "Iteration:  58% 52/89 [00:17<00:12,  3.06it/s]\u001b[A\n",
      "Iteration:  60% 53/89 [00:17<00:11,  3.04it/s]\u001b[A\n",
      "Iteration:  61% 54/89 [00:17<00:11,  3.05it/s]\u001b[A\n",
      "Iteration:  62% 55/89 [00:18<00:11,  3.06it/s]\u001b[A\n",
      "Iteration:  63% 56/89 [00:18<00:10,  3.07it/s]\u001b[A\n",
      "Iteration:  64% 57/89 [00:18<00:10,  3.07it/s]\u001b[A\n",
      "Iteration:  65% 58/89 [00:19<00:10,  3.07it/s]\u001b[A\n",
      "Iteration:  66% 59/89 [00:19<00:09,  3.07it/s]\u001b[A\n",
      "Iteration:  67% 60/89 [00:19<00:09,  3.07it/s]\u001b[A\n",
      "Iteration:  69% 61/89 [00:20<00:09,  3.07it/s]\u001b[A\n",
      "Iteration:  70% 62/89 [00:20<00:08,  3.06it/s]\u001b[A\n",
      "Iteration:  71% 63/89 [00:20<00:08,  3.07it/s]\u001b[A\n",
      "Iteration:  72% 64/89 [00:21<00:08,  3.07it/s]\u001b[A\n",
      "Iteration:  73% 65/89 [00:21<00:07,  3.07it/s]\u001b[A\n",
      "Iteration:  74% 66/89 [00:21<00:07,  3.07it/s]\u001b[A\n",
      "Iteration:  75% 67/89 [00:22<00:07,  3.07it/s]\u001b[A\n",
      "Iteration:  76% 68/89 [00:22<00:06,  3.07it/s]\u001b[A\n",
      "Iteration:  78% 69/89 [00:22<00:06,  3.08it/s]\u001b[A\n",
      "Iteration:  79% 70/89 [00:23<00:06,  3.08it/s]\u001b[A\n",
      "Iteration:  80% 71/89 [00:23<00:05,  3.07it/s]\u001b[A\n",
      "Iteration:  81% 72/89 [00:23<00:05,  3.06it/s]\u001b[A\n",
      "Iteration:  82% 73/89 [00:24<00:05,  3.05it/s]\u001b[A\n",
      "Iteration:  83% 74/89 [00:24<00:04,  3.06it/s]\u001b[A\n",
      "Iteration:  84% 75/89 [00:24<00:04,  3.06it/s]\u001b[A\n",
      "Iteration:  85% 76/89 [00:25<00:04,  3.06it/s]\u001b[A\n",
      "Iteration:  87% 77/89 [00:25<00:03,  3.00it/s]\u001b[A\n",
      "Iteration:  88% 78/89 [00:25<00:03,  3.03it/s]\u001b[A\n",
      "Iteration:  89% 79/89 [00:26<00:03,  3.03it/s]\u001b[A\n",
      "Iteration:  90% 80/89 [00:26<00:02,  3.05it/s]\u001b[A\n",
      "Iteration:  91% 81/89 [00:26<00:02,  3.06it/s]\u001b[A\n",
      "Iteration:  92% 82/89 [00:27<00:02,  3.07it/s]\u001b[A\n",
      "Iteration:  93% 83/89 [00:27<00:01,  3.07it/s]\u001b[A\n",
      "Iteration:  94% 84/89 [00:27<00:01,  3.07it/s]\u001b[A\n",
      "Iteration:  96% 85/89 [00:28<00:01,  3.07it/s]\u001b[A\n",
      "Iteration:  97% 86/89 [00:28<00:00,  3.07it/s]\u001b[A\n",
      "Iteration:  98% 87/89 [00:28<00:00,  3.07it/s]\u001b[A\n",
      "Iteration:  99% 88/89 [00:29<00:00,  3.07it/s]\u001b[A\n",
      "Iteration: 100% 89/89 [00:29<00:00,  3.27it/s]\u001b[A\n",
      "Epoch: 100% 1/1 [00:29<00:00, 29.34s/it]\n",
      "03/06/2020 18:06:30 - INFO - __main__ -    global_step = 89, average loss = 1.8568371976359506\n",
      "03/06/2020 18:06:30 - INFO - __main__ -   Saving model checkpoint to output_roberta_rev1\n",
      "03/06/2020 18:06:30 - INFO - transformers.configuration_utils -   Configuration saved in output_roberta_rev1/config.json\n",
      "03/06/2020 18:06:31 - INFO - transformers.modeling_utils -   Model weights saved in output_roberta_rev1/pytorch_model.bin\n",
      "03/06/2020 18:06:31 - INFO - transformers.configuration_utils -   loading configuration file output_roberta_rev1/config.json\n",
      "03/06/2020 18:06:31 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"eos_token_ids\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "03/06/2020 18:06:31 - INFO - transformers.modeling_utils -   loading weights file output_roberta_rev1/pytorch_model.bin\n",
      "03/06/2020 18:06:36 - INFO - transformers.tokenization_utils -   Model name 'output_roberta_rev1' not found in model shortcut name list (roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector). Assuming 'output_roberta_rev1' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "03/06/2020 18:06:36 - INFO - transformers.tokenization_utils -   Didn't find file output_roberta_rev1/added_tokens.json. We won't load it.\n",
      "03/06/2020 18:06:36 - INFO - transformers.tokenization_utils -   loading file output_roberta_rev1/vocab.json\n",
      "03/06/2020 18:06:36 - INFO - transformers.tokenization_utils -   loading file output_roberta_rev1/merges.txt\n",
      "03/06/2020 18:06:36 - INFO - transformers.tokenization_utils -   loading file None\n",
      "03/06/2020 18:06:36 - INFO - transformers.tokenization_utils -   loading file output_roberta_rev1/special_tokens_map.json\n",
      "03/06/2020 18:06:36 - INFO - transformers.tokenization_utils -   loading file output_roberta_rev1/tokenizer_config.json\n",
      "03/06/2020 18:06:36 - INFO - __main__ -   Evaluate the following checkpoints: ['output_roberta_rev1']\n",
      "03/06/2020 18:06:36 - INFO - transformers.configuration_utils -   loading configuration file output_roberta_rev1/config.json\n",
      "03/06/2020 18:06:36 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"eos_token_ids\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "03/06/2020 18:06:36 - INFO - transformers.modeling_utils -   loading weights file output_roberta_rev1/pytorch_model.bin\n",
      "03/06/2020 18:06:41 - INFO - __main__ -   Creating features from dataset file at \n",
      "03/06/2020 18:06:41 - INFO - __main__ -   Saving features into cached file roberta_cached_lm_510_test_text_rev1\n",
      "03/06/2020 18:06:41 - INFO - __main__ -   ***** Running evaluation  *****\n",
      "03/06/2020 18:06:41 - INFO - __main__ -     Num examples = 88\n",
      "03/06/2020 18:06:41 - INFO - __main__ -     Batch size = 4\n",
      "Evaluating: 100% 22/22 [00:02<00:00,  9.85it/s]\n",
      "03/06/2020 18:06:44 - INFO - __main__ -   ***** Eval results  *****\n",
      "03/06/2020 18:06:44 - INFO - __main__ -     perplexity = tensor(4.9297)\n",
      "03/06/2020 18:06:47 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "03/06/2020 18:06:48 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.a7ab0e5de2d8321d6d6a15b199110f2c99be72976b7d151423cb8d8c261a13b6\n",
      "03/06/2020 18:06:48 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"eos_token_ids\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "03/06/2020 18:06:48 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "03/06/2020 18:06:48 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "03/06/2020 18:06:49 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
      "03/06/2020 18:06:54 - INFO - transformers.modeling_utils -   Weights of RobertaForMaskedLM not initialized from pretrained model: ['lm_head.decoder.bias']\n",
      "03/06/2020 18:06:57 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=True, eval_all_checkpoints=False, eval_data_file='test_text_rev2', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='roberta-base', model_type='roberta', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output_roberta_rev2', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='train_text_rev2', warmup_steps=0, weight_decay=0.0)\n",
      "03/06/2020 18:06:57 - INFO - __main__ -   Creating features from dataset file at \n",
      "03/06/2020 18:07:00 - INFO - __main__ -   Saving features into cached file roberta_cached_lm_510_train_text_rev2\n",
      "03/06/2020 18:07:00 - INFO - __main__ -   ***** Running training *****\n",
      "03/06/2020 18:07:00 - INFO - __main__ -     Num examples = 2051\n",
      "03/06/2020 18:07:00 - INFO - __main__ -     Num Epochs = 1\n",
      "03/06/2020 18:07:00 - INFO - __main__ -     Instantaneous batch size per GPU = 4\n",
      "03/06/2020 18:07:00 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "03/06/2020 18:07:00 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
      "03/06/2020 18:07:00 - INFO - __main__ -     Total optimization steps = 513\n",
      "Epoch:   0% 0/1 [00:00<?, ?it/s]\n",
      "Iteration:   0% 0/513 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0% 1/513 [00:00<03:09,  2.71it/s]\u001b[A\n",
      "Iteration:   0% 2/513 [00:00<03:01,  2.81it/s]\u001b[A\n",
      "Iteration:   1% 3/513 [00:01<02:56,  2.89it/s]\u001b[A\n",
      "Iteration:   1% 4/513 [00:01<02:52,  2.94it/s]\u001b[A\n",
      "Iteration:   1% 5/513 [00:01<02:50,  2.97it/s]\u001b[A\n",
      "Iteration:   1% 6/513 [00:01<02:48,  3.01it/s]\u001b[A\n",
      "Iteration:   1% 7/513 [00:02<02:47,  3.03it/s]\u001b[A\n",
      "Iteration:   2% 8/513 [00:02<02:45,  3.04it/s]\u001b[A\n",
      "Iteration:   2% 9/513 [00:02<02:44,  3.06it/s]\u001b[A\n",
      "Iteration:   2% 10/513 [00:03<02:45,  3.05it/s]\u001b[A\n",
      "Iteration:   2% 11/513 [00:03<02:44,  3.04it/s]\u001b[A\n",
      "Iteration:   2% 12/513 [00:03<02:43,  3.06it/s]\u001b[A\n",
      "Iteration:   3% 13/513 [00:04<02:43,  3.06it/s]\u001b[A\n",
      "Iteration:   3% 14/513 [00:04<02:42,  3.06it/s]\u001b[A\n",
      "Iteration:   3% 15/513 [00:04<02:42,  3.07it/s]\u001b[A\n",
      "Iteration:   3% 16/513 [00:05<02:42,  3.07it/s]\u001b[A\n",
      "Iteration:   3% 17/513 [00:05<02:41,  3.07it/s]\u001b[A\n",
      "Iteration:   4% 18/513 [00:05<02:41,  3.07it/s]\u001b[A\n",
      "Iteration:   4% 19/513 [00:06<02:40,  3.07it/s]\u001b[A\n",
      "Iteration:   4% 20/513 [00:06<02:40,  3.07it/s]\u001b[A\n",
      "Iteration:   4% 21/513 [00:06<02:40,  3.07it/s]\u001b[A\n",
      "Iteration:   4% 22/513 [00:07<02:39,  3.07it/s]\u001b[A\n",
      "Iteration:   4% 23/513 [00:07<02:39,  3.08it/s]\u001b[A\n",
      "Iteration:   5% 24/513 [00:07<02:38,  3.08it/s]\u001b[A\n",
      "Iteration:   5% 25/513 [00:08<02:38,  3.08it/s]\u001b[A\n",
      "Iteration:   5% 26/513 [00:08<02:38,  3.07it/s]\u001b[A\n",
      "Iteration:   5% 27/513 [00:08<02:38,  3.08it/s]\u001b[A\n",
      "Iteration:   5% 28/513 [00:09<02:37,  3.08it/s]\u001b[A\n",
      "Iteration:   6% 29/513 [00:09<02:37,  3.07it/s]\u001b[A\n",
      "Iteration:   6% 30/513 [00:09<02:37,  3.07it/s]\u001b[A\n",
      "Iteration:   6% 31/513 [00:10<02:36,  3.07it/s]\u001b[A\n",
      "Iteration:   6% 32/513 [00:10<02:36,  3.08it/s]\u001b[A\n",
      "Iteration:   6% 33/513 [00:10<02:36,  3.06it/s]\u001b[A\n",
      "Iteration:   7% 34/513 [00:11<02:36,  3.06it/s]\u001b[A\n",
      "Iteration:   7% 35/513 [00:11<02:35,  3.07it/s]\u001b[A\n",
      "Iteration:   7% 36/513 [00:11<02:35,  3.07it/s]\u001b[A\n",
      "Iteration:   7% 37/513 [00:12<02:35,  3.06it/s]\u001b[A\n",
      "Iteration:   7% 38/513 [00:12<02:34,  3.07it/s]\u001b[A\n",
      "Iteration:   8% 39/513 [00:12<02:34,  3.07it/s]\u001b[A\n",
      "Iteration:   8% 40/513 [00:13<02:33,  3.07it/s]\u001b[A\n",
      "Iteration:   8% 41/513 [00:13<02:33,  3.07it/s]\u001b[A\n",
      "Iteration:   8% 42/513 [00:13<02:33,  3.07it/s]\u001b[A\n",
      "Iteration:   8% 43/513 [00:14<02:32,  3.07it/s]\u001b[A\n",
      "Iteration:   9% 44/513 [00:14<02:32,  3.07it/s]\u001b[A\n",
      "Iteration:   9% 45/513 [00:14<02:32,  3.08it/s]\u001b[A\n",
      "Iteration:   9% 46/513 [00:15<02:31,  3.08it/s]\u001b[A\n",
      "Iteration:   9% 47/513 [00:15<02:31,  3.08it/s]\u001b[A\n",
      "Iteration:   9% 48/513 [00:15<02:31,  3.08it/s]\u001b[A\n",
      "Iteration:  10% 49/513 [00:15<02:30,  3.08it/s]\u001b[A\n",
      "Iteration:  10% 50/513 [00:16<02:30,  3.08it/s]\u001b[A\n",
      "Iteration:  10% 51/513 [00:16<02:30,  3.07it/s]\u001b[A\n",
      "Iteration:  10% 52/513 [00:16<02:30,  3.07it/s]\u001b[A\n",
      "Iteration:  10% 53/513 [00:17<02:29,  3.07it/s]\u001b[A\n",
      "Iteration:  11% 54/513 [00:17<02:29,  3.08it/s]\u001b[A\n",
      "Iteration:  11% 55/513 [00:17<02:29,  3.06it/s]\u001b[A\n",
      "Iteration:  11% 56/513 [00:18<02:28,  3.07it/s]\u001b[A\n",
      "Iteration:  11% 57/513 [00:18<02:28,  3.07it/s]\u001b[A\n",
      "Iteration:  11% 58/513 [00:18<02:28,  3.07it/s]\u001b[A\n",
      "Iteration:  12% 59/513 [00:19<02:27,  3.08it/s]\u001b[A\n",
      "Iteration:  12% 60/513 [00:19<02:27,  3.07it/s]\u001b[A\n",
      "Iteration:  12% 61/513 [00:19<02:27,  3.06it/s]\u001b[A\n",
      "Iteration:  12% 62/513 [00:20<02:26,  3.07it/s]\u001b[A\n",
      "Iteration:  12% 63/513 [00:20<02:26,  3.07it/s]\u001b[A\n",
      "Iteration:  12% 64/513 [00:20<02:26,  3.07it/s]\u001b[A\n",
      "Iteration:  13% 65/513 [00:21<02:26,  3.05it/s]\u001b[A\n",
      "Iteration:  13% 66/513 [00:21<02:26,  3.06it/s]\u001b[A\n",
      "Iteration:  13% 67/513 [00:21<02:25,  3.07it/s]\u001b[A\n",
      "Iteration:  13% 68/513 [00:22<02:24,  3.07it/s]\u001b[A\n",
      "Iteration:  13% 69/513 [00:22<02:24,  3.07it/s]\u001b[A\n",
      "Iteration:  14% 70/513 [00:22<02:24,  3.07it/s]\u001b[A\n",
      "Iteration:  14% 71/513 [00:23<02:23,  3.07it/s]\u001b[A\n",
      "Iteration:  14% 72/513 [00:23<02:23,  3.08it/s]\u001b[A\n",
      "Iteration:  14% 73/513 [00:23<02:23,  3.07it/s]\u001b[A\n",
      "Iteration:  14% 74/513 [00:24<02:23,  3.07it/s]\u001b[A\n",
      "Iteration:  15% 75/513 [00:24<02:22,  3.07it/s]\u001b[A\n",
      "Iteration:  15% 76/513 [00:24<02:22,  3.07it/s]\u001b[A\n",
      "Iteration:  15% 77/513 [00:25<02:23,  3.04it/s]\u001b[A\n",
      "Iteration:  15% 78/513 [00:25<02:22,  3.05it/s]\u001b[A\n",
      "Iteration:  15% 79/513 [00:25<02:22,  3.05it/s]\u001b[A\n",
      "Iteration:  16% 80/513 [00:26<02:21,  3.06it/s]\u001b[A\n",
      "Iteration:  16% 81/513 [00:26<02:20,  3.06it/s]\u001b[A\n",
      "Iteration:  16% 82/513 [00:26<02:20,  3.07it/s]\u001b[A\n",
      "Iteration:  16% 83/513 [00:27<02:20,  3.07it/s]\u001b[A\n",
      "Iteration:  16% 84/513 [00:27<02:19,  3.06it/s]\u001b[A\n",
      "Iteration:  17% 85/513 [00:27<02:19,  3.07it/s]\u001b[A\n",
      "Iteration:  17% 86/513 [00:28<02:18,  3.07it/s]\u001b[A\n",
      "Iteration:  17% 87/513 [00:28<02:18,  3.08it/s]\u001b[A\n",
      "Iteration:  17% 88/513 [00:28<02:18,  3.08it/s]\u001b[A\n",
      "Iteration:  17% 89/513 [00:29<02:18,  3.07it/s]\u001b[A\n",
      "Iteration:  18% 90/513 [00:29<02:17,  3.07it/s]\u001b[A\n",
      "Iteration:  18% 91/513 [00:29<02:17,  3.08it/s]\u001b[A\n",
      "Iteration:  18% 92/513 [00:30<02:16,  3.08it/s]\u001b[A\n",
      "Iteration:  18% 93/513 [00:30<02:16,  3.07it/s]\u001b[A\n",
      "Iteration:  18% 94/513 [00:30<02:16,  3.07it/s]\u001b[A\n",
      "Iteration:  19% 95/513 [00:30<02:16,  3.07it/s]\u001b[A\n",
      "Iteration:  19% 96/513 [00:31<02:15,  3.07it/s]\u001b[A\n",
      "Iteration:  19% 97/513 [00:31<02:15,  3.07it/s]\u001b[A\n",
      "Iteration:  19% 98/513 [00:31<02:15,  3.06it/s]\u001b[A\n",
      "Iteration:  19% 99/513 [00:32<02:15,  3.05it/s]\u001b[A\n",
      "Iteration:  19% 100/513 [00:32<02:15,  3.06it/s]\u001b[A\n",
      "Iteration:  20% 101/513 [00:32<02:14,  3.07it/s]\u001b[A\n",
      "Iteration:  20% 102/513 [00:33<02:14,  3.05it/s]\u001b[A\n",
      "Iteration:  20% 103/513 [00:33<02:13,  3.06it/s]\u001b[A\n",
      "Iteration:  20% 104/513 [00:33<02:13,  3.07it/s]\u001b[A\n",
      "Iteration:  20% 105/513 [00:34<02:12,  3.07it/s]\u001b[A\n",
      "Iteration:  21% 106/513 [00:34<02:12,  3.07it/s]\u001b[A\n",
      "Iteration:  21% 107/513 [00:34<02:12,  3.07it/s]\u001b[A\n",
      "Iteration:  21% 108/513 [00:35<02:11,  3.07it/s]\u001b[A\n",
      "Iteration:  21% 109/513 [00:35<02:11,  3.07it/s]\u001b[A\n",
      "Iteration:  21% 110/513 [00:35<02:11,  3.07it/s]\u001b[A\n",
      "Iteration:  22% 111/513 [00:36<02:11,  3.06it/s]\u001b[A\n",
      "Iteration:  22% 112/513 [00:36<02:10,  3.06it/s]\u001b[A\n",
      "Iteration:  22% 113/513 [00:36<02:10,  3.07it/s]\u001b[A\n",
      "Iteration:  22% 114/513 [00:37<02:09,  3.07it/s]\u001b[A\n",
      "Iteration:  22% 115/513 [00:37<02:09,  3.07it/s]\u001b[A\n",
      "Iteration:  23% 116/513 [00:37<02:09,  3.07it/s]\u001b[A\n",
      "Iteration:  23% 117/513 [00:38<02:09,  3.06it/s]\u001b[A\n",
      "Iteration:  23% 118/513 [00:38<02:08,  3.07it/s]\u001b[A\n",
      "Iteration:  23% 119/513 [00:38<02:08,  3.07it/s]\u001b[A\n",
      "Iteration:  23% 120/513 [00:39<02:08,  3.05it/s]\u001b[A\n",
      "Iteration:  24% 121/513 [00:39<02:08,  3.05it/s]\u001b[A\n",
      "Iteration:  24% 122/513 [00:39<02:07,  3.06it/s]\u001b[A\n",
      "Iteration:  24% 123/513 [00:40<02:07,  3.06it/s]\u001b[A\n",
      "Iteration:  24% 124/513 [00:40<02:06,  3.07it/s]\u001b[A\n",
      "Iteration:  24% 125/513 [00:40<02:06,  3.06it/s]\u001b[A\n",
      "Iteration:  25% 126/513 [00:41<02:06,  3.07it/s]\u001b[A\n",
      "Iteration:  25% 127/513 [00:41<02:05,  3.07it/s]\u001b[A\n",
      "Iteration:  25% 128/513 [00:41<02:05,  3.08it/s]\u001b[A\n",
      "Iteration:  25% 129/513 [00:42<02:04,  3.08it/s]\u001b[A\n",
      "Iteration:  25% 130/513 [00:42<02:05,  3.06it/s]\u001b[A\n",
      "Iteration:  26% 131/513 [00:42<02:04,  3.06it/s]\u001b[A\n",
      "Iteration:  26% 132/513 [00:43<02:04,  3.07it/s]\u001b[A\n",
      "Iteration:  26% 133/513 [00:43<02:03,  3.07it/s]\u001b[A\n",
      "Iteration:  26% 134/513 [00:43<02:03,  3.07it/s]\u001b[A\n",
      "Iteration:  26% 135/513 [00:44<02:03,  3.07it/s]\u001b[A\n",
      "Iteration:  27% 136/513 [00:44<02:02,  3.07it/s]\u001b[A\n",
      "Iteration:  27% 137/513 [00:44<02:02,  3.07it/s]\u001b[A\n",
      "Iteration:  27% 138/513 [00:45<02:01,  3.07it/s]\u001b[A\n",
      "Iteration:  27% 139/513 [00:45<02:01,  3.07it/s]\u001b[A\n",
      "Iteration:  27% 140/513 [00:45<02:01,  3.08it/s]\u001b[A\n",
      "Iteration:  27% 141/513 [00:45<02:00,  3.08it/s]\u001b[A\n",
      "Iteration:  28% 142/513 [00:46<02:01,  3.07it/s]\u001b[A\n",
      "Iteration:  28% 143/513 [00:46<02:01,  3.05it/s]\u001b[A\n",
      "Iteration:  28% 144/513 [00:46<02:00,  3.05it/s]\u001b[A\n",
      "Iteration:  28% 145/513 [00:47<02:00,  3.06it/s]\u001b[A\n",
      "Iteration:  28% 146/513 [00:47<01:59,  3.06it/s]\u001b[A\n",
      "Iteration:  29% 147/513 [00:47<01:59,  3.07it/s]\u001b[A\n",
      "Iteration:  29% 148/513 [00:48<01:58,  3.07it/s]\u001b[A\n",
      "Iteration:  29% 149/513 [00:48<01:58,  3.07it/s]\u001b[A\n",
      "Iteration:  29% 150/513 [00:48<01:58,  3.07it/s]\u001b[A\n",
      "Iteration:  29% 151/513 [00:49<01:57,  3.07it/s]\u001b[A\n",
      "Iteration:  30% 152/513 [00:49<01:57,  3.08it/s]\u001b[A\n",
      "Iteration:  30% 153/513 [00:49<01:57,  3.08it/s]\u001b[A\n",
      "Iteration:  30% 154/513 [00:50<01:56,  3.07it/s]\u001b[A\n",
      "Iteration:  30% 155/513 [00:50<01:56,  3.07it/s]\u001b[A\n",
      "Iteration:  30% 156/513 [00:50<01:56,  3.08it/s]\u001b[A\n",
      "Iteration:  31% 157/513 [00:51<01:55,  3.08it/s]\u001b[A\n",
      "Iteration:  31% 158/513 [00:51<01:55,  3.08it/s]\u001b[A\n",
      "Iteration:  31% 159/513 [00:51<01:55,  3.07it/s]\u001b[A\n",
      "Iteration:  31% 160/513 [00:52<01:54,  3.07it/s]\u001b[A\n",
      "Iteration:  31% 161/513 [00:52<01:54,  3.07it/s]\u001b[A\n",
      "Iteration:  32% 162/513 [00:52<01:54,  3.08it/s]\u001b[A\n",
      "Iteration:  32% 163/513 [00:53<01:53,  3.08it/s]\u001b[A\n",
      "Iteration:  32% 164/513 [00:53<01:53,  3.06it/s]\u001b[A\n",
      "Iteration:  32% 165/513 [00:53<01:53,  3.06it/s]\u001b[A\n",
      "Iteration:  32% 166/513 [00:54<01:53,  3.07it/s]\u001b[A\n",
      "Iteration:  33% 167/513 [00:54<01:52,  3.07it/s]\u001b[A\n",
      "Iteration:  33% 168/513 [00:54<01:52,  3.07it/s]\u001b[A\n",
      "Iteration:  33% 169/513 [00:55<01:52,  3.07it/s]\u001b[A\n",
      "Iteration:  33% 170/513 [00:55<01:51,  3.07it/s]\u001b[A\n",
      "Iteration:  33% 171/513 [00:55<01:51,  3.08it/s]\u001b[A\n",
      "Iteration:  34% 172/513 [00:56<01:51,  3.06it/s]\u001b[A\n",
      "Iteration:  34% 173/513 [00:56<01:50,  3.07it/s]\u001b[A\n",
      "Iteration:  34% 174/513 [00:56<01:50,  3.07it/s]\u001b[A\n",
      "Iteration:  34% 175/513 [00:57<01:49,  3.07it/s]\u001b[A\n",
      "Iteration:  34% 176/513 [00:57<01:49,  3.07it/s]\u001b[A\n",
      "Iteration:  35% 177/513 [00:57<01:49,  3.06it/s]\u001b[A\n",
      "Iteration:  35% 178/513 [00:58<01:49,  3.07it/s]\u001b[A\n",
      "Iteration:  35% 179/513 [00:58<01:48,  3.07it/s]\u001b[A\n",
      "Iteration:  35% 180/513 [00:58<01:48,  3.07it/s]\u001b[A\n",
      "Iteration:  35% 181/513 [00:59<01:48,  3.07it/s]\u001b[A\n",
      "Iteration:  35% 182/513 [00:59<01:47,  3.07it/s]\u001b[A\n",
      "Iteration:  36% 183/513 [00:59<01:47,  3.07it/s]\u001b[A\n",
      "Iteration:  36% 184/513 [00:59<01:47,  3.07it/s]\u001b[A\n",
      "Iteration:  36% 185/513 [01:00<01:46,  3.07it/s]\u001b[A\n",
      "Iteration:  36% 186/513 [01:00<01:46,  3.07it/s]\u001b[A\n",
      "Iteration:  36% 187/513 [01:00<01:47,  3.05it/s]\u001b[A\n",
      "Iteration:  37% 188/513 [01:01<01:46,  3.06it/s]\u001b[A\n",
      "Iteration:  37% 189/513 [01:01<01:45,  3.06it/s]\u001b[A\n",
      "Iteration:  37% 190/513 [01:01<01:45,  3.06it/s]\u001b[A\n",
      "Iteration:  37% 191/513 [01:02<01:44,  3.07it/s]\u001b[A\n",
      "Iteration:  37% 192/513 [01:02<01:45,  3.05it/s]\u001b[A\n",
      "Iteration:  38% 193/513 [01:02<01:45,  3.04it/s]\u001b[A\n",
      "Iteration:  38% 194/513 [01:03<01:44,  3.06it/s]\u001b[A\n",
      "Iteration:  38% 195/513 [01:03<01:43,  3.06it/s]\u001b[A\n",
      "Iteration:  38% 196/513 [01:03<01:43,  3.06it/s]\u001b[A\n",
      "Iteration:  38% 197/513 [01:04<01:42,  3.07it/s]\u001b[A\n",
      "Iteration:  39% 198/513 [01:04<01:42,  3.07it/s]\u001b[A\n",
      "Iteration:  39% 199/513 [01:04<01:42,  3.07it/s]\u001b[A\n",
      "Iteration:  39% 200/513 [01:05<01:42,  3.05it/s]\u001b[A\n",
      "Iteration:  39% 201/513 [01:05<01:41,  3.06it/s]\u001b[A\n",
      "Iteration:  39% 202/513 [01:05<01:41,  3.06it/s]\u001b[A\n",
      "Iteration:  40% 203/513 [01:06<01:40,  3.07it/s]\u001b[A\n",
      "Iteration:  40% 204/513 [01:06<01:40,  3.07it/s]\u001b[A\n",
      "Iteration:  40% 205/513 [01:06<01:40,  3.07it/s]\u001b[A\n",
      "Iteration:  40% 206/513 [01:07<01:39,  3.08it/s]\u001b[A\n",
      "Iteration:  40% 207/513 [01:07<01:39,  3.08it/s]\u001b[A\n",
      "Iteration:  41% 208/513 [01:07<01:39,  3.06it/s]\u001b[A\n",
      "Iteration:  41% 209/513 [01:08<01:39,  3.06it/s]\u001b[A\n",
      "Iteration:  41% 210/513 [01:08<01:38,  3.07it/s]\u001b[A\n",
      "Iteration:  41% 211/513 [01:08<01:38,  3.07it/s]\u001b[A\n",
      "Iteration:  41% 212/513 [01:09<01:37,  3.08it/s]\u001b[A\n",
      "Iteration:  42% 213/513 [01:09<01:37,  3.07it/s]\u001b[A\n",
      "Iteration:  42% 214/513 [01:09<01:37,  3.07it/s]\u001b[A\n",
      "Iteration:  42% 215/513 [01:10<01:36,  3.07it/s]\u001b[A\n",
      "Iteration:  42% 216/513 [01:10<01:36,  3.07it/s]\u001b[A\n",
      "Iteration:  42% 217/513 [01:10<01:36,  3.08it/s]\u001b[A\n",
      "Iteration:  42% 218/513 [01:11<01:36,  3.06it/s]\u001b[A\n",
      "Iteration:  43% 219/513 [01:11<01:35,  3.07it/s]\u001b[A\n",
      "Iteration:  43% 220/513 [01:11<01:35,  3.07it/s]\u001b[A\n",
      "Iteration:  43% 221/513 [01:12<01:34,  3.08it/s]\u001b[A\n",
      "Iteration:  43% 222/513 [01:12<01:35,  3.06it/s]\u001b[A\n",
      "Iteration:  43% 223/513 [01:12<01:34,  3.07it/s]\u001b[A\n",
      "Iteration:  44% 224/513 [01:13<01:34,  3.07it/s]\u001b[A\n",
      "Iteration:  44% 225/513 [01:13<01:33,  3.07it/s]\u001b[A\n",
      "Iteration:  44% 226/513 [01:13<01:33,  3.07it/s]\u001b[A\n",
      "Iteration:  44% 227/513 [01:14<01:33,  3.06it/s]\u001b[A\n",
      "Iteration:  44% 228/513 [01:14<01:33,  3.06it/s]\u001b[A\n",
      "Iteration:  45% 229/513 [01:14<01:32,  3.07it/s]\u001b[A\n",
      "Iteration:  45% 230/513 [01:14<01:32,  3.06it/s]\u001b[A\n",
      "Iteration:  45% 231/513 [01:15<01:32,  3.06it/s]\u001b[A\n",
      "Iteration:  45% 232/513 [01:15<01:31,  3.06it/s]\u001b[A\n",
      "Iteration:  45% 233/513 [01:15<01:31,  3.07it/s]\u001b[A\n",
      "Iteration:  46% 234/513 [01:16<01:30,  3.07it/s]\u001b[A\n",
      "Iteration:  46% 235/513 [01:16<01:30,  3.07it/s]\u001b[A\n",
      "Iteration:  46% 236/513 [01:16<01:30,  3.06it/s]\u001b[A\n",
      "Iteration:  46% 237/513 [01:17<01:30,  3.07it/s]\u001b[A\n",
      "Iteration:  46% 238/513 [01:17<01:29,  3.07it/s]\u001b[A\n",
      "Iteration:  47% 239/513 [01:17<01:29,  3.07it/s]\u001b[A\n",
      "Iteration:  47% 240/513 [01:18<01:29,  3.07it/s]\u001b[A\n",
      "Iteration:  47% 241/513 [01:18<01:28,  3.07it/s]\u001b[A\n",
      "Iteration:  47% 242/513 [01:18<01:28,  3.07it/s]\u001b[A\n",
      "Iteration:  47% 243/513 [01:19<01:27,  3.07it/s]\u001b[A\n",
      "Iteration:  48% 244/513 [01:19<01:27,  3.08it/s]\u001b[A\n",
      "Iteration:  48% 245/513 [01:19<01:27,  3.06it/s]\u001b[A\n",
      "Iteration:  48% 246/513 [01:20<01:27,  3.07it/s]\u001b[A\n",
      "Iteration:  48% 247/513 [01:20<01:26,  3.07it/s]\u001b[A\n",
      "Iteration:  48% 248/513 [01:20<01:26,  3.07it/s]\u001b[A\n",
      "Iteration:  49% 249/513 [01:21<01:25,  3.07it/s]\u001b[A\n",
      "Iteration:  49% 250/513 [01:21<01:25,  3.07it/s]\u001b[A\n",
      "Iteration:  49% 251/513 [01:21<01:25,  3.07it/s]\u001b[A\n",
      "Iteration:  49% 252/513 [01:22<01:25,  3.06it/s]\u001b[A\n",
      "Iteration:  49% 253/513 [01:22<01:25,  3.06it/s]\u001b[A\n",
      "Iteration:  50% 254/513 [01:22<01:24,  3.05it/s]\u001b[A\n",
      "Iteration:  50% 255/513 [01:23<01:24,  3.06it/s]\u001b[A\n",
      "Iteration:  50% 256/513 [01:23<01:23,  3.06it/s]\u001b[A\n",
      "Iteration:  50% 257/513 [01:23<01:23,  3.07it/s]\u001b[A\n",
      "Iteration:  50% 258/513 [01:24<01:23,  3.07it/s]\u001b[A\n",
      "Iteration:  50% 259/513 [01:24<01:23,  3.06it/s]\u001b[A\n",
      "Iteration:  51% 260/513 [01:24<01:22,  3.07it/s]\u001b[A\n",
      "Iteration:  51% 261/513 [01:25<01:22,  3.07it/s]\u001b[A\n",
      "Iteration:  51% 262/513 [01:25<01:21,  3.07it/s]\u001b[A\n",
      "Iteration:  51% 263/513 [01:25<01:21,  3.06it/s]\u001b[A\n",
      "Iteration:  51% 264/513 [01:26<01:21,  3.06it/s]\u001b[A\n",
      "Iteration:  52% 265/513 [01:26<01:20,  3.07it/s]\u001b[A\n",
      "Iteration:  52% 266/513 [01:26<01:20,  3.07it/s]\u001b[A\n",
      "Iteration:  52% 267/513 [01:27<01:19,  3.08it/s]\u001b[A\n",
      "Iteration:  52% 268/513 [01:27<01:20,  3.06it/s]\u001b[A\n",
      "Iteration:  52% 269/513 [01:27<01:19,  3.07it/s]\u001b[A\n",
      "Iteration:  53% 270/513 [01:28<01:19,  3.07it/s]\u001b[A\n",
      "Iteration:  53% 271/513 [01:28<01:18,  3.08it/s]\u001b[A\n",
      "Iteration:  53% 272/513 [01:28<01:18,  3.07it/s]\u001b[A\n",
      "Iteration:  53% 273/513 [01:29<01:18,  3.07it/s]\u001b[A\n",
      "Iteration:  53% 274/513 [01:29<01:17,  3.07it/s]\u001b[A\n",
      "Iteration:  54% 275/513 [01:29<01:17,  3.07it/s]\u001b[A\n",
      "Iteration:  54% 276/513 [01:29<01:17,  3.07it/s]\u001b[A\n",
      "Iteration:  54% 277/513 [01:30<01:16,  3.07it/s]\u001b[A\n",
      "Iteration:  54% 278/513 [01:30<01:16,  3.06it/s]\u001b[A\n",
      "Iteration:  54% 279/513 [01:30<01:16,  3.07it/s]\u001b[A\n",
      "Iteration:  55% 280/513 [01:31<01:15,  3.07it/s]\u001b[A\n",
      "Iteration:  55% 281/513 [01:31<01:15,  3.06it/s]\u001b[A\n",
      "Iteration:  55% 282/513 [01:31<01:15,  3.07it/s]\u001b[A\n",
      "Iteration:  55% 283/513 [01:32<01:14,  3.07it/s]\u001b[A\n",
      "Iteration:  55% 284/513 [01:32<01:14,  3.07it/s]\u001b[A\n",
      "Iteration:  56% 285/513 [01:32<01:14,  3.08it/s]\u001b[A\n",
      "Iteration:  56% 286/513 [01:33<01:14,  3.07it/s]\u001b[A\n",
      "Iteration:  56% 287/513 [01:33<01:13,  3.07it/s]\u001b[A\n",
      "Iteration:  56% 288/513 [01:33<01:13,  3.07it/s]\u001b[A\n",
      "Iteration:  56% 289/513 [01:34<01:12,  3.07it/s]\u001b[A\n",
      "Iteration:  57% 290/513 [01:34<01:12,  3.07it/s]\u001b[A\n",
      "Iteration:  57% 291/513 [01:34<01:12,  3.07it/s]\u001b[A\n",
      "Iteration:  57% 292/513 [01:35<01:11,  3.08it/s]\u001b[A\n",
      "Iteration:  57% 293/513 [01:35<01:11,  3.08it/s]\u001b[A\n",
      "Iteration:  57% 294/513 [01:35<01:11,  3.08it/s]\u001b[A\n",
      "Iteration:  58% 295/513 [01:36<01:10,  3.07it/s]\u001b[A\n",
      "Iteration:  58% 296/513 [01:36<01:11,  3.04it/s]\u001b[A\n",
      "Iteration:  58% 297/513 [01:36<01:10,  3.05it/s]\u001b[A\n",
      "Iteration:  58% 298/513 [01:37<01:10,  3.06it/s]\u001b[A\n",
      "Iteration:  58% 299/513 [01:37<01:09,  3.07it/s]\u001b[A\n",
      "Iteration:  58% 300/513 [01:37<01:09,  3.06it/s]\u001b[A\n",
      "Iteration:  59% 301/513 [01:38<01:09,  3.07it/s]\u001b[A\n",
      "Iteration:  59% 302/513 [01:38<01:08,  3.07it/s]\u001b[A\n",
      "Iteration:  59% 303/513 [01:38<01:08,  3.07it/s]\u001b[A\n",
      "Iteration:  59% 304/513 [01:39<01:08,  3.07it/s]\u001b[A\n",
      "Iteration:  59% 305/513 [01:39<01:07,  3.07it/s]\u001b[A\n",
      "Iteration:  60% 306/513 [01:39<01:07,  3.07it/s]\u001b[A\n",
      "Iteration:  60% 307/513 [01:40<01:07,  3.07it/s]\u001b[A\n",
      "Iteration:  60% 308/513 [01:40<01:06,  3.08it/s]\u001b[A\n",
      "Iteration:  60% 309/513 [01:40<01:06,  3.07it/s]\u001b[A\n",
      "Iteration:  60% 310/513 [01:41<01:06,  3.07it/s]\u001b[A\n",
      "Iteration:  61% 311/513 [01:41<01:05,  3.08it/s]\u001b[A\n",
      "Iteration:  61% 312/513 [01:41<01:05,  3.08it/s]\u001b[A\n",
      "Iteration:  61% 313/513 [01:42<01:05,  3.07it/s]\u001b[A\n",
      "Iteration:  61% 314/513 [01:42<01:04,  3.06it/s]\u001b[A\n",
      "Iteration:  61% 315/513 [01:42<01:04,  3.07it/s]\u001b[A\n",
      "Iteration:  62% 316/513 [01:43<01:04,  3.07it/s]\u001b[A\n",
      "Iteration:  62% 317/513 [01:43<01:03,  3.07it/s]\u001b[A\n",
      "Iteration:  62% 318/513 [01:43<01:03,  3.06it/s]\u001b[A\n",
      "Iteration:  62% 319/513 [01:44<01:03,  3.07it/s]\u001b[A\n",
      "Iteration:  62% 320/513 [01:44<01:02,  3.07it/s]\u001b[A\n",
      "Iteration:  63% 321/513 [01:44<01:02,  3.07it/s]\u001b[A\n",
      "Iteration:  63% 322/513 [01:44<01:02,  3.06it/s]\u001b[A\n",
      "Iteration:  63% 323/513 [01:45<01:01,  3.07it/s]\u001b[A\n",
      "Iteration:  63% 324/513 [01:45<01:01,  3.07it/s]\u001b[A\n",
      "Iteration:  63% 325/513 [01:45<01:01,  3.07it/s]\u001b[A\n",
      "Iteration:  64% 326/513 [01:46<01:00,  3.07it/s]\u001b[A\n",
      "Iteration:  64% 327/513 [01:46<01:00,  3.06it/s]\u001b[A\n",
      "Iteration:  64% 328/513 [01:46<01:00,  3.06it/s]\u001b[A\n",
      "Iteration:  64% 329/513 [01:47<00:59,  3.07it/s]\u001b[A\n",
      "Iteration:  64% 330/513 [01:47<00:59,  3.07it/s]\u001b[A\n",
      "Iteration:  65% 331/513 [01:47<00:59,  3.06it/s]\u001b[A\n",
      "Iteration:  65% 332/513 [01:48<00:58,  3.07it/s]\u001b[A\n",
      "Iteration:  65% 333/513 [01:48<00:58,  3.07it/s]\u001b[A\n",
      "Iteration:  65% 334/513 [01:48<00:58,  3.07it/s]\u001b[A\n",
      "Iteration:  65% 335/513 [01:49<00:58,  3.06it/s]\u001b[A\n",
      "Iteration:  65% 336/513 [01:49<00:57,  3.07it/s]\u001b[A\n",
      "Iteration:  66% 337/513 [01:49<00:57,  3.08it/s]\u001b[A\n",
      "Iteration:  66% 338/513 [01:50<00:56,  3.08it/s]\u001b[A\n",
      "Iteration:  66% 339/513 [01:50<00:56,  3.08it/s]\u001b[A\n",
      "Iteration:  66% 340/513 [01:50<00:56,  3.07it/s]\u001b[A\n",
      "Iteration:  66% 341/513 [01:51<00:56,  3.07it/s]\u001b[A\n",
      "Iteration:  67% 342/513 [01:51<00:55,  3.07it/s]\u001b[A\n",
      "Iteration:  67% 343/513 [01:51<00:55,  3.08it/s]\u001b[A\n",
      "Iteration:  67% 344/513 [01:52<00:55,  3.07it/s]\u001b[A\n",
      "Iteration:  67% 345/513 [01:52<00:54,  3.07it/s]\u001b[A\n",
      "Iteration:  67% 346/513 [01:52<00:54,  3.07it/s]\u001b[A\n",
      "Iteration:  68% 347/513 [01:53<00:53,  3.08it/s]\u001b[A\n",
      "Iteration:  68% 348/513 [01:53<00:53,  3.08it/s]\u001b[A\n",
      "Iteration:  68% 349/513 [01:53<00:53,  3.08it/s]\u001b[A\n",
      "Iteration:  68% 350/513 [01:54<00:53,  3.06it/s]\u001b[A\n",
      "Iteration:  68% 351/513 [01:54<00:52,  3.07it/s]\u001b[A\n",
      "Iteration:  69% 352/513 [01:54<00:52,  3.07it/s]\u001b[A\n",
      "Iteration:  69% 353/513 [01:55<00:52,  3.07it/s]\u001b[A\n",
      "Iteration:  69% 354/513 [01:55<00:51,  3.06it/s]\u001b[A\n",
      "Iteration:  69% 355/513 [01:55<00:51,  3.06it/s]\u001b[A\n",
      "Iteration:  69% 356/513 [01:56<00:51,  3.07it/s]\u001b[A\n",
      "Iteration:  70% 357/513 [01:56<00:50,  3.06it/s]\u001b[A\n",
      "Iteration:  70% 358/513 [01:56<00:50,  3.07it/s]\u001b[A\n",
      "Iteration:  70% 359/513 [01:57<00:50,  3.07it/s]\u001b[A\n",
      "Iteration:  70% 360/513 [01:57<00:49,  3.07it/s]\u001b[A\n",
      "Iteration:  70% 361/513 [01:57<00:49,  3.07it/s]\u001b[A\n",
      "Iteration:  71% 362/513 [01:58<00:49,  3.06it/s]\u001b[A\n",
      "Iteration:  71% 363/513 [01:58<00:48,  3.07it/s]\u001b[A\n",
      "Iteration:  71% 364/513 [01:58<00:48,  3.06it/s]\u001b[A\n",
      "Iteration:  71% 365/513 [01:58<00:48,  3.07it/s]\u001b[A\n",
      "Iteration:  71% 366/513 [01:59<00:48,  3.06it/s]\u001b[A\n",
      "Iteration:  72% 367/513 [01:59<00:47,  3.07it/s]\u001b[A\n",
      "Iteration:  72% 368/513 [01:59<00:47,  3.06it/s]\u001b[A\n",
      "Iteration:  72% 369/513 [02:00<00:46,  3.06it/s]\u001b[A\n",
      "Iteration:  72% 370/513 [02:00<00:46,  3.07it/s]\u001b[A\n",
      "Iteration:  72% 371/513 [02:00<00:46,  3.07it/s]\u001b[A\n",
      "Iteration:  73% 372/513 [02:01<00:45,  3.07it/s]\u001b[A\n",
      "Iteration:  73% 373/513 [02:01<00:45,  3.07it/s]\u001b[A\n",
      "Iteration:  73% 374/513 [02:01<00:45,  3.07it/s]\u001b[A\n",
      "Iteration:  73% 375/513 [02:02<00:44,  3.07it/s]\u001b[A\n",
      "Iteration:  73% 376/513 [02:02<00:44,  3.08it/s]\u001b[A\n",
      "Iteration:  73% 377/513 [02:02<00:44,  3.07it/s]\u001b[A\n",
      "Iteration:  74% 378/513 [02:03<00:43,  3.07it/s]\u001b[A\n",
      "Iteration:  74% 379/513 [02:03<00:43,  3.07it/s]\u001b[A\n",
      "Iteration:  74% 380/513 [02:03<00:43,  3.08it/s]\u001b[A\n",
      "Iteration:  74% 381/513 [02:04<00:42,  3.08it/s]\u001b[A\n",
      "Iteration:  74% 382/513 [02:04<00:42,  3.07it/s]\u001b[A\n",
      "Iteration:  75% 383/513 [02:04<00:42,  3.07it/s]\u001b[A\n",
      "Iteration:  75% 384/513 [02:05<00:42,  3.06it/s]\u001b[A\n",
      "Iteration:  75% 385/513 [02:05<00:41,  3.07it/s]\u001b[A\n",
      "Iteration:  75% 386/513 [02:05<00:41,  3.07it/s]\u001b[A\n",
      "Iteration:  75% 387/513 [02:06<00:41,  3.07it/s]\u001b[A\n",
      "Iteration:  76% 388/513 [02:06<00:40,  3.06it/s]\u001b[A\n",
      "Iteration:  76% 389/513 [02:06<00:40,  3.07it/s]\u001b[A\n",
      "Iteration:  76% 390/513 [02:07<00:40,  3.07it/s]\u001b[A\n",
      "Iteration:  76% 391/513 [02:07<00:39,  3.06it/s]\u001b[A\n",
      "Iteration:  76% 392/513 [02:07<00:39,  3.07it/s]\u001b[A\n",
      "Iteration:  77% 393/513 [02:08<00:39,  3.07it/s]\u001b[A\n",
      "Iteration:  77% 394/513 [02:08<00:38,  3.07it/s]\u001b[A\n",
      "Iteration:  77% 395/513 [02:08<00:38,  3.07it/s]\u001b[A\n",
      "Iteration:  77% 396/513 [02:09<00:38,  3.07it/s]\u001b[A\n",
      "Iteration:  77% 397/513 [02:09<00:37,  3.06it/s]\u001b[A\n",
      "Iteration:  78% 398/513 [02:09<00:37,  3.07it/s]\u001b[A\n",
      "Iteration:  78% 399/513 [02:10<00:37,  3.07it/s]\u001b[A\n",
      "Iteration:  78% 400/513 [02:10<00:36,  3.06it/s]\u001b[A\n",
      "Iteration:  78% 401/513 [02:10<00:36,  3.07it/s]\u001b[A\n",
      "Iteration:  78% 402/513 [02:11<00:36,  3.07it/s]\u001b[A\n",
      "Iteration:  79% 403/513 [02:11<00:35,  3.07it/s]\u001b[A\n",
      "Iteration:  79% 404/513 [02:11<00:35,  3.06it/s]\u001b[A\n",
      "Iteration:  79% 405/513 [02:12<00:35,  3.07it/s]\u001b[A\n",
      "Iteration:  79% 406/513 [02:12<00:34,  3.07it/s]\u001b[A\n",
      "Iteration:  79% 407/513 [02:12<00:34,  3.07it/s]\u001b[A\n",
      "Iteration:  80% 408/513 [02:13<00:34,  3.06it/s]\u001b[A\n",
      "Iteration:  80% 409/513 [02:13<00:33,  3.06it/s]\u001b[A\n",
      "Iteration:  80% 410/513 [02:13<00:33,  3.06it/s]\u001b[A\n",
      "Iteration:  80% 411/513 [02:13<00:33,  3.06it/s]\u001b[A\n",
      "Iteration:  80% 412/513 [02:14<00:32,  3.07it/s]\u001b[A\n",
      "Iteration:  81% 413/513 [02:14<00:32,  3.05it/s]\u001b[A\n",
      "Iteration:  81% 414/513 [02:14<00:32,  3.06it/s]\u001b[A\n",
      "Iteration:  81% 415/513 [02:15<00:31,  3.07it/s]\u001b[A\n",
      "Iteration:  81% 416/513 [02:15<00:31,  3.07it/s]\u001b[A\n",
      "Iteration:  81% 417/513 [02:15<00:31,  3.07it/s]\u001b[A\n",
      "Iteration:  81% 418/513 [02:16<00:31,  3.06it/s]\u001b[A\n",
      "Iteration:  82% 419/513 [02:16<00:30,  3.07it/s]\u001b[A\n",
      "Iteration:  82% 420/513 [02:16<00:30,  3.07it/s]\u001b[A\n",
      "Iteration:  82% 421/513 [02:17<00:29,  3.07it/s]\u001b[A\n",
      "Iteration:  82% 422/513 [02:17<00:29,  3.06it/s]\u001b[A\n",
      "Iteration:  82% 423/513 [02:17<00:29,  3.07it/s]\u001b[A\n",
      "Iteration:  83% 424/513 [02:18<00:28,  3.08it/s]\u001b[A\n",
      "Iteration:  83% 425/513 [02:18<00:28,  3.08it/s]\u001b[A\n",
      "Iteration:  83% 426/513 [02:18<00:28,  3.08it/s]\u001b[A\n",
      "Iteration:  83% 427/513 [02:19<00:27,  3.08it/s]\u001b[A\n",
      "Iteration:  83% 428/513 [02:19<00:27,  3.07it/s]\u001b[A\n",
      "Iteration:  84% 429/513 [02:19<00:27,  3.08it/s]\u001b[A\n",
      "Iteration:  84% 430/513 [02:20<00:26,  3.07it/s]\u001b[A\n",
      "Iteration:  84% 431/513 [02:20<00:26,  3.05it/s]\u001b[A\n",
      "Iteration:  84% 432/513 [02:20<00:26,  3.05it/s]\u001b[A\n",
      "Iteration:  84% 433/513 [02:21<00:26,  3.06it/s]\u001b[A\n",
      "Iteration:  85% 434/513 [02:21<00:25,  3.06it/s]\u001b[A\n",
      "Iteration:  85% 435/513 [02:21<00:25,  3.06it/s]\u001b[A\n",
      "Iteration:  85% 436/513 [02:22<00:25,  3.06it/s]\u001b[A\n",
      "Iteration:  85% 437/513 [02:22<00:24,  3.07it/s]\u001b[A\n",
      "Iteration:  85% 438/513 [02:22<00:24,  3.07it/s]\u001b[A\n",
      "Iteration:  86% 439/513 [02:23<00:24,  3.08it/s]\u001b[A\n",
      "Iteration:  86% 440/513 [02:23<00:23,  3.07it/s]\u001b[A\n",
      "Iteration:  86% 441/513 [02:23<00:23,  3.07it/s]\u001b[A\n",
      "Iteration:  86% 442/513 [02:24<00:23,  3.07it/s]\u001b[A\n",
      "Iteration:  86% 443/513 [02:24<00:22,  3.08it/s]\u001b[A\n",
      "Iteration:  87% 444/513 [02:24<00:22,  3.08it/s]\u001b[A\n",
      "Iteration:  87% 445/513 [02:25<00:22,  3.07it/s]\u001b[A\n",
      "Iteration:  87% 446/513 [02:25<00:21,  3.07it/s]\u001b[A\n",
      "Iteration:  87% 447/513 [02:25<00:21,  3.07it/s]\u001b[A\n",
      "Iteration:  87% 448/513 [02:26<00:21,  3.08it/s]\u001b[A\n",
      "Iteration:  88% 449/513 [02:26<00:20,  3.06it/s]\u001b[A\n",
      "Iteration:  88% 450/513 [02:26<00:20,  3.06it/s]\u001b[A\n",
      "Iteration:  88% 451/513 [02:27<00:20,  3.07it/s]\u001b[A\n",
      "Iteration:  88% 452/513 [02:27<00:19,  3.07it/s]\u001b[A\n",
      "Iteration:  88% 453/513 [02:27<00:19,  3.07it/s]\u001b[A\n",
      "Iteration:  88% 454/513 [02:27<00:19,  3.06it/s]\u001b[A\n",
      "Iteration:  89% 455/513 [02:28<00:18,  3.07it/s]\u001b[A\n",
      "Iteration:  89% 456/513 [02:28<00:18,  3.07it/s]\u001b[A\n",
      "Iteration:  89% 457/513 [02:28<00:18,  3.07it/s]\u001b[A\n",
      "Iteration:  89% 458/513 [02:29<00:18,  3.06it/s]\u001b[A\n",
      "Iteration:  89% 459/513 [02:29<00:17,  3.06it/s]\u001b[A\n",
      "Iteration:  90% 460/513 [02:29<00:17,  3.06it/s]\u001b[A\n",
      "Iteration:  90% 461/513 [02:30<00:16,  3.07it/s]\u001b[A\n",
      "Iteration:  90% 462/513 [02:30<00:16,  3.07it/s]\u001b[A\n",
      "Iteration:  90% 463/513 [02:30<00:16,  3.07it/s]\u001b[A\n",
      "Iteration:  90% 464/513 [02:31<00:15,  3.07it/s]\u001b[A\n",
      "Iteration:  91% 465/513 [02:31<00:15,  3.07it/s]\u001b[A\n",
      "Iteration:  91% 466/513 [02:31<00:15,  3.08it/s]\u001b[A\n",
      "Iteration:  91% 467/513 [02:32<00:14,  3.07it/s]\u001b[A\n",
      "Iteration:  91% 468/513 [02:32<00:14,  3.07it/s]\u001b[A\n",
      "Iteration:  91% 469/513 [02:32<00:14,  3.05it/s]\u001b[A\n",
      "Iteration:  92% 470/513 [02:33<00:14,  3.06it/s]\u001b[A\n",
      "Iteration:  92% 471/513 [02:33<00:13,  3.06it/s]\u001b[A\n",
      "Iteration:  92% 472/513 [02:33<00:13,  3.06it/s]\u001b[A\n",
      "Iteration:  92% 473/513 [02:34<00:13,  3.07it/s]\u001b[A\n",
      "Iteration:  92% 474/513 [02:34<00:12,  3.07it/s]\u001b[A\n",
      "Iteration:  93% 475/513 [02:34<00:12,  3.06it/s]\u001b[A\n",
      "Iteration:  93% 476/513 [02:35<00:12,  3.06it/s]\u001b[A\n",
      "Iteration:  93% 477/513 [02:35<00:11,  3.06it/s]\u001b[A\n",
      "Iteration:  93% 478/513 [02:35<00:11,  3.06it/s]\u001b[A\n",
      "Iteration:  93% 479/513 [02:36<00:11,  3.07it/s]\u001b[A\n",
      "Iteration:  94% 480/513 [02:36<00:10,  3.07it/s]\u001b[A\n",
      "Iteration:  94% 481/513 [02:36<00:10,  3.07it/s]\u001b[A\n",
      "Iteration:  94% 482/513 [02:37<00:10,  3.06it/s]\u001b[A\n",
      "Iteration:  94% 483/513 [02:37<00:09,  3.06it/s]\u001b[A\n",
      "Iteration:  94% 484/513 [02:37<00:09,  3.07it/s]\u001b[A\n",
      "Iteration:  95% 485/513 [02:38<00:09,  3.07it/s]\u001b[A\n",
      "Iteration:  95% 486/513 [02:38<00:08,  3.06it/s]\u001b[A\n",
      "Iteration:  95% 487/513 [02:38<00:08,  3.06it/s]\u001b[A\n",
      "Iteration:  95% 488/513 [02:39<00:08,  3.06it/s]\u001b[A\n",
      "Iteration:  95% 489/513 [02:39<00:07,  3.07it/s]\u001b[A\n",
      "Iteration:  96% 490/513 [02:39<00:07,  3.05it/s]\u001b[A\n",
      "Iteration:  96% 491/513 [02:40<00:07,  3.06it/s]\u001b[A\n",
      "Iteration:  96% 492/513 [02:40<00:06,  3.06it/s]\u001b[A\n",
      "Iteration:  96% 493/513 [02:40<00:06,  3.06it/s]\u001b[A\n",
      "Iteration:  96% 494/513 [02:41<00:06,  3.06it/s]\u001b[A\n",
      "Iteration:  96% 495/513 [02:41<00:05,  3.06it/s]\u001b[A\n",
      "Iteration:  97% 496/513 [02:41<00:05,  3.07it/s]\u001b[A\n",
      "Iteration:  97% 497/513 [02:42<00:05,  3.04it/s]\u001b[A\n",
      "Iteration:  97% 498/513 [02:42<00:04,  3.03it/s]\u001b[A\n",
      "Iteration:  97% 499/513 [02:42<00:04,  3.04it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "03/06/2020 18:09:43 - INFO - transformers.configuration_utils -   Configuration saved in output_roberta_rev2/checkpoint-500/config.json\n",
      "03/06/2020 18:09:45 - INFO - transformers.modeling_utils -   Model weights saved in output_roberta_rev2/checkpoint-500/pytorch_model.bin\n",
      "03/06/2020 18:09:45 - INFO - __main__ -   Saving model checkpoint to output_roberta_rev2/checkpoint-500\n",
      "03/06/2020 18:09:49 - INFO - __main__ -   Saving optimizer and scheduler states to output_roberta_rev2/checkpoint-500\n",
      "\n",
      "Iteration:  97% 500/513 [02:48<00:24,  1.91s/it]\u001b[A\n",
      "Iteration:  98% 501/513 [02:48<00:17,  1.44s/it]\u001b[A\n",
      "Iteration:  98% 502/513 [02:48<00:12,  1.11s/it]\u001b[A\n",
      "Iteration:  98% 503/513 [02:49<00:08,  1.15it/s]\u001b[A\n",
      "Iteration:  98% 504/513 [02:49<00:06,  1.41it/s]\u001b[A\n",
      "Iteration:  98% 505/513 [02:49<00:04,  1.69it/s]\u001b[A\n",
      "Iteration:  99% 506/513 [02:50<00:03,  1.95it/s]\u001b[A\n",
      "Iteration:  99% 507/513 [02:50<00:02,  2.18it/s]\u001b[A\n",
      "Iteration:  99% 508/513 [02:50<00:02,  2.38it/s]\u001b[A\n",
      "Iteration:  99% 509/513 [02:51<00:01,  2.54it/s]\u001b[A\n",
      "Iteration:  99% 510/513 [02:51<00:01,  2.67it/s]\u001b[A\n",
      "Iteration: 100% 511/513 [02:51<00:00,  2.78it/s]\u001b[A\n",
      "Iteration: 100% 512/513 [02:52<00:00,  2.86it/s]\u001b[A\n",
      "Iteration: 100% 513/513 [02:52<00:00,  3.08it/s]\u001b[A\n",
      "Epoch: 100% 1/1 [02:52<00:00, 172.51s/it]\n",
      "03/06/2020 18:09:53 - INFO - __main__ -    global_step = 513, average loss = 1.6878476547218904\n",
      "03/06/2020 18:09:53 - INFO - __main__ -   Saving model checkpoint to output_roberta_rev2\n",
      "03/06/2020 18:09:53 - INFO - transformers.configuration_utils -   Configuration saved in output_roberta_rev2/config.json\n",
      "03/06/2020 18:10:00 - INFO - transformers.modeling_utils -   Model weights saved in output_roberta_rev2/pytorch_model.bin\n",
      "03/06/2020 18:10:00 - INFO - transformers.configuration_utils -   loading configuration file output_roberta_rev2/config.json\n",
      "03/06/2020 18:10:00 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"eos_token_ids\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "03/06/2020 18:10:00 - INFO - transformers.modeling_utils -   loading weights file output_roberta_rev2/pytorch_model.bin\n",
      "03/06/2020 18:10:05 - INFO - transformers.tokenization_utils -   Model name 'output_roberta_rev2' not found in model shortcut name list (roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector). Assuming 'output_roberta_rev2' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "03/06/2020 18:10:05 - INFO - transformers.tokenization_utils -   Didn't find file output_roberta_rev2/added_tokens.json. We won't load it.\n",
      "03/06/2020 18:10:05 - INFO - transformers.tokenization_utils -   loading file output_roberta_rev2/vocab.json\n",
      "03/06/2020 18:10:05 - INFO - transformers.tokenization_utils -   loading file output_roberta_rev2/merges.txt\n",
      "03/06/2020 18:10:05 - INFO - transformers.tokenization_utils -   loading file None\n",
      "03/06/2020 18:10:05 - INFO - transformers.tokenization_utils -   loading file output_roberta_rev2/special_tokens_map.json\n",
      "03/06/2020 18:10:05 - INFO - transformers.tokenization_utils -   loading file output_roberta_rev2/tokenizer_config.json\n",
      "03/06/2020 18:10:06 - INFO - __main__ -   Evaluate the following checkpoints: ['output_roberta_rev2']\n",
      "03/06/2020 18:10:06 - INFO - transformers.configuration_utils -   loading configuration file output_roberta_rev2/config.json\n",
      "03/06/2020 18:10:06 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"eos_token_ids\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "03/06/2020 18:10:06 - INFO - transformers.modeling_utils -   loading weights file output_roberta_rev2/pytorch_model.bin\n",
      "03/06/2020 18:10:11 - INFO - __main__ -   Creating features from dataset file at \n",
      "03/06/2020 18:10:12 - INFO - __main__ -   Saving features into cached file roberta_cached_lm_510_test_text_rev2\n",
      "03/06/2020 18:10:12 - INFO - __main__ -   ***** Running evaluation  *****\n",
      "03/06/2020 18:10:12 - INFO - __main__ -     Num examples = 513\n",
      "03/06/2020 18:10:12 - INFO - __main__ -     Batch size = 4\n",
      "Evaluating: 100% 129/129 [00:13<00:00,  9.88it/s]\n",
      "03/06/2020 18:10:25 - INFO - __main__ -   ***** Eval results  *****\n",
      "03/06/2020 18:10:25 - INFO - __main__ -     perplexity = tensor(4.4364)\n",
      "03/06/2020 18:10:29 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "03/06/2020 18:10:29 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.a7ab0e5de2d8321d6d6a15b199110f2c99be72976b7d151423cb8d8c261a13b6\n",
      "03/06/2020 18:10:29 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"eos_token_ids\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "03/06/2020 18:10:30 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "03/06/2020 18:10:30 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "03/06/2020 18:10:30 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
      "03/06/2020 18:10:35 - INFO - transformers.modeling_utils -   Weights of RobertaForMaskedLM not initialized from pretrained model: ['lm_head.decoder.bias']\n",
      "03/06/2020 18:10:39 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=True, eval_all_checkpoints=False, eval_data_file='test_text_rev3', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='roberta-base', model_type='roberta', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output_roberta_rev3', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='train_text_rev3', warmup_steps=0, weight_decay=0.0)\n",
      "03/06/2020 18:10:39 - INFO - __main__ -   Creating features from dataset file at \n",
      "03/06/2020 18:10:39 - INFO - __main__ -   Saving features into cached file roberta_cached_lm_510_train_text_rev3\n",
      "03/06/2020 18:10:39 - INFO - __main__ -   ***** Running training *****\n",
      "03/06/2020 18:10:39 - INFO - __main__ -     Num examples = 281\n",
      "03/06/2020 18:10:39 - INFO - __main__ -     Num Epochs = 1\n",
      "03/06/2020 18:10:39 - INFO - __main__ -     Instantaneous batch size per GPU = 4\n",
      "03/06/2020 18:10:39 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "03/06/2020 18:10:39 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
      "03/06/2020 18:10:39 - INFO - __main__ -     Total optimization steps = 71\n",
      "Epoch:   0% 0/1 [00:00<?, ?it/s]\n",
      "Iteration:   0% 0/71 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   1% 1/71 [00:00<00:24,  2.87it/s]\u001b[A\n",
      "Iteration:   3% 2/71 [00:00<00:23,  2.92it/s]\u001b[A\n",
      "Iteration:   4% 3/71 [00:01<00:22,  2.97it/s]\u001b[A\n",
      "Iteration:   6% 4/71 [00:01<00:22,  2.99it/s]\u001b[A\n",
      "Iteration:   7% 5/71 [00:01<00:21,  3.01it/s]\u001b[A\n",
      "Iteration:   8% 6/71 [00:01<00:21,  3.03it/s]\u001b[A\n",
      "Iteration:  10% 7/71 [00:02<00:21,  3.04it/s]\u001b[A\n",
      "Iteration:  11% 8/71 [00:02<00:20,  3.05it/s]\u001b[A\n",
      "Iteration:  13% 9/71 [00:02<00:20,  3.05it/s]\u001b[A\n",
      "Iteration:  14% 10/71 [00:03<00:19,  3.06it/s]\u001b[A\n",
      "Iteration:  15% 11/71 [00:03<00:19,  3.06it/s]\u001b[A\n",
      "Iteration:  17% 12/71 [00:03<00:19,  3.06it/s]\u001b[A\n",
      "Iteration:  18% 13/71 [00:04<00:19,  3.05it/s]\u001b[A\n",
      "Iteration:  20% 14/71 [00:04<00:18,  3.06it/s]\u001b[A\n",
      "Iteration:  21% 15/71 [00:04<00:18,  3.06it/s]\u001b[A\n",
      "Iteration:  23% 16/71 [00:05<00:17,  3.06it/s]\u001b[A\n",
      "Iteration:  24% 17/71 [00:05<00:17,  3.07it/s]\u001b[A\n",
      "Iteration:  25% 18/71 [00:05<00:17,  3.07it/s]\u001b[A\n",
      "Iteration:  27% 19/71 [00:06<00:16,  3.07it/s]\u001b[A\n",
      "Iteration:  28% 20/71 [00:06<00:16,  3.06it/s]\u001b[A\n",
      "Iteration:  30% 21/71 [00:06<00:16,  3.06it/s]\u001b[A\n",
      "Iteration:  31% 22/71 [00:07<00:15,  3.06it/s]\u001b[A\n",
      "Iteration:  32% 23/71 [00:07<00:15,  3.07it/s]\u001b[A\n",
      "Iteration:  34% 24/71 [00:07<00:15,  3.06it/s]\u001b[A\n",
      "Iteration:  35% 25/71 [00:08<00:14,  3.07it/s]\u001b[A\n",
      "Iteration:  37% 26/71 [00:08<00:14,  3.07it/s]\u001b[A\n",
      "Iteration:  38% 27/71 [00:08<00:14,  3.08it/s]\u001b[A\n",
      "Iteration:  39% 28/71 [00:09<00:13,  3.07it/s]\u001b[A\n",
      "Iteration:  41% 29/71 [00:09<00:13,  3.07it/s]\u001b[A\n",
      "Iteration:  42% 30/71 [00:09<00:13,  3.07it/s]\u001b[A\n",
      "Iteration:  44% 31/71 [00:10<00:13,  3.07it/s]\u001b[A\n",
      "Iteration:  45% 32/71 [00:10<00:12,  3.07it/s]\u001b[A\n",
      "Iteration:  46% 33/71 [00:10<00:12,  3.06it/s]\u001b[A\n",
      "Iteration:  48% 34/71 [00:11<00:12,  3.04it/s]\u001b[A\n",
      "Iteration:  49% 35/71 [00:11<00:11,  3.03it/s]\u001b[A\n",
      "Iteration:  51% 36/71 [00:11<00:11,  3.04it/s]\u001b[A\n",
      "Iteration:  52% 37/71 [00:12<00:11,  3.04it/s]\u001b[A\n",
      "Iteration:  54% 38/71 [00:12<00:10,  3.05it/s]\u001b[A\n",
      "Iteration:  55% 39/71 [00:12<00:10,  3.06it/s]\u001b[A\n",
      "Iteration:  56% 40/71 [00:13<00:10,  3.06it/s]\u001b[A\n",
      "Iteration:  58% 41/71 [00:13<00:09,  3.06it/s]\u001b[A\n",
      "Iteration:  59% 42/71 [00:13<00:09,  3.06it/s]\u001b[A\n",
      "Iteration:  61% 43/71 [00:14<00:09,  3.07it/s]\u001b[A\n",
      "Iteration:  62% 44/71 [00:14<00:08,  3.07it/s]\u001b[A\n",
      "Iteration:  63% 45/71 [00:14<00:08,  3.06it/s]\u001b[A\n",
      "Iteration:  65% 46/71 [00:15<00:08,  3.07it/s]\u001b[A\n",
      "Iteration:  66% 47/71 [00:15<00:07,  3.07it/s]\u001b[A\n",
      "Iteration:  68% 48/71 [00:15<00:07,  3.07it/s]\u001b[A\n",
      "Iteration:  69% 49/71 [00:16<00:07,  3.07it/s]\u001b[A\n",
      "Iteration:  70% 50/71 [00:16<00:06,  3.07it/s]\u001b[A\n",
      "Iteration:  72% 51/71 [00:16<00:06,  3.07it/s]\u001b[A\n",
      "Iteration:  73% 52/71 [00:17<00:06,  3.07it/s]\u001b[A\n",
      "Iteration:  75% 53/71 [00:17<00:05,  3.07it/s]\u001b[A\n",
      "Iteration:  76% 54/71 [00:17<00:05,  3.06it/s]\u001b[A\n",
      "Iteration:  77% 55/71 [00:17<00:05,  3.06it/s]\u001b[A\n",
      "Iteration:  79% 56/71 [00:18<00:04,  3.04it/s]\u001b[A\n",
      "Iteration:  80% 57/71 [00:18<00:04,  3.05it/s]\u001b[A\n",
      "Iteration:  82% 58/71 [00:18<00:04,  3.05it/s]\u001b[A\n",
      "Iteration:  83% 59/71 [00:19<00:03,  3.06it/s]\u001b[A\n",
      "Iteration:  85% 60/71 [00:19<00:03,  3.06it/s]\u001b[A\n",
      "Iteration:  86% 61/71 [00:19<00:03,  3.06it/s]\u001b[A\n",
      "Iteration:  87% 62/71 [00:20<00:02,  3.06it/s]\u001b[A\n",
      "Iteration:  89% 63/71 [00:20<00:02,  3.06it/s]\u001b[A\n",
      "Iteration:  90% 64/71 [00:20<00:02,  3.06it/s]\u001b[A\n",
      "Iteration:  92% 65/71 [00:21<00:01,  3.07it/s]\u001b[A\n",
      "Iteration:  93% 66/71 [00:21<00:01,  3.07it/s]\u001b[A\n",
      "Iteration:  94% 67/71 [00:21<00:01,  3.06it/s]\u001b[A\n",
      "Iteration:  96% 68/71 [00:22<00:00,  3.07it/s]\u001b[A\n",
      "Iteration:  97% 69/71 [00:22<00:00,  3.07it/s]\u001b[A\n",
      "Iteration:  99% 70/71 [00:22<00:00,  3.07it/s]\u001b[A\n",
      "Iteration: 100% 71/71 [00:23<00:00,  3.77it/s]\u001b[A\n",
      "Epoch: 100% 1/1 [00:23<00:00, 23.01s/it]\n",
      "03/06/2020 18:11:02 - INFO - __main__ -    global_step = 71, average loss = 1.863042932161143\n",
      "03/06/2020 18:11:02 - INFO - __main__ -   Saving model checkpoint to output_roberta_rev3\n",
      "03/06/2020 18:11:02 - INFO - transformers.configuration_utils -   Configuration saved in output_roberta_rev3/config.json\n",
      "03/06/2020 18:11:04 - INFO - transformers.modeling_utils -   Model weights saved in output_roberta_rev3/pytorch_model.bin\n",
      "03/06/2020 18:11:04 - INFO - transformers.configuration_utils -   loading configuration file output_roberta_rev3/config.json\n",
      "03/06/2020 18:11:04 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"eos_token_ids\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "03/06/2020 18:11:04 - INFO - transformers.modeling_utils -   loading weights file output_roberta_rev3/pytorch_model.bin\n",
      "03/06/2020 18:11:09 - INFO - transformers.tokenization_utils -   Model name 'output_roberta_rev3' not found in model shortcut name list (roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector). Assuming 'output_roberta_rev3' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "03/06/2020 18:11:09 - INFO - transformers.tokenization_utils -   Didn't find file output_roberta_rev3/added_tokens.json. We won't load it.\n",
      "03/06/2020 18:11:09 - INFO - transformers.tokenization_utils -   loading file output_roberta_rev3/vocab.json\n",
      "03/06/2020 18:11:09 - INFO - transformers.tokenization_utils -   loading file output_roberta_rev3/merges.txt\n",
      "03/06/2020 18:11:09 - INFO - transformers.tokenization_utils -   loading file None\n",
      "03/06/2020 18:11:09 - INFO - transformers.tokenization_utils -   loading file output_roberta_rev3/special_tokens_map.json\n",
      "03/06/2020 18:11:09 - INFO - transformers.tokenization_utils -   loading file output_roberta_rev3/tokenizer_config.json\n",
      "03/06/2020 18:11:09 - INFO - __main__ -   Evaluate the following checkpoints: ['output_roberta_rev3']\n",
      "03/06/2020 18:11:09 - INFO - transformers.configuration_utils -   loading configuration file output_roberta_rev3/config.json\n",
      "03/06/2020 18:11:09 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"eos_token_ids\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "03/06/2020 18:11:09 - INFO - transformers.modeling_utils -   loading weights file output_roberta_rev3/pytorch_model.bin\n",
      "03/06/2020 18:11:14 - INFO - __main__ -   Creating features from dataset file at \n",
      "03/06/2020 18:11:14 - INFO - __main__ -   Saving features into cached file roberta_cached_lm_510_test_text_rev3\n",
      "03/06/2020 18:11:14 - INFO - __main__ -   ***** Running evaluation  *****\n",
      "03/06/2020 18:11:14 - INFO - __main__ -     Num examples = 71\n",
      "03/06/2020 18:11:14 - INFO - __main__ -     Batch size = 4\n",
      "Evaluating: 100% 18/18 [00:01<00:00,  9.95it/s]\n",
      "03/06/2020 18:11:16 - INFO - __main__ -   ***** Eval results  *****\n",
      "03/06/2020 18:11:16 - INFO - __main__ -     perplexity = tensor(5.3800)\n"
     ]
    }
   ],
   "source": [
    "# fine tune these three set of reviews\n",
    "!python run_language_modelling.py --output_dir=output_roberta_rev1 --model_type=roberta --model_name_or_path=roberta-base --do_train --train_data_file=train_text_rev1 --do_eval --eval_data_file=test_text_rev1 --mlm --overwrite_output_dir\n",
    "!python run_language_modelling.py --output_dir=output_roberta_rev2 --model_type=roberta --model_name_or_path=roberta-base --do_train --train_data_file=train_text_rev2 --do_eval --eval_data_file=test_text_rev2 --mlm --overwrite_output_dir\n",
    "!python run_language_modelling.py --output_dir=output_roberta_rev3 --model_type=roberta --model_name_or_path=roberta-base --do_train --train_data_file=train_text_rev3 --do_eval --eval_data_file=test_text_rev3 --mlm  --overwrite_output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MyAhim1ADCG0"
   },
   "outputs": [],
   "source": [
    "roberta_1_model_embedding = RobertaModel.from_pretrained('output_roberta_rev1')\n",
    "roberta_1_tokenizer = RobertaTokenizer.from_pretrained('output_roberta_rev1')\n",
    "roberta_2_model_embedding = RobertaModel.from_pretrained('output_roberta_rev2')\n",
    "roberta_2_tokenizer = RobertaTokenizer.from_pretrained('output_roberta_rev2')\n",
    "roberta_3_model_embedding = RobertaModel.from_pretrained('output_roberta_rev3')\n",
    "roberta_3_tokenizer = RobertaTokenizer.from_pretrained('output_roberta_rev3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 858
    },
    "colab_type": "code",
    "id": "dg_azYxRDe-J",
    "outputId": "bf3eda94-ec8a-4bf2-aa7c-273a3fbcf49a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fancy beautiful high quality recommend\n",
      " \n",
      "For neutral reviews: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAD8CAYAAAC/1zkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJuGmwlUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For postive reviews: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAD8CAYAAAC/1zkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For negative reviews: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAD8CAYAAAC/1zkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7yyhFcrchAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"fancy beautiful high quality recommend\"\n",
    "print(\"fancy beautiful high quality recommend\")\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def word_vector(text, word_id, model, tokenizer):\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    word_embeddings, sentence_embeddings = model(tokens_tensor)   \n",
    "    vector = word_embeddings[0][word_id].detach().numpy()\n",
    "    return vector\n",
    "def visualise_diffs(text, model, tokenizer):\n",
    "    word_vecs = []\n",
    "    for i in range(0, len(text.split())):\n",
    "        word_vecs.append(word_vector(text, i, model, tokenizer))\n",
    "    L = []\n",
    "    for p in word_vecs:\n",
    "        l = []\n",
    "        for q in word_vecs:\n",
    "            l.append(1 - cosine(p, q))\n",
    "        L.append(l)\n",
    "    M = np.array(L)\n",
    "    fig = plt.figure()\n",
    "    div = pd.DataFrame(M, columns = list(text.split()), index = list(text.split()))\n",
    "    ax = sns.heatmap(div, cmap=\"YlGnBu\")\n",
    "    plt.show()\n",
    "\n",
    "print(\" \")\n",
    "print(\"For neutral reviews: \")\n",
    "visualise_diffs(text, roberta_1_model_embedding, roberta_1_tokenizer)\n",
    "print(\"For postive reviews: \")\n",
    "visualise_diffs(text, roberta_2_model_embedding, roberta_2_tokenizer)\n",
    "print(\"For negative reviews: \")\n",
    "visualise_diffs(text, roberta_3_model_embedding, roberta_3_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "vERWeHnpElfa",
    "outputId": "189d6258-a4b3-4b64-d369-731bd81e3a6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ugly uncomfortable constrained poor avoid\n",
      " \n",
      "For neutral reviews: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaIAAAE7CAYAAACfYoXkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naGAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For postive reviews: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaIAAAE7CAYAAACfYoXkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMzPLyonIzMyyciIyM7OsnIjMzCyr/w/HhLzZdjDZigAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For negative reviews: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaIAAAE7CAYAAACfYoXkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWiURRURErZKIIiKiVklEERFRq/8PI5I4b5dDxqEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"ugly uncomfortable constrained poor avoid\"\n",
    "print(\"ugly uncomfortable constrained poor avoid\")\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def word_vector(text, word_id, model, tokenizer):\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    word_embeddings, sentence_embeddings = model(tokens_tensor)   \n",
    "    vector = word_embeddings[0][word_id].detach().numpy()\n",
    "    return vector\n",
    "def visualise_diffs(text, model, tokenizer):\n",
    "    word_vecs = []\n",
    "    for i in range(0, len(text.split())):\n",
    "        word_vecs.append(word_vector(text, i, model, tokenizer))\n",
    "    L = []\n",
    "    for p in word_vecs:\n",
    "        l = []\n",
    "        for q in word_vecs:\n",
    "            l.append(1 - cosine(p, q))\n",
    "        L.append(l)\n",
    "    M = np.array(L)\n",
    "    fig = plt.figure()\n",
    "    div = pd.DataFrame(M, columns = list(text.split()), index = list(text.split()))\n",
    "    ax = sns.heatmap(div,cmap=\"YlGnBu\")\n",
    "    plt.show()\n",
    "\n",
    "print(\" \")\n",
    "print(\"For neutral reviews: \")\n",
    "visualise_diffs(text, roberta_1_model_embedding, roberta_1_tokenizer)\n",
    "print(\"For postive reviews: \")\n",
    "visualise_diffs(text, roberta_2_model_embedding, roberta_2_tokenizer)\n",
    "print(\"For negative reviews: \")\n",
    "visualise_diffs(text, roberta_3_model_embedding, roberta_3_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "edexIBt0Fb1A",
    "outputId": "b5d59bf3-d14d-42e2-aa29-5a863b96a018"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ordinary plain common usual general ecumenical\n",
      " \n",
      "For neutral reviews: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEsCAYAAAAGgF7BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For postive reviews: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEsCAYAAAAGgF7BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For negative reviews: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEsCAYAAAAGgF7BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNCcTMzNrmpOJmZk1zcnEzMya9v8BNagABPAyozMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"ordinary plain common usual general ecumenical\"\n",
    "print(\"ordinary plain common usual general ecumenical\")\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def word_vector(text, word_id, model, tokenizer):\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    word_embeddings, sentence_embeddings = model(tokens_tensor)   \n",
    "    vector = word_embeddings[0][word_id].detach().numpy()\n",
    "    return vector\n",
    "def visualise_diffs(text, model, tokenizer):\n",
    "    word_vecs = []\n",
    "    for i in range(0, len(text.split())):\n",
    "        word_vecs.append(word_vector(text, i, model, tokenizer))\n",
    "    L = []\n",
    "    for p in word_vecs:\n",
    "        l = []\n",
    "        for q in word_vecs:\n",
    "            l.append(1 - cosine(p, q))\n",
    "        L.append(l)\n",
    "    M = np.array(L)\n",
    "    fig = plt.figure()\n",
    "    div = pd.DataFrame(M, columns = list(text.split()), index = list(text.split()))\n",
    "    ax = sns.heatmap(div,cmap=\"YlGnBu\")\n",
    "    plt.show()\n",
    "\n",
    "print(\" \")\n",
    "print(\"For neutral reviews: \")\n",
    "visualise_diffs(text, roberta_1_model_embedding, roberta_1_tokenizer)\n",
    "print(\"For postive reviews: \")\n",
    "visualise_diffs(text, roberta_2_model_embedding, roberta_2_tokenizer)\n",
    "print(\"For negative reviews: \")\n",
    "visualise_diffs(text, roberta_3_model_embedding, roberta_3_tokenizer)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hw8_YS_Updated.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
